{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a77072696e64e8e8d12efc02f0d6a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d4cff085a9345248ee51803b58223dc",
              "IPY_MODEL_0376a249c436418ea9260a4a796f79eb",
              "IPY_MODEL_c3360bd1d321482fa3f0001707c4c0c6"
            ],
            "layout": "IPY_MODEL_d6a26714e41b4f23b19346467775eb9a"
          }
        },
        "6d4cff085a9345248ee51803b58223dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73f4194c2ab04196885e678ac6d1946f",
            "placeholder": "​",
            "style": "IPY_MODEL_da92741191c54fd7ad3899f1cf2b7b8a",
            "value": "modules.json: 100%"
          }
        },
        "0376a249c436418ea9260a4a796f79eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_743967ae99004a7aa8b226ab0fc5986c",
            "max": 229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99cf9919102c451c93c66cab3f2df170",
            "value": 229
          }
        },
        "c3360bd1d321482fa3f0001707c4c0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67a184c39af74864bc403ec0d6bc00a0",
            "placeholder": "​",
            "style": "IPY_MODEL_343de6a8a7534a979b9025c818a3e01c",
            "value": " 229/229 [00:00&lt;00:00, 21.5kB/s]"
          }
        },
        "d6a26714e41b4f23b19346467775eb9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73f4194c2ab04196885e678ac6d1946f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da92741191c54fd7ad3899f1cf2b7b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "743967ae99004a7aa8b226ab0fc5986c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99cf9919102c451c93c66cab3f2df170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67a184c39af74864bc403ec0d6bc00a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "343de6a8a7534a979b9025c818a3e01c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "330ee34d7ada4298aaf2271b4683a3c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a827a615f0c3438ea16dfceca5e7ffea",
              "IPY_MODEL_e829d05bc5ba418aa698b0360860dda2",
              "IPY_MODEL_3bad55727a5d4131bc29c8c5c7e5526e"
            ],
            "layout": "IPY_MODEL_6a8b1e11ae4a466995a4e58c756495b6"
          }
        },
        "a827a615f0c3438ea16dfceca5e7ffea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1dee0275dd94b6aa74a3fc930679888",
            "placeholder": "​",
            "style": "IPY_MODEL_a76eb6d25c8d4effb97581130b377b3f",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "e829d05bc5ba418aa698b0360860dda2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef51da9386274f35a21360e76a5d94fe",
            "max": 122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2744adfd449b4917ac4cebc199b59e87",
            "value": 122
          }
        },
        "3bad55727a5d4131bc29c8c5c7e5526e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63149334640a4c7aae2e732b717b0738",
            "placeholder": "​",
            "style": "IPY_MODEL_f0bb8e77c72841c1862c7f4275425482",
            "value": " 122/122 [00:00&lt;00:00, 8.84kB/s]"
          }
        },
        "6a8b1e11ae4a466995a4e58c756495b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1dee0275dd94b6aa74a3fc930679888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a76eb6d25c8d4effb97581130b377b3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef51da9386274f35a21360e76a5d94fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2744adfd449b4917ac4cebc199b59e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63149334640a4c7aae2e732b717b0738": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0bb8e77c72841c1862c7f4275425482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1946f47c7be41cb9beb75eb887ea618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b19c5fad8624c0097cdc2455408bcc6",
              "IPY_MODEL_a6b40dd1a6a14ff2ad608a6a0bd935ea",
              "IPY_MODEL_91a030c55aeb42d0b084ee26e2685f96"
            ],
            "layout": "IPY_MODEL_316aecd84a624974ae79dd61a81e0c06"
          }
        },
        "0b19c5fad8624c0097cdc2455408bcc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e987a331ee342ff8d715328e3904a3d",
            "placeholder": "​",
            "style": "IPY_MODEL_1f46ed11fcd04a59b307bfbfc8497a55",
            "value": "README.md: "
          }
        },
        "a6b40dd1a6a14ff2ad608a6a0bd935ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d39ced911e3140238b9a09d38f95ab2f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2576fe68d8dc4f218ae5481ddb8293ec",
            "value": 1
          }
        },
        "91a030c55aeb42d0b084ee26e2685f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd56263b33f74e3bbb36de7faa6e7602",
            "placeholder": "​",
            "style": "IPY_MODEL_d420220112134725915c449166c74f11",
            "value": " 3.89k/? [00:00&lt;00:00, 222kB/s]"
          }
        },
        "316aecd84a624974ae79dd61a81e0c06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e987a331ee342ff8d715328e3904a3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f46ed11fcd04a59b307bfbfc8497a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d39ced911e3140238b9a09d38f95ab2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2576fe68d8dc4f218ae5481ddb8293ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd56263b33f74e3bbb36de7faa6e7602": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d420220112134725915c449166c74f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6948afe6595b4b74b92e893eac8d3586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbcd65739e714167874b1223e82fc36a",
              "IPY_MODEL_c3eb31df80494cc7b403881b10247e9b",
              "IPY_MODEL_c4f3f022f45b4ff3ba5eb686ce0b12e0"
            ],
            "layout": "IPY_MODEL_4d5bd6dcae844e899d12013f0b8115dd"
          }
        },
        "dbcd65739e714167874b1223e82fc36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7841723427c45629b80bd4ae6198586",
            "placeholder": "​",
            "style": "IPY_MODEL_f663edc47bf3460394d0a7a9f9d4bcff",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "c3eb31df80494cc7b403881b10247e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c760b783f5524c9180367ec961533c67",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d43ccc3e12f4d6ba7e2685b0ab1dcf7",
            "value": 53
          }
        },
        "c4f3f022f45b4ff3ba5eb686ce0b12e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1bddf909aa844ce8cda761a53ee9d70",
            "placeholder": "​",
            "style": "IPY_MODEL_2503e1ab7e564a289ad2a7fb7cc7c096",
            "value": " 53.0/53.0 [00:00&lt;00:00, 5.06kB/s]"
          }
        },
        "4d5bd6dcae844e899d12013f0b8115dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7841723427c45629b80bd4ae6198586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f663edc47bf3460394d0a7a9f9d4bcff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c760b783f5524c9180367ec961533c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d43ccc3e12f4d6ba7e2685b0ab1dcf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1bddf909aa844ce8cda761a53ee9d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2503e1ab7e564a289ad2a7fb7cc7c096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a094b339d134366b7ddac98e2107bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65e63b1fdec94885819028f47ec95caa",
              "IPY_MODEL_6909d1ea5eca443896d0341980be9210",
              "IPY_MODEL_a9ca4991b24042c7bc83f842517dd434"
            ],
            "layout": "IPY_MODEL_d0526c08f02d4d669c2e91e2489078a3"
          }
        },
        "65e63b1fdec94885819028f47ec95caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e23c5dc5404a4b5e93a1f760cbe15dbf",
            "placeholder": "​",
            "style": "IPY_MODEL_81778570e34a4494a3ac81998373ec6c",
            "value": "config.json: 100%"
          }
        },
        "6909d1ea5eca443896d0341980be9210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2340e4965225403ea850e99c9e7b0edb",
            "max": 645,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e068868cffd541a896c30d6c594c1baf",
            "value": 645
          }
        },
        "a9ca4991b24042c7bc83f842517dd434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d3aa191d57241e59d6cbb3e3735cf0c",
            "placeholder": "​",
            "style": "IPY_MODEL_1a53b60a13e146dbaca8a3a01c00aaf1",
            "value": " 645/645 [00:00&lt;00:00, 51.2kB/s]"
          }
        },
        "d0526c08f02d4d669c2e91e2489078a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e23c5dc5404a4b5e93a1f760cbe15dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81778570e34a4494a3ac81998373ec6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2340e4965225403ea850e99c9e7b0edb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e068868cffd541a896c30d6c594c1baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d3aa191d57241e59d6cbb3e3735cf0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a53b60a13e146dbaca8a3a01c00aaf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e437b6e825d249c08c4f39573f10dcd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce9964e21b604591a4e018d598f4b8d3",
              "IPY_MODEL_8b1606d87e5d4bdea294f39a209aadac",
              "IPY_MODEL_523ddc726e58403d855b03a84348883f"
            ],
            "layout": "IPY_MODEL_3a513294ec5a4fbeacde6dae328714b1"
          }
        },
        "ce9964e21b604591a4e018d598f4b8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cbdf128fc9c4fe7916d70d91f6fa9e4",
            "placeholder": "​",
            "style": "IPY_MODEL_ba7471cc66044c0a89d8a56d3e6946f5",
            "value": "model.safetensors: 100%"
          }
        },
        "8b1606d87e5d4bdea294f39a209aadac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f92517fc83644939de7cbf5d4576c7c",
            "max": 470641600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39796df35d284085b9c936376750c3a1",
            "value": 470641600
          }
        },
        "523ddc726e58403d855b03a84348883f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e09078f30da5451f9ec4b92963414057",
            "placeholder": "​",
            "style": "IPY_MODEL_b5889643ae3446c5a007395b0a7777de",
            "value": " 471M/471M [00:10&lt;00:00, 53.9MB/s]"
          }
        },
        "3a513294ec5a4fbeacde6dae328714b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cbdf128fc9c4fe7916d70d91f6fa9e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba7471cc66044c0a89d8a56d3e6946f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f92517fc83644939de7cbf5d4576c7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39796df35d284085b9c936376750c3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e09078f30da5451f9ec4b92963414057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5889643ae3446c5a007395b0a7777de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d62aaa85a0e4aa6b5f20ca60f2b68bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_608c0742d7344bfa83b27ff07301b74b",
              "IPY_MODEL_8750513096754bb29a57e8e2715b1c19",
              "IPY_MODEL_5f6d955ed09440b69f765cfd4f3ea127"
            ],
            "layout": "IPY_MODEL_4061f04aeaa34bf9a1bc08750b295c96"
          }
        },
        "608c0742d7344bfa83b27ff07301b74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a97ac15b482e4be8b443c1e1f406f6c7",
            "placeholder": "​",
            "style": "IPY_MODEL_1f161adbf72c4e0f81671860fd3d88b6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8750513096754bb29a57e8e2715b1c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_652ae76a3e554b3da41048a986691ab7",
            "max": 480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e37ad39bd6164200b0f0e8f628c2bd52",
            "value": 480
          }
        },
        "5f6d955ed09440b69f765cfd4f3ea127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dfc321099fe44d3bb9f170e473bec82",
            "placeholder": "​",
            "style": "IPY_MODEL_598214d951614dfab07ec5d27d22a584",
            "value": " 480/480 [00:00&lt;00:00, 16.7kB/s]"
          }
        },
        "4061f04aeaa34bf9a1bc08750b295c96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97ac15b482e4be8b443c1e1f406f6c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f161adbf72c4e0f81671860fd3d88b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "652ae76a3e554b3da41048a986691ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e37ad39bd6164200b0f0e8f628c2bd52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dfc321099fe44d3bb9f170e473bec82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "598214d951614dfab07ec5d27d22a584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc4e7ef74833492eb17313c15b082be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a323074c5c64a30b26b9d8845dd3a93",
              "IPY_MODEL_0d20558c1a9a4793bffa0edb3b303569",
              "IPY_MODEL_96725e66e73e4c7cb7ecc614c3e7c17f"
            ],
            "layout": "IPY_MODEL_96435fc1cdb3465e86b1bac10b4d3d8c"
          }
        },
        "3a323074c5c64a30b26b9d8845dd3a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d2c8d45d29e47df8c3140f1b587ccf6",
            "placeholder": "​",
            "style": "IPY_MODEL_38a3b59566414ae2abcc3550535ec265",
            "value": "tokenizer.json: 100%"
          }
        },
        "0d20558c1a9a4793bffa0edb3b303569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a03b275305f4d1688a872edbd9fee3d",
            "max": 9081518,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b179680ce937450f9d5fea97058a9989",
            "value": 9081518
          }
        },
        "96725e66e73e4c7cb7ecc614c3e7c17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59bbb36fee8d46f28edcfc346edaa31a",
            "placeholder": "​",
            "style": "IPY_MODEL_aa127e522f674d4d8e715e4c996a5538",
            "value": " 9.08M/9.08M [00:00&lt;00:00, 16.0MB/s]"
          }
        },
        "96435fc1cdb3465e86b1bac10b4d3d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d2c8d45d29e47df8c3140f1b587ccf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38a3b59566414ae2abcc3550535ec265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a03b275305f4d1688a872edbd9fee3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b179680ce937450f9d5fea97058a9989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59bbb36fee8d46f28edcfc346edaa31a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa127e522f674d4d8e715e4c996a5538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e26b7d8101646d9819855504a7b9209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e7f9b1a782c49458bbaba09692d3787",
              "IPY_MODEL_a4cd5b7f61094dd89407c9e5021ba561",
              "IPY_MODEL_bf5f8474d21c42f8a281404eb849a277"
            ],
            "layout": "IPY_MODEL_0d9cf4eae325490aa0ec9e7720863c1a"
          }
        },
        "4e7f9b1a782c49458bbaba09692d3787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5eef243a00b417cbd6cdda0245acf6f",
            "placeholder": "​",
            "style": "IPY_MODEL_11b104213f4142bcb586baf12e167c09",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a4cd5b7f61094dd89407c9e5021ba561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_862154c055634bccab2942dc612fec3f",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59ccd13fd3a046679a69f434c807782e",
            "value": 239
          }
        },
        "bf5f8474d21c42f8a281404eb849a277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b53c3e3bcaaa477bb5ef564d97b5fb16",
            "placeholder": "​",
            "style": "IPY_MODEL_4b526812ecb142ccaf0960d331437a0f",
            "value": " 239/239 [00:00&lt;00:00, 8.52kB/s]"
          }
        },
        "0d9cf4eae325490aa0ec9e7720863c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5eef243a00b417cbd6cdda0245acf6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11b104213f4142bcb586baf12e167c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "862154c055634bccab2942dc612fec3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ccd13fd3a046679a69f434c807782e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b53c3e3bcaaa477bb5ef564d97b5fb16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b526812ecb142ccaf0960d331437a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d94e9b2e7e6c44678b27aa80d1b7e249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc02a195684b4d42a79d31e5a582539d",
              "IPY_MODEL_4c102d68e2734f548c9b5d1ab00f21d4",
              "IPY_MODEL_ea68b4c522e8457bb6d4a1fa580e13dc"
            ],
            "layout": "IPY_MODEL_0fdc6e9d5327496b93b08ceaf129dd07"
          }
        },
        "fc02a195684b4d42a79d31e5a582539d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a71807fdb27491f86a0b6c3de37ea68",
            "placeholder": "​",
            "style": "IPY_MODEL_fb474713f7284cf189a1778b0548182a",
            "value": "config.json: 100%"
          }
        },
        "4c102d68e2734f548c9b5d1ab00f21d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e113b2778754fe6bb6a0c5bea00de2c",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7604b92b30e146278f9d20aa87f65e5f",
            "value": 190
          }
        },
        "ea68b4c522e8457bb6d4a1fa580e13dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2c15fde744b404d8716ecfc8ed2ef1e",
            "placeholder": "​",
            "style": "IPY_MODEL_6e05088801bb4049849afc6552b904ee",
            "value": " 190/190 [00:00&lt;00:00, 8.79kB/s]"
          }
        },
        "0fdc6e9d5327496b93b08ceaf129dd07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a71807fdb27491f86a0b6c3de37ea68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb474713f7284cf189a1778b0548182a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e113b2778754fe6bb6a0c5bea00de2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7604b92b30e146278f9d20aa87f65e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2c15fde744b404d8716ecfc8ed2ef1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e05088801bb4049849afc6552b904ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97fa9fcea7224847b2ce85e23a747090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4037165ffe0b41c087088897efafd4a6",
              "IPY_MODEL_17146fbc2a3e4cbca49adb5ebe8cb0df",
              "IPY_MODEL_80abd70b7c204d91b75fd9d27f1ad399"
            ],
            "layout": "IPY_MODEL_9a11569393864849ac6a6ba022d74832"
          }
        },
        "4037165ffe0b41c087088897efafd4a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af56e6dcd32245cf9f57550b80109436",
            "placeholder": "​",
            "style": "IPY_MODEL_b5dc9e71b16c4ac1819a75da05fe7a1b",
            "value": "config.json: 100%"
          }
        },
        "17146fbc2a3e4cbca49adb5ebe8cb0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5963d9d5a9d9433390d861cc8f31a8fb",
            "max": 794,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ac7ec9959f446c7a2726e6381632efb",
            "value": 794
          }
        },
        "80abd70b7c204d91b75fd9d27f1ad399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc6469c9b6e0476686f9b53c8243c44e",
            "placeholder": "​",
            "style": "IPY_MODEL_509081e364474627bdfa4f82ab285e28",
            "value": " 794/794 [00:00&lt;00:00, 27.8kB/s]"
          }
        },
        "9a11569393864849ac6a6ba022d74832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af56e6dcd32245cf9f57550b80109436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5dc9e71b16c4ac1819a75da05fe7a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5963d9d5a9d9433390d861cc8f31a8fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac7ec9959f446c7a2726e6381632efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc6469c9b6e0476686f9b53c8243c44e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "509081e364474627bdfa4f82ab285e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54673bb2846b4c01853f2ab60734692b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bd98dd24c8545b5b848afb73b072478",
              "IPY_MODEL_c5d032034a81493688a23a17cd5673a5",
              "IPY_MODEL_3dcb9827d4304a27b6c45271ded60985"
            ],
            "layout": "IPY_MODEL_2ff4537fda4b43948782e0d2a86cafa8"
          }
        },
        "9bd98dd24c8545b5b848afb73b072478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a633a3e9a547a8a919ccd15924845c",
            "placeholder": "​",
            "style": "IPY_MODEL_9300e8a5909b4f0189c5d584257c9c8f",
            "value": "model.safetensors: 100%"
          }
        },
        "c5d032034a81493688a23a17cd5673a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_295fa1b9b1084380bae98f24d2c15ed3",
            "max": 90870598,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe32a13348e3471c8df81ba21f496fc8",
            "value": 90870598
          }
        },
        "3dcb9827d4304a27b6c45271ded60985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b144861404d847d7a9923960cd760627",
            "placeholder": "​",
            "style": "IPY_MODEL_80eea4fe0e4e42a7959ba5c50de6c884",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 80.4MB/s]"
          }
        },
        "2ff4537fda4b43948782e0d2a86cafa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1a633a3e9a547a8a919ccd15924845c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9300e8a5909b4f0189c5d584257c9c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "295fa1b9b1084380bae98f24d2c15ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe32a13348e3471c8df81ba21f496fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b144861404d847d7a9923960cd760627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80eea4fe0e4e42a7959ba5c50de6c884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ac754cf828a45b6ba205a2c1c50455f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c3669327a2f45d3b3d2eb60239ec6c3",
              "IPY_MODEL_d483f8fb5da544edbd17c15d9a84b711",
              "IPY_MODEL_ad6d0c8da4c04a91a39aaa213ab1704b"
            ],
            "layout": "IPY_MODEL_c53dc526224f4a28b3d4d78b6b00a5b0"
          }
        },
        "2c3669327a2f45d3b3d2eb60239ec6c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e5b484e1b5743bc8008456509123e82",
            "placeholder": "​",
            "style": "IPY_MODEL_5523e4cde7114d6e904838f778cd4d9b",
            "value": "tokenizer_config.json: "
          }
        },
        "d483f8fb5da544edbd17c15d9a84b711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb469a196cc647d7a1bcf3f257718d79",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b96a4de56d544e45a3767b5f666ada31",
            "value": 1
          }
        },
        "ad6d0c8da4c04a91a39aaa213ab1704b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55c6e7dff4184f2c9eeb545f1892b338",
            "placeholder": "​",
            "style": "IPY_MODEL_2e827e69891e419681b58a180535e87e",
            "value": " 1.33k/? [00:00&lt;00:00, 108kB/s]"
          }
        },
        "c53dc526224f4a28b3d4d78b6b00a5b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e5b484e1b5743bc8008456509123e82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5523e4cde7114d6e904838f778cd4d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb469a196cc647d7a1bcf3f257718d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b96a4de56d544e45a3767b5f666ada31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55c6e7dff4184f2c9eeb545f1892b338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e827e69891e419681b58a180535e87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3056d3fe4624741877b789b48b9038a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91edab52d19d4d0882b569bc6aff0916",
              "IPY_MODEL_fede74ad35e54b2bb4e73e49425e44ec",
              "IPY_MODEL_14e71fcc89f44a44b7871d790c03fe05"
            ],
            "layout": "IPY_MODEL_3be02c0782d7423fbd3e79a2a46495c5"
          }
        },
        "91edab52d19d4d0882b569bc6aff0916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25f78db229954ff1a5e80fa3fb00baa8",
            "placeholder": "​",
            "style": "IPY_MODEL_5cc0d505d4e1470fa40c1ee7ab645fc1",
            "value": "vocab.txt: "
          }
        },
        "fede74ad35e54b2bb4e73e49425e44ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56b5d0e50a344222b18abd8503f5fdb2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d143908d82c4cea80be9f22e57cc972",
            "value": 1
          }
        },
        "14e71fcc89f44a44b7871d790c03fe05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c660381386f4953ad7aa8cc6fc97a18",
            "placeholder": "​",
            "style": "IPY_MODEL_26be313acece487faa7f8997164c9be0",
            "value": " 232k/? [00:00&lt;00:00, 7.21MB/s]"
          }
        },
        "3be02c0782d7423fbd3e79a2a46495c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25f78db229954ff1a5e80fa3fb00baa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc0d505d4e1470fa40c1ee7ab645fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56b5d0e50a344222b18abd8503f5fdb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9d143908d82c4cea80be9f22e57cc972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c660381386f4953ad7aa8cc6fc97a18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26be313acece487faa7f8997164c9be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95d799bfc8f340e69e3318e8b04a4264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c1e923f78294a308dee4c18f6a8fa0d",
              "IPY_MODEL_0ff92b7445334b19bb87b804c21fdaaf",
              "IPY_MODEL_88e6621f2a694fdbbbb7349a3eb18b45"
            ],
            "layout": "IPY_MODEL_31b6ff07ed6a46f1b0359684c512476f"
          }
        },
        "4c1e923f78294a308dee4c18f6a8fa0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0190c1495b3b42f38c9064e7917215e0",
            "placeholder": "​",
            "style": "IPY_MODEL_a49f93c5fe7042908feeb35a7757e356",
            "value": "tokenizer.json: "
          }
        },
        "0ff92b7445334b19bb87b804c21fdaaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6b080ebb10f4c99a16f8f3ebf275220",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce84a55c6046486a9cdb7102f9b9e283",
            "value": 1
          }
        },
        "88e6621f2a694fdbbbb7349a3eb18b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89fbeb7321b9423d89417ea7a3aa2696",
            "placeholder": "​",
            "style": "IPY_MODEL_5906f7da2f6e4b089c7285c57b687849",
            "value": " 711k/? [00:00&lt;00:00, 29.0MB/s]"
          }
        },
        "31b6ff07ed6a46f1b0359684c512476f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0190c1495b3b42f38c9064e7917215e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a49f93c5fe7042908feeb35a7757e356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6b080ebb10f4c99a16f8f3ebf275220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ce84a55c6046486a9cdb7102f9b9e283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89fbeb7321b9423d89417ea7a3aa2696": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5906f7da2f6e4b089c7285c57b687849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e75444baf124147be779f9397d145ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b106066014a4cce93ee8899ccc83435",
              "IPY_MODEL_c1a455e80ecc49289be48ea78329abb3",
              "IPY_MODEL_be9ce6a1879647c3868d591daa3dc413"
            ],
            "layout": "IPY_MODEL_065134508e344c13858d581cdc37950f"
          }
        },
        "2b106066014a4cce93ee8899ccc83435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7349f1abae6419aa238cbb893a18862",
            "placeholder": "​",
            "style": "IPY_MODEL_5b99d868617648259df41d4fe5e1c6f6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c1a455e80ecc49289be48ea78329abb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a411d9cfad8411491e7ba3f48b92ff2",
            "max": 132,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34c4d86391be4e0dbd92a64ef1f7c80e",
            "value": 132
          }
        },
        "be9ce6a1879647c3868d591daa3dc413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92b3f2e2d57942d281b0e13f74ece5bb",
            "placeholder": "​",
            "style": "IPY_MODEL_d67eea6347a840d2b23a4b1df413d02f",
            "value": " 132/132 [00:00&lt;00:00, 11.0kB/s]"
          }
        },
        "065134508e344c13858d581cdc37950f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7349f1abae6419aa238cbb893a18862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b99d868617648259df41d4fe5e1c6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a411d9cfad8411491e7ba3f48b92ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34c4d86391be4e0dbd92a64ef1f7c80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92b3f2e2d57942d281b0e13f74ece5bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d67eea6347a840d2b23a4b1df413d02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca63a8efae9147fab0dcd552762c6827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbe0254f5c654745a97e05b642b78aa2",
              "IPY_MODEL_744b871a5b824b108ff4bc5411f16bea",
              "IPY_MODEL_9794ffbd53644e20aae3fd7b352f4fdd"
            ],
            "layout": "IPY_MODEL_f6431a15ffd44b9283b08530617ddf23"
          }
        },
        "dbe0254f5c654745a97e05b642b78aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65b3345330ec49708c516a3832c0bf83",
            "placeholder": "​",
            "style": "IPY_MODEL_32fd11910e9e4030a350cb9c02b9281d",
            "value": "README.md: "
          }
        },
        "744b871a5b824b108ff4bc5411f16bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c240399e3534d25982ae05b2f18fbeb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f305b22bf27c495fb9582aa9fbd60e43",
            "value": 1
          }
        },
        "9794ffbd53644e20aae3fd7b352f4fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c4c285fd9214da0bc8992b4eafb1fc2",
            "placeholder": "​",
            "style": "IPY_MODEL_89105d78fd8d44a5b8fb3678a4fb8e3d",
            "value": " 3.67k/? [00:00&lt;00:00, 276kB/s]"
          }
        },
        "f6431a15ffd44b9283b08530617ddf23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65b3345330ec49708c516a3832c0bf83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32fd11910e9e4030a350cb9c02b9281d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c240399e3534d25982ae05b2f18fbeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f305b22bf27c495fb9582aa9fbd60e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c4c285fd9214da0bc8992b4eafb1fc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89105d78fd8d44a5b8fb3678a4fb8e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "505eaa2e48924177a85e5e59a7f76bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb178277f87c4ca8b7d6da97a38b5c2c",
              "IPY_MODEL_a63f6d37ab474402af1685b9c0caa38c",
              "IPY_MODEL_dc88fd584fb84ef7b1235d217e416e6b"
            ],
            "layout": "IPY_MODEL_bf458c9be5054f01afcc956a5b7d9493"
          }
        },
        "eb178277f87c4ca8b7d6da97a38b5c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f7cc1554247455c8e2ac3c2c928c024",
            "placeholder": "​",
            "style": "IPY_MODEL_d46ec53d63d84133bebeea2b65d3be8b",
            "value": "Batches: 100%"
          }
        },
        "a63f6d37ab474402af1685b9c0caa38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0850a1bc0abe41dabb6ec6638fe79183",
            "max": 223,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26e4858a7219469393dbe7526a64f2c1",
            "value": 223
          }
        },
        "dc88fd584fb84ef7b1235d217e416e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31e9581c1a954a838f13784a9d9f3ba6",
            "placeholder": "​",
            "style": "IPY_MODEL_3a313ed2644245059695fc332745b24d",
            "value": " 223/223 [09:53&lt;00:00,  1.32it/s]"
          }
        },
        "bf458c9be5054f01afcc956a5b7d9493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f7cc1554247455c8e2ac3c2c928c024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d46ec53d63d84133bebeea2b65d3be8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0850a1bc0abe41dabb6ec6638fe79183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e4858a7219469393dbe7526a64f2c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31e9581c1a954a838f13784a9d9f3ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a313ed2644245059695fc332745b24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "SETUP INICIAL PARA GOOGLE COLAB\n",
        "============================================\n",
        "Ejecutar esta celda primero en Google Colab\n",
        "\"\"\"\n",
        "\n",
        "# ==================== INSTALACIÓN DE DEPENDENCIAS ====================\n",
        "print(\"📦 Instalando dependencias...\\n\")\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Instalar todas las librerías necesarias\n",
        "print(\"📦 Instalando librerías...\")\n",
        "!pip install -q chromadb sentence-transformers rank-bm25 groq neo4j scikit-learn rarfile\n",
        "\n",
        "print(\"✅ Dependencias instaladas\\n\")\n",
        "\n",
        "# ==================== INSTALAR UNRAR ====================\n",
        "print(\"📦 Instalando herramientas de sistema...\")\n",
        "!apt-get install -qq unrar > /dev/null 2>&1\n",
        "print(\"✅ Herramientas instaladas\\n\")\n",
        "\n",
        "# ==================== DESCOMPRIMIR FUENTES.RAR ====================\n",
        "print(\"📦 Procesando fuentes de datos...\")\n",
        "\n",
        "import rarfile\n",
        "from pathlib import Path\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "rar_path = Path('/content/fuentes.rar')\n",
        "\n",
        "if rar_path.exists():\n",
        "    print(f\"✅ Archivo {rar_path.name} encontrado\")\n",
        "\n",
        "    data_dir = Path('/content/data')\n",
        "    if data_dir.exists():\n",
        "        print(f\"🗑️ Limpiando carpeta data existente...\")\n",
        "        shutil.rmtree(data_dir)\n",
        "\n",
        "    data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    print(f\"📂 Descomprimiendo en {data_dir}...\")\n",
        "\n",
        "    try:\n",
        "        with rarfile.RarFile(rar_path, 'r') as rar_ref:\n",
        "            rar_ref.extractall(data_dir)\n",
        "\n",
        "        print(\"✅ Archivos descomprimidos\")\n",
        "\n",
        "        # Reorganizar estructura si es necesario\n",
        "        subdirs = list(data_dir.glob('*/'))\n",
        "        if len(subdirs) == 1:\n",
        "            print(\"📁 Reorganizando estructura de carpetas...\")\n",
        "            subdir = subdirs[0]\n",
        "            for item in subdir.iterdir():\n",
        "                shutil.move(str(item), str(data_dir / item.name))\n",
        "            subdir.rmdir()\n",
        "            print(\"✅ Estructura reorganizada\")\n",
        "\n",
        "        # Consolidar archivos de subdirectorios\n",
        "        print(f\"\\n📦 Consolidando archivos en /content/data/...\")\n",
        "\n",
        "        for pattern in ['*.csv', '*.json', '*.txt', '*.md']:\n",
        "            for file in data_dir.rglob(pattern):\n",
        "                if file.parent != data_dir:\n",
        "                    dest = data_dir / file.name\n",
        "                    if not dest.exists():\n",
        "                        shutil.move(str(file), str(dest))\n",
        "\n",
        "        # Limpiar directorios vacíos\n",
        "        for subdir in list(data_dir.glob('*/')):\n",
        "            if not list(subdir.iterdir()):\n",
        "                subdir.rmdir()\n",
        "\n",
        "        print(\"✅ Archivos consolidados\")\n",
        "\n",
        "        # Contar archivos\n",
        "        csv_count = len(list(data_dir.glob('*.csv')))\n",
        "        json_count = len(list(data_dir.glob('*.json')))\n",
        "        txt_count = len(list(data_dir.glob('*.txt')))\n",
        "        md_count = len(list(data_dir.glob('*.md')))\n",
        "\n",
        "        print(f\"\\n📊 Resumen en /content/data/:\")\n",
        "        print(f\"   📊 {csv_count} archivos CSV\")\n",
        "        print(f\"   📄 {json_count} archivos JSON\")\n",
        "        print(f\"   📝 {txt_count} archivos TXT\")\n",
        "        print(f\"   📘 {md_count} archivos MD\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ ERROR: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"⚠️ Archivo fuentes.rar NO encontrado en /content/\")\n",
        "    print(\"\\n   INSTRUCCIONES:\")\n",
        "    print(\"   1. Haz clic en el ícono de carpeta 📁 en el panel izquierdo\")\n",
        "    print(\"   2. Arrastra o sube el archivo fuentes.rar\")\n",
        "    print(\"   3. Ejecuta esta celda nuevamente\")\n",
        "\n",
        "print()\n",
        "\n",
        "# ==================== CONFIGURAR PATHS ====================\n",
        "print(\"📍 Configurando rutas de trabajo...\")\n",
        "\n",
        "BASE_DIR = Path('/content')\n",
        "DATA_DIR = Path('/content/data')\n",
        "MODELS_DIR = Path('/content/models')\n",
        "OUTPUT_DIR = Path('/content/outputs')\n",
        "\n",
        "for dir_path in [MODELS_DIR, OUTPUT_DIR]:\n",
        "    dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"✅ Rutas configuradas:\")\n",
        "print(f\"   Base: {BASE_DIR}\")\n",
        "print(f\"   Datos: {DATA_DIR}\")\n",
        "print(f\"   Modelos: {MODELS_DIR}\")\n",
        "print(f\"   Outputs: {OUTPUT_DIR}\\n\")\n",
        "\n",
        "# ==================== VERIFICAR ARCHIVOS ====================\n",
        "print(\"🔍 Verificando archivos de datos...\")\n",
        "\n",
        "csv_files = list(DATA_DIR.glob('*.csv'))\n",
        "json_files = list(DATA_DIR.glob('*.json'))\n",
        "txt_files = list(DATA_DIR.glob('*.txt'))\n",
        "md_files = list(DATA_DIR.glob('*.md'))\n",
        "\n",
        "print(f\"✅ Archivos CSV: {len(csv_files)}\")\n",
        "for f in sorted(csv_files)[:5]:\n",
        "    print(f\"   📊 {f.name}\")\n",
        "if len(csv_files) > 5:\n",
        "    print(f\"   ... y {len(csv_files) - 5} más\")\n",
        "\n",
        "print(f\"\\n✅ Archivos JSON: {len(json_files)}\")\n",
        "for f in sorted(json_files):\n",
        "    print(f\"   📄 {f.name}\")\n",
        "\n",
        "if txt_files:\n",
        "    print(f\"\\n✅ Archivos TXT: {len(txt_files)} (reseñas)\")\n",
        "    print(f\"   Primeros 5: {[f.name for f in sorted(txt_files)[:5]]}\")\n",
        "\n",
        "if md_files:\n",
        "    print(f\"\\n✅ Archivos MD: {len(md_files)} (manuales)\")\n",
        "    print(f\"   Primeros 5: {[f.name for f in sorted(md_files)[:5]]}\")\n",
        "\n",
        "# Verificar archivos críticos\n",
        "archivos_criticos = [\n",
        "    'faqs.json',\n",
        "    'productos.csv',\n",
        "    'vendedores.csv',\n",
        "    'ventas_historicas.csv',\n",
        "    'tickets_soporte.csv',\n",
        "    'inventario_sucursales.csv',\n",
        "    'devoluciones.csv'\n",
        "]\n",
        "\n",
        "print(f\"\\n🔍 Verificando archivos críticos:\")\n",
        "archivos_faltantes = []\n",
        "for archivo in archivos_criticos:\n",
        "    if (DATA_DIR / archivo).exists():\n",
        "        print(f\"   ✅ {archivo}\")\n",
        "    else:\n",
        "        print(f\"   ❌ {archivo} - NO ENCONTRADO\")\n",
        "        archivos_faltantes.append(archivo)\n",
        "\n",
        "if archivos_faltantes:\n",
        "    print(f\"\\n⚠️ ADVERTENCIA: Faltan {len(archivos_faltantes)} archivos críticos\")\n",
        "else:\n",
        "    print(f\"\\n✅ Todos los archivos críticos están disponibles\")\n",
        "\n",
        "print()\n",
        "\n",
        "# ==================== RESUMEN FINAL ====================\n",
        "print(\"=\"*60)\n",
        "print(\"✅ SETUP COMPLETADO\")\n",
        "print(\"=\"*60)\n",
        "print(f\"📂 Directorio de datos: {DATA_DIR}\")\n",
        "print(f\"📊 Archivos CSV: {len(csv_files)}\")\n",
        "print(f\"📄 Archivos JSON: {len(json_files)}\")\n",
        "print(f\"📝 Archivos TXT: {len(txt_files)}\")\n",
        "print(f\"📘 Archivos MD: {len(md_files)}\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n✅ Listo para continuar con la siguiente celda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUidebZMt-An",
        "outputId": "dad467d5-39ab-441c-a99f-68ade185b67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Instalando dependencias...\n",
            "\n",
            "📦 Instalando librerías...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.4/325.4 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m✅ Dependencias instaladas\n",
            "\n",
            "📦 Instalando herramientas de sistema...\n",
            "✅ Herramientas instaladas\n",
            "\n",
            "📦 Procesando fuentes de datos...\n",
            "✅ Archivo fuentes.rar encontrado\n",
            "📂 Descomprimiendo en /content/data...\n",
            "✅ Archivos descomprimidos\n",
            "📁 Reorganizando estructura de carpetas...\n",
            "✅ Estructura reorganizada\n",
            "\n",
            "📦 Consolidando archivos en /content/data/...\n",
            "✅ Archivos consolidados\n",
            "\n",
            "📊 Resumen en /content/data/:\n",
            "   📊 6 archivos CSV\n",
            "   📄 1 archivos JSON\n",
            "   📝 2979 archivos TXT\n",
            "   📘 50 archivos MD\n",
            "\n",
            "📍 Configurando rutas de trabajo...\n",
            "✅ Rutas configuradas:\n",
            "   Base: /content\n",
            "   Datos: /content/data\n",
            "   Modelos: /content/models\n",
            "   Outputs: /content/outputs\n",
            "\n",
            "🔍 Verificando archivos de datos...\n",
            "✅ Archivos CSV: 6\n",
            "   📊 devoluciones.csv\n",
            "   📊 inventario_sucursales.csv\n",
            "   📊 productos.csv\n",
            "   📊 tickets_soporte.csv\n",
            "   📊 vendedores.csv\n",
            "   ... y 1 más\n",
            "\n",
            "✅ Archivos JSON: 1\n",
            "   📄 faqs.json\n",
            "\n",
            "✅ Archivos TXT: 2979 (reseñas)\n",
            "   Primeros 5: ['medio_faqs.json.txt', 'resena_R00003.txt', 'resena_R00012.txt', 'resena_R00018.txt', 'resena_R00024.txt']\n",
            "\n",
            "✅ Archivos MD: 50 (manuales)\n",
            "   Primeros 5: ['manual_P0004_Compacto_Licuadora.md', 'manual_P0013_Procesadora.md', 'manual_P0014_Premium_Picadora.md', 'manual_P0016_Super_Picadora.md', 'manual_P0017_Profesional_Batidora_de_Mano.md']\n",
            "\n",
            "🔍 Verificando archivos críticos:\n",
            "   ✅ faqs.json\n",
            "   ✅ productos.csv\n",
            "   ✅ vendedores.csv\n",
            "   ✅ ventas_historicas.csv\n",
            "   ✅ tickets_soporte.csv\n",
            "   ✅ inventario_sucursales.csv\n",
            "   ✅ devoluciones.csv\n",
            "\n",
            "✅ Todos los archivos críticos están disponibles\n",
            "\n",
            "============================================================\n",
            "✅ SETUP COMPLETADO\n",
            "============================================================\n",
            "📂 Directorio de datos: /content/data\n",
            "📊 Archivos CSV: 6\n",
            "📄 Archivos JSON: 1\n",
            "📝 Archivos TXT: 2979\n",
            "📘 Archivos MD: 50\n",
            "============================================================\n",
            "\n",
            "✅ Listo para continuar con la siguiente celda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 2: CONFIGURACIÓN DE API KEYS Y CONFIG\n",
        "============================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# ==================== CONFIGURAR API KEYS ====================\n",
        "print(\"🔐 Configurando API Keys...\")\n",
        "\n",
        "# Cargar desde archivo .env si existe\n",
        "env_path = '/content/.env' if os.path.exists('/content/.env') else '.env'\n",
        "\n",
        "if os.path.exists(env_path):\n",
        "    with open(env_path) as f:\n",
        "        for line in f:\n",
        "            if '=' in line and not line.startswith('#'):\n",
        "                key, value = line.strip().split('=', 1)\n",
        "                os.environ[key] = value\n",
        "    print(f\"✅ Credenciales cargadas desde {env_path}\")\n",
        "else:\n",
        "    print(\"⚠️ Archivo .env no encontrado\")\n",
        "    print(\"   Crear archivo .env con las siguientes variables:\")\n",
        "    print(\"   GROQ_API_KEY=tu_clave\")\n",
        "    print(\"   NEO4J_URI=neo4j://tu_servidor:7687\")\n",
        "    print(\"   NEO4J_USER=neo4j\")\n",
        "    print(\"   NEO4J_PASSWORD=tu_password\")\n",
        "\n",
        "# Asignar variables desde entorno\n",
        "GROQ_API_KEY = os.environ.get('GROQ_API_KEY')\n",
        "NEO4J_URI = os.environ.get('NEO4J_URI')\n",
        "NEO4J_USER = os.environ.get('NEO4J_USER')\n",
        "NEO4J_PASSWORD = os.environ.get('NEO4J_PASSWORD')\n",
        "\n",
        "# Verificar credenciales\n",
        "if all([GROQ_API_KEY, NEO4J_URI, NEO4J_PASSWORD]):\n",
        "    print(\"✅ Todas las credenciales configuradas\")\n",
        "else:\n",
        "    print(\"❌ Faltan credenciales - revisar archivo .env\")\n",
        "\n",
        "print(\"✅ Variables de entorno configuradas\\n\")\n",
        "\n",
        "# ==================== CONFIGURACIÓN GLOBAL ====================\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Clase de configuración global del sistema RAG\"\"\"\n",
        "\n",
        "    # ===== PATHS =====\n",
        "    BASE_DIR = BASE_DIR\n",
        "    DATA_DIR = DATA_DIR\n",
        "    MODELS_DIR = MODELS_DIR\n",
        "    OUTPUT_DIR = OUTPUT_DIR\n",
        "\n",
        "    # ===== API KEYS =====\n",
        "    GROQ_API_KEY = GROQ_API_KEY\n",
        "    NEO4J_URI = NEO4J_URI\n",
        "    NEO4J_USER = NEO4J_USER\n",
        "    NEO4J_PASSWORD = NEO4J_PASSWORD\n",
        "\n",
        "    # ===== ARCHIVOS DE DATOS =====\n",
        "    DATA_FILES = {\n",
        "        'faqs': 'faqs.json',\n",
        "        'productos': 'productos.csv',\n",
        "        'vendedores': 'vendedores.csv',\n",
        "        'ventas': 'ventas_historicas.csv',\n",
        "        'tickets': 'tickets_soporte.csv',\n",
        "        'inventario': 'inventario_sucursales.csv',\n",
        "        'devoluciones': 'devoluciones.csv'\n",
        "    }\n",
        "\n",
        "    # ===== PATRONES DE ARCHIVOS =====\n",
        "    RESENAS_PATTERN = 'resena_*.txt'  # resena_R00001.txt, etc.\n",
        "    MANUALES_PATTERN = 'manual_*.md'  # manual_P0001_*.md, etc.\n",
        "\n",
        "    # ===== CONFIGURACIÓN LLM (GROQ) =====\n",
        "    LLM_CONFIG = {\n",
        "        'provider': 'groq',\n",
        "        'model': 'llama-3.3-70b-versatile',  # Modelo recomendado de GROQ\n",
        "        'temperature': 0.3,\n",
        "        'max_tokens': 1024,\n",
        "        'top_p': 0.9\n",
        "    }\n",
        "\n",
        "    # ===== CONFIGURACIÓN EMBEDDINGS =====\n",
        "    EMBEDDING_CONFIG = {\n",
        "        'model_name': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
        "        'device': 'cpu',  # Cambiar a 'cuda' si hay GPU disponible\n",
        "        'normalize_embeddings': True\n",
        "    }\n",
        "\n",
        "    # ===== CONFIGURACIÓN CHROMADB =====\n",
        "    CHROMA_CONFIG = {\n",
        "        'collection_name': 'electrodomesticos_docs',\n",
        "        'persist_directory': str(MODELS_DIR / 'chromadb'),\n",
        "        'distance_metric': 'cosine'\n",
        "    }\n",
        "\n",
        "    # ===== CONFIGURACIÓN TEXT SPLITTER =====\n",
        "    SPLITTER_CONFIG = {\n",
        "        'chunk_size': 400,\n",
        "        'chunk_overlap': 50,\n",
        "        'separators': [\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
        "    }\n",
        "\n",
        "    # ===== CONFIGURACIÓN BÚSQUEDA HÍBRIDA =====\n",
        "    HYBRID_SEARCH_CONFIG = {\n",
        "        'semantic_top_k': 20,\n",
        "        'bm25_top_k': 20,\n",
        "        'rerank_top_k': 5,\n",
        "        'alpha': 0.7  # 70% semántico, 30% BM25\n",
        "    }\n",
        "\n",
        "    # ===== CONFIGURACIÓN MEMORIA =====\n",
        "    MEMORY_CONFIG = {\n",
        "        'max_turns': 5,\n",
        "        'max_context_length': 2000\n",
        "    }\n",
        "\n",
        "    # ===== CLASES DE INTENCIÓN =====\n",
        "    INTENT_CLASSES = {\n",
        "        'vectorial': {\n",
        "            'description': 'Preguntas sobre uso, funcionamiento, problemas, mantenimiento, opiniones',\n",
        "            'keywords': ['cómo', 'usar', 'funciona', 'problema', 'opinión', 'reseña', 'manual']\n",
        "        },\n",
        "        'tabular': {\n",
        "            'description': 'Consultas de precios, filtros, stock, especificaciones técnicas',\n",
        "            'keywords': ['precio', 'menos de', 'mayor que', 'stock', 'disponible', 'cuánto']\n",
        "        },\n",
        "        'grafo': {\n",
        "            'description': 'Productos relacionados, compatibilidad, accesorios, similares',\n",
        "            'keywords': ['relacionado', 'compatible', 'similar', 'repuesto', 'accesorio']\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # ===== PROMPTS DEL SISTEMA =====\n",
        "    SYSTEM_PROMPTS = {\n",
        "        'rag_assistant': \"\"\"Eres un asistente virtual experto en electrodomésticos.\n",
        "\n",
        "Instrucciones:\n",
        "1. Responde SIEMPRE en español\n",
        "2. Sé claro, conciso y útil\n",
        "3. Si no tienes información suficiente, sugiere reformular la pregunta\n",
        "4. Cita información específica cuando sea relevante (ej: \"El producto P0001...\")\n",
        "5. Mantén un tono profesional pero amigable\n",
        "\"\"\",\n",
        "\n",
        "        'filter_generator': \"\"\"Eres un experto en generar filtros de búsqueda para bases de datos.\n",
        "\n",
        "IMPORTANTE:\n",
        "- Responde SOLO con un objeto JSON válido\n",
        "- NO agregues explicaciones antes o después del JSON\n",
        "- NO uses markdown (```json)\n",
        "- El JSON debe ser parseable directamente con json.loads()\n",
        "\"\"\",\n",
        "\n",
        "        'cypher_generator': \"\"\"Eres un experto en Neo4j y el lenguaje Cypher.\n",
        "\n",
        "IMPORTANTE:\n",
        "- Responde SOLO con la query Cypher\n",
        "- NO agregues explicaciones\n",
        "- La query debe ser ejecutable directamente\n",
        "- Usa LIMIT para evitar resultados excesivos (máximo 50)\n",
        "\"\"\"\n",
        "    }\n",
        "\n",
        "# Crear instancia de configuración global\n",
        "config = Config()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"✅ CONFIGURACIÓN COMPLETADA\")\n",
        "print(\"=\"*60)\n",
        "print(f\"📂 Directorio de datos: {config.DATA_DIR}\")\n",
        "print(f\"🤖 Proveedor LLM: {config.LLM_CONFIG['provider'].upper()}\")\n",
        "print(f\"📝 Modelo: {config.LLM_CONFIG['model']}\")\n",
        "print(f\"🧠 Modelo embeddings: {config.EMBEDDING_CONFIG['model_name']}\")\n",
        "print(f\"💾 ChromaDB: {config.CHROMA_CONFIG['persist_directory']}\")\n",
        "print(f\"🔐 API Keys configuradas: {'✅' if config.GROQ_API_KEY else '❌'}\")\n",
        "print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvRqGtWHNi9k",
        "outputId": "9db6f1ce-9772-464c-c0d9-de0eed9b25c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔐 Configurando API Keys...\n",
            "⚠️ Archivo .env no encontrado\n",
            "   Crear archivo .env con las siguientes variables:\n",
            "   GROQ_API_KEY=tu_clave\n",
            "   NEO4J_URI=neo4j://tu_servidor:7687\n",
            "   NEO4J_USER=neo4j\n",
            "   NEO4J_PASSWORD=tu_password\n",
            "✅ Todas las credenciales configuradas\n",
            "✅ Variables de entorno configuradas\n",
            "\n",
            "============================================================\n",
            "✅ CONFIGURACIÓN COMPLETADA\n",
            "============================================================\n",
            "📂 Directorio de datos: /content/data\n",
            "🤖 Proveedor LLM: GROQ\n",
            "📝 Modelo: llama-3.3-70b-versatile\n",
            "🧠 Modelo embeddings: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
            "💾 ChromaDB: /content/models/chromadb\n",
            "🔐 API Keys configuradas: ✅\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 3: CARGA DE DATOS\n",
        "============================================\n",
        "Carga y procesa todos los archivos de fuentes de información\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "import re\n",
        "\n",
        "# ==================== CORRECCIÓN DE ENCODING ====================\n",
        "\n",
        "def fix_encoding(text: str) -> str:\n",
        "    \"\"\"Corrige el encoding UTF-8 mal interpretado\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "\n",
        "    # Usar códigos unicode en lugar de caracteres literales\n",
        "    replacements = {\n",
        "        '\\xc3\\xa1': 'á',  # á\n",
        "        '\\xc3\\xa9': 'é',  # é\n",
        "        '\\xc3\\xad': 'í',  # í\n",
        "        '\\xc3\\xb3': 'ó',  # ó\n",
        "        '\\xc3\\xba': 'ú',  # ú\n",
        "        '\\xc3\\x81': 'Á',  # Á\n",
        "        '\\xc3\\x89': 'É',  # É\n",
        "        '\\xc3\\x8d': 'Í',  # Í\n",
        "        '\\xc3\\x93': 'Ó',  # Ó\n",
        "        '\\xc3\\x9a': 'Ú',  # Ú\n",
        "        '\\xc3\\xb1': 'ñ',  # ñ\n",
        "        '\\xc3\\x91': 'Ñ',  # Ñ\n",
        "        '\\xc2\\xbf': '¿',  # ¿\n",
        "        '\\xc2\\xa1': '¡',  # ¡\n",
        "    }\n",
        "\n",
        "    for bad, good in replacements.items():\n",
        "        text = text.replace(bad, good)\n",
        "\n",
        "    # Patrones adicionales comunes\n",
        "    text = text.replace('\\xc3\\xb3n', 'ón')\n",
        "    text = text.replace('\\xc3\\xadn', 'ín')\n",
        "    text = text.replace('\\xc3\\xb1o', 'ño')\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# ==================== CARGA DE ARCHIVOS ====================\n",
        "\n",
        "def load_json(filepath: Path) -> List[Dict]:\n",
        "    \"\"\"Carga archivo JSON con corrección de encoding\"\"\"\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "    except UnicodeDecodeError:\n",
        "        with open(filepath, 'r', encoding='latin-1') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "    if isinstance(data, list):\n",
        "        for item in data:\n",
        "            if isinstance(item, dict):\n",
        "                for key, value in item.items():\n",
        "                    if isinstance(value, str):\n",
        "                        item[key] = fix_encoding(value)\n",
        "\n",
        "    return data\n",
        "\n",
        "def load_csv(filepath: Path) -> pd.DataFrame:\n",
        "    \"\"\"Carga archivo CSV con corrección de encoding y tipos de datos\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(filepath, encoding='utf-8')\n",
        "    except UnicodeDecodeError:\n",
        "        df = pd.read_csv(filepath, encoding='latin-1')\n",
        "\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'object':\n",
        "            df[col] = df[col].apply(lambda x: fix_encoding(x) if isinstance(x, str) else x)\n",
        "\n",
        "    # CORRECCIÓN DE TIPOS DE DATOS\n",
        "    # Convertir columnas numéricas que pueden estar como texto\n",
        "    numeric_columns = ['precio_usd', 'stock', 'potencia_w', 'peso_kg', 'garantia_meses',\n",
        "                      'cantidad', 'total', 'descuento_pct', 'precio_unitario',\n",
        "                      'stock_sucursal', 'precio_sucursal', 'monto_devuelto']\n",
        "\n",
        "    for col in numeric_columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    return df\n",
        "\n",
        "def load_resenas(base_dir: Path) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Carga todas las reseñas desde archivos .txt\n",
        "    Busca en:\n",
        "    - /content/data/resena_*.txt\n",
        "    - /content/data/reseñas_usuarios/resena_*.txt\n",
        "    \"\"\"\n",
        "    resenas = []\n",
        "\n",
        "    # Buscar en múltiples ubicaciones\n",
        "    search_paths = [\n",
        "        base_dir / 'resena_*.txt',\n",
        "        base_dir / 'reseñas_usuarios' / 'resena_*.txt',\n",
        "        base_dir / 'resenas_usuarios' / 'resena_*.txt'\n",
        "    ]\n",
        "\n",
        "    txt_files = []\n",
        "    for search_path in search_paths:\n",
        "        txt_files.extend(list(base_dir.glob(str(search_path.relative_to(base_dir)))))\n",
        "\n",
        "    # También búsqueda recursiva general\n",
        "    txt_files.extend(list(base_dir.rglob('resena_*.txt')))\n",
        "\n",
        "    # Eliminar duplicados\n",
        "    txt_files = list(set(txt_files))\n",
        "\n",
        "    print(f\"   📝 Encontrados {len(txt_files)} archivos .txt\")\n",
        "\n",
        "    for txt_file in txt_files:\n",
        "        match = re.search(r'resena_(\\w+)\\.txt', txt_file.name)\n",
        "        if match:\n",
        "            id_resena = match.group(1)\n",
        "\n",
        "            try:\n",
        "                with open(txt_file, 'r', encoding='utf-8') as f:\n",
        "                    texto = f.read().strip()\n",
        "\n",
        "                if texto:\n",
        "                    resenas.append({\n",
        "                        'id_resena': id_resena,\n",
        "                        'texto': fix_encoding(texto),\n",
        "                        'archivo': txt_file.name\n",
        "                    })\n",
        "            except Exception as e:\n",
        "                print(f\"      ⚠️ Error leyendo {txt_file.name}: {e}\")\n",
        "\n",
        "    return resenas\n",
        "\n",
        "def parse_manual_sections(markdown_text: str) -> List[Dict]:\n",
        "    \"\"\"Parsea un manual en markdown y extrae secciones\"\"\"\n",
        "    secciones = []\n",
        "\n",
        "    partes = re.split(r'\\n## ', markdown_text)\n",
        "\n",
        "    for i, parte in enumerate(partes):\n",
        "        if i == 0:\n",
        "            continue\n",
        "\n",
        "        lines = parte.split('\\n', 1)\n",
        "        titulo = lines[0].strip()\n",
        "        contenido = lines[1].strip() if len(lines) > 1 else \"\"\n",
        "\n",
        "        tipo = categorize_section(titulo)\n",
        "\n",
        "        if contenido and tipo:\n",
        "            secciones.append({\n",
        "                'tipo': tipo,\n",
        "                'titulo': titulo,\n",
        "                'contenido': contenido\n",
        "            })\n",
        "\n",
        "    return secciones\n",
        "\n",
        "def categorize_section(titulo: str) -> str:\n",
        "    \"\"\"Categoriza una sección del manual según su título\"\"\"\n",
        "    titulo_lower = titulo.lower()\n",
        "\n",
        "    if 'especificacion' in titulo_lower:\n",
        "        return 'especificaciones'\n",
        "    elif 'componente' in titulo_lower:\n",
        "        return 'componentes'\n",
        "    elif 'procedimiento' in titulo_lower or 'uso' in titulo_lower:\n",
        "        return 'procedimientos'\n",
        "    elif 'compatibilidad' in titulo_lower or 'relacion' in titulo_lower:\n",
        "        return 'compatibilidad'\n",
        "    elif 'problema' in titulo_lower or 'solucion' in titulo_lower:\n",
        "        return 'troubleshooting'\n",
        "    elif 'mantenimiento' in titulo_lower:\n",
        "        return 'mantenimiento'\n",
        "    elif 'garantia' in titulo_lower or 'garantía' in titulo_lower:\n",
        "        return 'garantia'\n",
        "    else:\n",
        "        return 'otros'\n",
        "\n",
        "def load_manuales(base_dir: Path) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Carga y parsea todos los manuales técnicos\n",
        "    Busca en:\n",
        "    - /content/data/manual_*.md\n",
        "    - /content/data/manuales_productos/manual_*.md\n",
        "    \"\"\"\n",
        "    manuales = []\n",
        "\n",
        "    # Buscar en múltiples ubicaciones\n",
        "    search_paths = [\n",
        "        base_dir / 'manual_*.md',\n",
        "        base_dir / 'manuales_productos' / 'manual_*.md'\n",
        "    ]\n",
        "\n",
        "    md_files = []\n",
        "    for search_path in search_paths:\n",
        "        md_files.extend(list(base_dir.glob(str(search_path.relative_to(base_dir)))))\n",
        "\n",
        "    # También búsqueda recursiva general\n",
        "    md_files.extend(list(base_dir.rglob('manual_*.md')))\n",
        "\n",
        "    # Eliminar duplicados\n",
        "    md_files = list(set(md_files))\n",
        "\n",
        "    print(f\"   📘 Encontrados {len(md_files)} archivos .md\")\n",
        "\n",
        "    for md_file in md_files:\n",
        "        match = re.search(r'manual_(P\\d+)', md_file.name)\n",
        "        if match:\n",
        "            id_producto = match.group(1)\n",
        "\n",
        "            try:\n",
        "                with open(md_file, 'r', encoding='utf-8') as f:\n",
        "                    contenido = f.read()\n",
        "\n",
        "                secciones = parse_manual_sections(contenido)\n",
        "\n",
        "                for seccion in secciones:\n",
        "                    manuales.append({\n",
        "                        'id_producto': id_producto,\n",
        "                        'tipo_seccion': seccion['tipo'],\n",
        "                        'titulo': seccion['titulo'],\n",
        "                        'contenido': fix_encoding(seccion['contenido']),\n",
        "                        'archivo': md_file.name\n",
        "                    })\n",
        "            except Exception as e:\n",
        "                print(f\"      ⚠️ Error leyendo {md_file.name}: {e}\")\n",
        "\n",
        "    return manuales\n",
        "\n",
        "# ==================== EXTRACCIÓN DE METADATA ====================\n",
        "\n",
        "def extract_productos_metadata(df: pd.DataFrame) -> Dict:\n",
        "    \"\"\"Extrae metadata del dataset de productos\"\"\"\n",
        "    metadata = {\n",
        "        'total_productos': len(df),\n",
        "        'columnas': list(df.columns),\n",
        "        'categorias_unicas': sorted(df['categoria'].dropna().unique().tolist()),\n",
        "        'subcategorias_unicas': sorted(df['subcategoria'].dropna().unique().tolist()),\n",
        "        'marcas_unicas': sorted(df['marca'].dropna().unique().tolist()),\n",
        "        'precio_min': float(df['precio_usd'].min()),\n",
        "        'precio_max': float(df['precio_usd'].max()),\n",
        "        'colores_disponibles': sorted(df['color'].dropna().unique().tolist()),\n",
        "        'voltajes_disponibles': sorted(df['voltaje'].dropna().unique().tolist()),\n",
        "        'garantia_min': int(df['garantia_meses'].min()),\n",
        "        'garantia_max': int(df['garantia_meses'].max()),\n",
        "        'potencia_min': float(df['potencia_w'].min()),\n",
        "        'potencia_max': float(df['potencia_w'].max()),\n",
        "        'capacidades_unicas': sorted(df['capacidad'].dropna().unique().tolist())\n",
        "    }\n",
        "\n",
        "    return metadata\n",
        "\n",
        "def extract_ventas_metadata(df: pd.DataFrame) -> Dict:\n",
        "    \"\"\"Extrae metadata del dataset de ventas\"\"\"\n",
        "    metadata = {\n",
        "        'total_ventas': len(df),\n",
        "        'columnas': list(df.columns),\n",
        "        'metodos_pago': sorted(df['metodo_pago'].dropna().unique().tolist()),\n",
        "        'sucursales': sorted(df['sucursal'].dropna().unique().tolist()),\n",
        "        'provincias': sorted(df['cliente_provincia'].dropna().unique().tolist()),\n",
        "        'fecha_min': df['fecha'].min(),\n",
        "        'fecha_max': df['fecha'].max(),\n",
        "        'total_min': float(df['total'].min()),\n",
        "        'total_max': float(df['total'].max()),\n",
        "        'descuento_max': int(df['descuento_pct'].max())\n",
        "    }\n",
        "\n",
        "    return metadata\n",
        "\n",
        "# ==================== CLASE DATA LOADER ====================\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"Clase para cargar todos los datos del sistema RAG\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.dataframes = {}\n",
        "        self.documents = {}\n",
        "        self.metadata = {}\n",
        "\n",
        "    def load_all(self):\n",
        "        \"\"\"Carga todos los datos del sistema\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"CARGANDO DATOS DEL SISTEMA RAG\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        # ========== CARGAR DATAFRAMES CSV ==========\n",
        "        print(\"📊 Cargando archivos CSV...\")\n",
        "        for key, filename in self.config.DATA_FILES.items():\n",
        "            if filename.endswith('.csv'):\n",
        "                filepath = self.config.DATA_DIR / filename\n",
        "                if filepath.exists():\n",
        "                    self.dataframes[key] = load_csv(filepath)\n",
        "                    print(f\"   ✅ {key}: {len(self.dataframes[key])} filas\")\n",
        "                else:\n",
        "                    print(f\"   ⚠️ No encontrado: {filename}\")\n",
        "\n",
        "        # ========== CARGAR FAQs JSON ==========\n",
        "        print(\"\\n📄 Cargando FAQs...\")\n",
        "        faqs_path = self.config.DATA_DIR / self.config.DATA_FILES['faqs']\n",
        "        if faqs_path.exists():\n",
        "            self.documents['faqs'] = load_json(faqs_path)\n",
        "            print(f\"   ✅ FAQs: {len(self.documents['faqs'])} registros\")\n",
        "        else:\n",
        "            print(f\"   ⚠️ No encontrado: {faqs_path.name}\")\n",
        "            self.documents['faqs'] = []\n",
        "\n",
        "        # ========== CARGAR RESEÑAS ==========\n",
        "        print(\"\\n📝 Cargando reseñas...\")\n",
        "        self.documents['resenas'] = load_resenas(self.config.DATA_DIR)\n",
        "        print(f\"   ✅ Reseñas cargadas: {len(self.documents['resenas'])} archivos\")\n",
        "\n",
        "        # ========== CARGAR MANUALES ==========\n",
        "        print(\"\\n📘 Cargando manuales...\")\n",
        "        self.documents['manuales'] = load_manuales(self.config.DATA_DIR)\n",
        "        print(f\"   ✅ Manuales cargados: {len(self.documents['manuales'])} secciones\")\n",
        "\n",
        "        # ========== EXTRAER METADATA ==========\n",
        "        print(\"\\n📊 Extrayendo metadata...\")\n",
        "        if 'productos' in self.dataframes:\n",
        "            self.metadata['productos'] = extract_productos_metadata(self.dataframes['productos'])\n",
        "            print(f\"   ✅ Metadata productos:\")\n",
        "            print(f\"      - {len(self.metadata['productos']['categorias_unicas'])} categorías\")\n",
        "            print(f\"      - {len(self.metadata['productos']['marcas_unicas'])} marcas\")\n",
        "            print(f\"      - Precios: ${self.metadata['productos']['precio_min']:.2f} - ${self.metadata['productos']['precio_max']:.2f}\")\n",
        "\n",
        "        if 'ventas' in self.dataframes:\n",
        "            self.metadata['ventas'] = extract_ventas_metadata(self.dataframes['ventas'])\n",
        "            print(f\"   ✅ Metadata ventas:\")\n",
        "            print(f\"      - {self.metadata['ventas']['total_ventas']} transacciones\")\n",
        "            print(f\"      - {len(self.metadata['ventas']['sucursales'])} sucursales\")\n",
        "            print(f\"      - {len(self.metadata['ventas']['metodos_pago'])} métodos de pago\")\n",
        "\n",
        "        # ========== RESUMEN FINAL ==========\n",
        "        self._print_summary()\n",
        "\n",
        "        return self.dataframes, self.documents, self.metadata\n",
        "\n",
        "    def _print_summary(self):\n",
        "        \"\"\"Imprime resumen de datos cargados\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"RESUMEN DE DATOS CARGADOS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(f\"\\n📊 DataFrames ({len(self.dataframes)}):\")\n",
        "        for key, df in self.dataframes.items():\n",
        "            print(f\"   {key:15s} → {len(df):6d} filas x {len(df.columns):2d} columnas\")\n",
        "\n",
        "        print(f\"\\n📄 Documentos no tabulares:\")\n",
        "        for key, docs in self.documents.items():\n",
        "            print(f\"   {key:15s} → {len(docs):6d} documentos\")\n",
        "\n",
        "        total_docs = sum(len(docs) for docs in self.documents.values())\n",
        "        print(f\"\\n📈 Total documentos para vectorizar: {total_docs}\")\n",
        "\n",
        "        print(f\"\\n📊 Metadata extraída: {len(self.metadata)} datasets\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== EJECUCIÓN ====================\n",
        "\n",
        "print(\"📄 Inicializando DataLoader...\")\n",
        "data_loader = DataLoader(config)\n",
        "\n",
        "dataframes, documents, metadata = data_loader.load_all()\n",
        "\n",
        "print(\"✅ Datos cargados exitosamente\")\n",
        "print(f\"   Acceso: dataframes, documents, metadata\")\n",
        "print(f\"\\nEjemplo de uso:\")\n",
        "print(f\"   df_productos = dataframes['productos']\")\n",
        "print(f\"   faqs = documents['faqs']\")\n",
        "print(f\"   meta_productos = metadata['productos']\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxxKQt8xZiFK",
        "outputId": "d6860d83-3956-4d13-ac59-0082b5196abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 Inicializando DataLoader...\n",
            "\n",
            "============================================================\n",
            "CARGANDO DATOS DEL SISTEMA RAG\n",
            "============================================================\n",
            "\n",
            "📊 Cargando archivos CSV...\n",
            "   ✅ productos: 300 filas\n",
            "   ✅ vendedores: 100 filas\n",
            "   ✅ ventas: 10000 filas\n",
            "   ✅ tickets: 2000 filas\n",
            "   ✅ inventario: 4100 filas\n",
            "   ✅ devoluciones: 800 filas\n",
            "\n",
            "📄 Cargando FAQs...\n",
            "   ✅ FAQs: 3000 registros\n",
            "\n",
            "📝 Cargando reseñas...\n",
            "   📝 Encontrados 2978 archivos .txt\n",
            "   ✅ Reseñas cargadas: 2978 archivos\n",
            "\n",
            "📘 Cargando manuales...\n",
            "   📘 Encontrados 50 archivos .md\n",
            "   ✅ Manuales cargados: 450 secciones\n",
            "\n",
            "📊 Extrayendo metadata...\n",
            "   ✅ Metadata productos:\n",
            "      - 4 categorías\n",
            "      - 17 marcas\n",
            "      - Precios: $28.22 - $2992.33\n",
            "   ✅ Metadata ventas:\n",
            "      - 10000 transacciones\n",
            "      - 23 sucursales\n",
            "      - 8 métodos de pago\n",
            "\n",
            "============================================================\n",
            "RESUMEN DE DATOS CARGADOS\n",
            "============================================================\n",
            "\n",
            "📊 DataFrames (6):\n",
            "   productos       →    300 filas x 14 columnas\n",
            "   vendedores      →    100 filas x 10 columnas\n",
            "   ventas          →  10000 filas x 15 columnas\n",
            "   tickets         →   2000 filas x 17 columnas\n",
            "   inventario      →   4100 filas x 14 columnas\n",
            "   devoluciones    →    800 filas x 14 columnas\n",
            "\n",
            "📄 Documentos no tabulares:\n",
            "   faqs            →   3000 documentos\n",
            "   resenas         →   2978 documentos\n",
            "   manuales        →    450 documentos\n",
            "\n",
            "📈 Total documentos para vectorizar: 6428\n",
            "\n",
            "📊 Metadata extraída: 2 datasets\n",
            "============================================================\n",
            "\n",
            "✅ Datos cargados exitosamente\n",
            "   Acceso: dataframes, documents, metadata\n",
            "\n",
            "Ejemplo de uso:\n",
            "   df_productos = dataframes['productos']\n",
            "   faqs = documents['faqs']\n",
            "   meta_productos = metadata['productos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 4: BASE DE DATOS VECTORIAL CON CHROMADB\n",
        "============================================\n",
        "Implementa los 4 puntos requeridos:\n",
        "1. ChromaDB como base de datos vectorial\n",
        "2. Modelo de embeddings multilenguaje\n",
        "3. Text Splitter con parámetros configurables\n",
        "4. Búsqueda híbrida (Semántica + BM25) + ReRank\n",
        "\"\"\"\n",
        "\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONSTRUYENDO BASE DE DATOS VECTORIAL\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== PUNTO 1: TEXT SPLITTER ====================\n",
        "\n",
        "class DocumentProcessor:\n",
        "    \"\"\"\n",
        "    PUNTO 3: TEXT SPLITTER\n",
        "\n",
        "    Procesa documentos y los divide en chunks con parámetros configurables:\n",
        "    - chunk_size: Tamaño máximo de cada chunk\n",
        "    - chunk_overlap: Solapamiento entre chunks\n",
        "    - separators: Lista jerárquica de separadores\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.chunk_size = config.SPLITTER_CONFIG['chunk_size']\n",
        "        self.chunk_overlap = config.SPLITTER_CONFIG['chunk_overlap']\n",
        "        self.separators = config.SPLITTER_CONFIG['separators']\n",
        "\n",
        "        print(f\"📝 Text Splitter configurado:\")\n",
        "        print(f\"   - Chunk size: {self.chunk_size}\")\n",
        "        print(f\"   - Chunk overlap: {self.chunk_overlap}\")\n",
        "        print(f\"   - Separadores: {self.separators}\")\n",
        "\n",
        "    def split_text(self, text: str) -> List[str]:\n",
        "        \"\"\"Divide texto en chunks con overlap usando separadores jerárquicos\"\"\"\n",
        "        chunks = []\n",
        "\n",
        "        # Intentar dividir por separadores jerárquicos\n",
        "        for separator in self.separators:\n",
        "            if separator in text:\n",
        "                parts = text.split(separator)\n",
        "                current_chunk = \"\"\n",
        "\n",
        "                for part in parts:\n",
        "                    if len(current_chunk) + len(part) < self.chunk_size:\n",
        "                        current_chunk += part + separator\n",
        "                    else:\n",
        "                        if current_chunk:\n",
        "                            chunks.append(current_chunk.strip())\n",
        "                        current_chunk = part + separator\n",
        "\n",
        "                if current_chunk:\n",
        "                    chunks.append(current_chunk.strip())\n",
        "\n",
        "                if chunks:\n",
        "                    return chunks\n",
        "\n",
        "        # Si no hay separadores, dividir por caracteres con overlap\n",
        "        for i in range(0, len(text), self.chunk_size - self.chunk_overlap):\n",
        "            chunk = text[i:i + self.chunk_size]\n",
        "            if chunk.strip():\n",
        "                chunks.append(chunk.strip())\n",
        "\n",
        "        return chunks if chunks else [text]\n",
        "\n",
        "    def prepare_faqs(self, faqs: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"Prepara FAQs con contexto mejorado\"\"\"\n",
        "        documents = []\n",
        "\n",
        "        for faq in faqs:\n",
        "            # Agregar prefijo según categoría para mejor contexto\n",
        "            categoria = faq.get('categoria', '')\n",
        "\n",
        "            if categoria == 'Uso':\n",
        "                prefix = \"INSTRUCCIONES DE USO - \"\n",
        "            elif categoria == 'Problemas Comunes':\n",
        "                prefix = \"SOLUCIÓN DE PROBLEMAS - \"\n",
        "            elif categoria == 'Mantenimiento':\n",
        "                prefix = \"MANTENIMIENTO - \"\n",
        "            elif categoria == 'Garantía':\n",
        "                prefix = \"GARANTÍA - \"\n",
        "            elif categoria == 'Especificaciones':\n",
        "                prefix = \"ESPECIFICACIONES TÉCNICAS - \"\n",
        "            else:\n",
        "                prefix = \"\"\n",
        "\n",
        "            text = f\"{prefix}Pregunta: {faq['pregunta']}\\nRespuesta: {faq['respuesta']}\"\n",
        "\n",
        "            documents.append({\n",
        "                'id': faq['id_faq'],\n",
        "                'text': text,\n",
        "                'metadata': {\n",
        "                    'source': 'faq',\n",
        "                    'id_producto': faq.get('id_producto', ''),\n",
        "                    'nombre_producto': faq.get('nombre_producto', ''),\n",
        "                    'categoria': faq.get('categoria', ''),\n",
        "                    'pregunta': faq['pregunta']\n",
        "                }\n",
        "            })\n",
        "\n",
        "        return documents\n",
        "\n",
        "    def prepare_manuales(self, manuales: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"Prepara manuales divididos en chunks con contexto\"\"\"\n",
        "        documents = []\n",
        "\n",
        "        for idx, manual in enumerate(manuales):\n",
        "            chunks = self.split_text(manual['contenido'])\n",
        "\n",
        "            for chunk_idx, chunk in enumerate(chunks):\n",
        "                doc_id = f\"{manual['id_producto']}_{manual['tipo_seccion']}_{idx}_{chunk_idx}\"\n",
        "\n",
        "                # Agregar prefijos contextuales según tipo\n",
        "                tipo = manual['tipo_seccion']\n",
        "\n",
        "                if tipo == 'procedimientos':\n",
        "                    prefix = \"INSTRUCCIONES DE USO PASO A PASO - \"\n",
        "                elif tipo == 'troubleshooting':\n",
        "                    prefix = \"SOLUCIÓN DE PROBLEMAS - \"\n",
        "                elif tipo == 'especificaciones':\n",
        "                    prefix = \"ESPECIFICACIONES TÉCNICAS - \"\n",
        "                elif tipo == 'mantenimiento':\n",
        "                    prefix = \"MANTENIMIENTO - \"\n",
        "                elif tipo == 'compatibilidad':\n",
        "                    prefix = \"COMPATIBILIDAD Y ACCESORIOS - \"\n",
        "                else:\n",
        "                    prefix = \"\"\n",
        "\n",
        "                text = f\"{prefix}{manual['titulo']}\\n\\n{chunk}\"\n",
        "\n",
        "                documents.append({\n",
        "                    'id': doc_id,\n",
        "                    'text': text,\n",
        "                    'metadata': {\n",
        "                        'source': 'manual',\n",
        "                        'id_producto': manual['id_producto'],\n",
        "                        'tipo_seccion': manual['tipo_seccion'],\n",
        "                        'titulo': manual['titulo'],\n",
        "                        'archivo': manual.get('archivo', '')\n",
        "                    }\n",
        "                })\n",
        "\n",
        "        return documents\n",
        "\n",
        "    def prepare_resenas(self, resenas: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"Prepara reseñas con contexto de opinión\"\"\"\n",
        "        documents = []\n",
        "\n",
        "        for resena in resenas:\n",
        "            text = f\"OPINIÓN DE USUARIO - Reseña:\\n{resena['texto']}\"\n",
        "\n",
        "            documents.append({\n",
        "                'id': resena['id_resena'],\n",
        "                'text': text,\n",
        "                'metadata': {\n",
        "                    'source': 'resena',\n",
        "                    'id_resena': resena['id_resena'],\n",
        "                    'archivo': resena.get('archivo', '')\n",
        "                }\n",
        "            })\n",
        "\n",
        "        return documents\n",
        "\n",
        "# ==================== PUNTO 1: CHROMADB + PUNTO 2: EMBEDDINGS ====================\n",
        "\n",
        "class VectorDatabase:\n",
        "    \"\"\"\n",
        "    PUNTO 1: ChromaDB como base de datos vectorial\n",
        "    PUNTO 2: Modelo de embeddings multilenguaje\n",
        "\n",
        "    Gestiona la base de datos vectorial con:\n",
        "    - ChromaDB para almacenamiento persistente\n",
        "    - Sentence Transformers para embeddings en español\n",
        "    - Cross-Encoder para reranking\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "        # Inicializar ChromaDB\n",
        "        print(\"💾 Inicializando ChromaDB...\")\n",
        "        self.client = chromadb.Client(Settings(\n",
        "            persist_directory=config.CHROMA_CONFIG['persist_directory'],\n",
        "            anonymized_telemetry=False\n",
        "        ))\n",
        "\n",
        "        # PUNTO 2: Cargar modelo de embeddings multilenguaje\n",
        "        print(f\"\\n🧠 Cargando modelo de embeddings...\")\n",
        "        print(f\"   Modelo: {config.EMBEDDING_CONFIG['model_name']}\")\n",
        "        print(f\"   Dispositivo: {config.EMBEDDING_CONFIG['device']}\")\n",
        "        print(f\"   Normalización: {config.EMBEDDING_CONFIG['normalize_embeddings']}\")\n",
        "\n",
        "        self.embedding_model = SentenceTransformer(\n",
        "            config.EMBEDDING_CONFIG['model_name'],\n",
        "            device=config.EMBEDDING_CONFIG['device']\n",
        "        )\n",
        "        print(f\"✅ Modelo de embeddings cargado\")\n",
        "\n",
        "        # Cargar modelo de reranking\n",
        "        print(f\"\\n🔄 Cargando modelo de reranking...\")\n",
        "        self.reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "        print(f\"✅ Modelo de reranking cargado\")\n",
        "\n",
        "        # Eliminar colección existente si existe\n",
        "        try:\n",
        "            self.client.delete_collection(name=config.CHROMA_CONFIG['collection_name'])\n",
        "            print(\"\\n🗑️ Colección anterior eliminada\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Crear nueva colección\n",
        "        print(f\"\\n📦 Creando colección: {config.CHROMA_CONFIG['collection_name']}\")\n",
        "        self.collection = self.client.create_collection(\n",
        "            name=config.CHROMA_CONFIG['collection_name'],\n",
        "            metadata={\"hnsw:space\": config.CHROMA_CONFIG['distance_metric']}\n",
        "        )\n",
        "        print(\"✅ Colección creada\")\n",
        "\n",
        "    def add_documents(self, documents: List[Dict]):\n",
        "        \"\"\"Agrega documentos a la colección con sus embeddings\"\"\"\n",
        "        if not documents:\n",
        "            return\n",
        "\n",
        "        print(f\"\\n📝 Agregando {len(documents)} documentos...\")\n",
        "\n",
        "        # Preparar datos para ChromaDB\n",
        "        ids = [doc['id'] for doc in documents]\n",
        "        texts = [doc['text'] for doc in documents]\n",
        "        metadatas = [doc['metadata'] for doc in documents]\n",
        "\n",
        "        # PUNTO 2: Generar embeddings con el modelo multilenguaje\n",
        "        print(\"🧠 Generando embeddings...\")\n",
        "        embeddings = self.embedding_model.encode(\n",
        "            texts,\n",
        "            show_progress_bar=True,\n",
        "            normalize_embeddings=self.config.EMBEDDING_CONFIG['normalize_embeddings']\n",
        "        ).tolist()\n",
        "\n",
        "        # Agregar a ChromaDB en lotes\n",
        "        batch_size = 100\n",
        "        for i in range(0, len(ids), batch_size):\n",
        "            batch_ids = ids[i:i+batch_size]\n",
        "            batch_embeddings = embeddings[i:i+batch_size]\n",
        "            batch_texts = texts[i:i+batch_size]\n",
        "            batch_metadatas = metadatas[i:i+batch_size]\n",
        "\n",
        "            self.collection.add(\n",
        "                ids=batch_ids,\n",
        "                embeddings=batch_embeddings,\n",
        "                documents=batch_texts,\n",
        "                metadatas=batch_metadatas\n",
        "            )\n",
        "\n",
        "        print(f\"✅ {len(documents)} documentos agregados a ChromaDB\")\n",
        "\n",
        "    def search(self, query: str, top_k: int = 10, filters: Optional[Dict] = None) -> List[Dict]:\n",
        "        \"\"\"Búsqueda semántica en ChromaDB\"\"\"\n",
        "        # Generar embedding de la query\n",
        "        query_embedding = self.embedding_model.encode(\n",
        "            [query],\n",
        "            normalize_embeddings=self.config.EMBEDDING_CONFIG['normalize_embeddings']\n",
        "        ).tolist()[0]\n",
        "\n",
        "        # Preparar filtros (where clause)\n",
        "        where_clause = None\n",
        "        if filters:\n",
        "            where_clause = filters\n",
        "\n",
        "        # Buscar en ChromaDB\n",
        "        results = self.collection.query(\n",
        "            query_embeddings=[query_embedding],\n",
        "            n_results=top_k,\n",
        "            where=where_clause\n",
        "        )\n",
        "\n",
        "        # Formatear resultados\n",
        "        formatted_results = []\n",
        "        for i in range(len(results['ids'][0])):\n",
        "            formatted_results.append({\n",
        "                'id': results['ids'][0][i],\n",
        "                'text': results['documents'][0][i],\n",
        "                'metadata': results['metadatas'][0][i],\n",
        "                'distance': results['distances'][0][i],\n",
        "                'score': 1 - results['distances'][0][i]\n",
        "            })\n",
        "\n",
        "        return formatted_results\n",
        "\n",
        "# ==================== PUNTO 4: BÚSQUEDA HÍBRIDA (BM25) ====================\n",
        "\n",
        "class BM25Search:\n",
        "    \"\"\"\n",
        "    PUNTO 4: Búsqueda por keywords con BM25\n",
        "\n",
        "    Complementa la búsqueda semántica con búsqueda léxica\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.corpus = []\n",
        "        self.documents = []\n",
        "        self.bm25 = None\n",
        "        print(\"🔍 Inicializando BM25 para búsqueda híbrida...\")\n",
        "\n",
        "    def tokenize(self, text: str) -> List[str]:\n",
        "        \"\"\"Tokeniza texto en palabras\"\"\"\n",
        "        text = text.lower()\n",
        "        tokens = re.findall(r'\\b\\w+\\b', text)\n",
        "        return tokens\n",
        "\n",
        "    def index_documents(self, documents: List[Dict]):\n",
        "        \"\"\"Indexa documentos para BM25\"\"\"\n",
        "        print(f\"📚 Indexando {len(documents)} documentos para BM25...\")\n",
        "\n",
        "        self.documents = documents\n",
        "        self.corpus = [self.tokenize(doc['text']) for doc in documents]\n",
        "        self.bm25 = BM25Okapi(self.corpus)\n",
        "\n",
        "        print(\"✅ BM25 indexado\")\n",
        "\n",
        "    def search(self, query: str, top_k: int = 10) -> List[Dict]:\n",
        "        \"\"\"Búsqueda con BM25\"\"\"\n",
        "        if not self.bm25:\n",
        "            return []\n",
        "\n",
        "        tokenized_query = self.tokenize(query)\n",
        "        scores = self.bm25.get_scores(tokenized_query)\n",
        "\n",
        "        # Obtener top-k\n",
        "        top_indices = np.argsort(scores)[::-1][:top_k]\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            if scores[idx] > 0:\n",
        "                results.append({\n",
        "                    'id': self.documents[idx]['id'],\n",
        "                    'text': self.documents[idx]['text'],\n",
        "                    'metadata': self.documents[idx]['metadata'],\n",
        "                    'score': float(scores[idx])\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "# ==================== PUNTO 4: BÚSQUEDA HÍBRIDA + RERANK ====================\n",
        "\n",
        "class HybridSearch:\n",
        "    \"\"\"\n",
        "    PUNTO 4: Búsqueda híbrida (Semántica + BM25) + ReRank\n",
        "\n",
        "    Combina:\n",
        "    1. Búsqueda semántica (ChromaDB + embeddings)\n",
        "    2. Búsqueda léxica (BM25)\n",
        "    3. Fusión de resultados (RRF)\n",
        "    4. Reranking con Cross-Encoder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vector_db: VectorDatabase, bm25_search: BM25Search, config):\n",
        "        self.vector_db = vector_db\n",
        "        self.bm25_search = bm25_search\n",
        "        self.config = config\n",
        "\n",
        "        print(\"\\n🔀 Búsqueda híbrida configurada:\")\n",
        "        print(f\"   - Top-K semántico: {config.HYBRID_SEARCH_CONFIG['semantic_top_k']}\")\n",
        "        print(f\"   - Top-K BM25: {config.HYBRID_SEARCH_CONFIG['bm25_top_k']}\")\n",
        "        print(f\"   - Top-K final (rerank): {config.HYBRID_SEARCH_CONFIG['rerank_top_k']}\")\n",
        "        print(f\"   - Alpha (peso semántico): {config.HYBRID_SEARCH_CONFIG['alpha']}\")\n",
        "\n",
        "    def search(self, query: str, top_k: int = 5, filters: Optional[Dict] = None, auto_filter: bool = True) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Búsqueda híbrida completa con 4 pasos:\n",
        "        1. Búsqueda semántica\n",
        "        2. Búsqueda BM25\n",
        "        3. Fusión RRF\n",
        "        4. Reranking\n",
        "        \"\"\"\n",
        "\n",
        "        # Filtrado inteligente automático\n",
        "        if auto_filter and filters is None:\n",
        "            filters = self._smart_filter(query)\n",
        "\n",
        "        # 1. Búsqueda semántica (70% peso)\n",
        "        semantic_results = self.vector_db.search(\n",
        "            query,\n",
        "            top_k=self.config.HYBRID_SEARCH_CONFIG['semantic_top_k'],\n",
        "            filters=filters\n",
        "        )\n",
        "\n",
        "        # 2. Búsqueda BM25 (30% peso)\n",
        "        bm25_results = self.bm25_search.search(\n",
        "            query,\n",
        "            top_k=self.config.HYBRID_SEARCH_CONFIG['bm25_top_k']\n",
        "        )\n",
        "\n",
        "        # 3. Fusión con RRF\n",
        "        fused_results = self._reciprocal_rank_fusion(\n",
        "            semantic_results,\n",
        "            bm25_results,\n",
        "            alpha=self.config.HYBRID_SEARCH_CONFIG['alpha']\n",
        "        )\n",
        "\n",
        "        # 4. Reranking con Cross-Encoder\n",
        "        reranked_results = self._rerank(query, fused_results, top_k)\n",
        "\n",
        "        return reranked_results\n",
        "\n",
        "    def _smart_filter(self, query: str) -> Optional[Dict]:\n",
        "        \"\"\"Detecta tipo de pregunta y aplica filtros apropiados\"\"\"\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        # Para \"cómo usar\" -> SOLO manuales y FAQs de uso\n",
        "        if any(word in query_lower for word in ['cómo', 'como', 'usar', 'utilizar', 'hacer', 'preparar']):\n",
        "            return {\"source\": {\"$in\": [\"manual\", \"faq\"]}}\n",
        "\n",
        "        # Para \"opinión\" -> SOLO reseñas\n",
        "        if any(word in query_lower for word in ['opinión', 'opinion', 'reseña', 'comentario', 'qué dicen']):\n",
        "            return {\"source\": {\"$in\": [\"resena\"]}}\n",
        "\n",
        "        # Para \"problema\" -> tickets, FAQs y manuales\n",
        "        if any(word in query_lower for word in ['problema', 'no funciona', 'error', 'falla']):\n",
        "            return {\"source\": {\"$in\": [\"ticket\", \"faq\", \"manual\"]}}\n",
        "\n",
        "        # Sin filtro para preguntas generales\n",
        "        return None\n",
        "\n",
        "    def _reciprocal_rank_fusion(self, semantic_results: List[Dict], bm25_results: List[Dict], k: int = 60, alpha: float = 0.7) -> List[Dict]:\n",
        "        \"\"\"Fusiona resultados usando RRF con pesos ajustables\"\"\"\n",
        "        scores = {}\n",
        "        docs = {}\n",
        "\n",
        "        # Procesar resultados semánticos (70%)\n",
        "        for rank, result in enumerate(semantic_results):\n",
        "            doc_id = result['id']\n",
        "            scores[doc_id] = scores.get(doc_id, 0) + alpha * (1 / (k + rank + 1))\n",
        "            docs[doc_id] = result\n",
        "\n",
        "        # Procesar resultados BM25 (30%)\n",
        "        for rank, result in enumerate(bm25_results):\n",
        "            doc_id = result['id']\n",
        "            scores[doc_id] = scores.get(doc_id, 0) + (1 - alpha) * (1 / (k + rank + 1))\n",
        "            if doc_id not in docs:\n",
        "                docs[doc_id] = result\n",
        "\n",
        "        # Ordenar por score fusionado\n",
        "        sorted_ids = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)\n",
        "\n",
        "        fused_results = []\n",
        "        for doc_id in sorted_ids:\n",
        "            result = docs[doc_id].copy()\n",
        "            result['fusion_score'] = scores[doc_id]\n",
        "            fused_results.append(result)\n",
        "\n",
        "        return fused_results\n",
        "\n",
        "    def _rerank(self, query: str, results: List[Dict], top_k: int) -> List[Dict]:\n",
        "        \"\"\"Reordena resultados con cross-encoder\"\"\"\n",
        "        if not results:\n",
        "            return []\n",
        "\n",
        "        # Preparar pares query-documento\n",
        "        pairs = [[query, result['text']] for result in results]\n",
        "\n",
        "        # Calcular scores con cross-encoder\n",
        "        rerank_scores = self.vector_db.reranker.predict(pairs)\n",
        "\n",
        "        # Agregar scores y reordenar\n",
        "        for i, result in enumerate(results):\n",
        "            result['rerank_score'] = float(rerank_scores[i])\n",
        "\n",
        "        # Ordenar por rerank_score\n",
        "        reranked = sorted(results, key=lambda x: x['rerank_score'], reverse=True)\n",
        "\n",
        "        return reranked[:top_k]\n",
        "\n",
        "# ==================== CONSTRUCCIÓN DEL SISTEMA ====================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PROCESANDO Y VECTORIZANDO DOCUMENTOS\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# 1. Inicializar procesador de documentos\n",
        "processor = DocumentProcessor(config)\n",
        "\n",
        "# 2. Preparar todos los documentos\n",
        "print(\"\\n📄 Preparando documentos...\")\n",
        "all_documents = []\n",
        "\n",
        "all_documents.extend(processor.prepare_faqs(documents['faqs']))\n",
        "print(f\"✅ FAQs preparados: {len(documents['faqs'])}\")\n",
        "\n",
        "all_documents.extend(processor.prepare_manuales(documents['manuales']))\n",
        "print(f\"✅ Manuales preparados: {len(documents['manuales'])}\")\n",
        "\n",
        "all_documents.extend(processor.prepare_resenas(documents['resenas']))\n",
        "print(f\"✅ Reseñas preparadas: {len(documents['resenas'])}\")\n",
        "\n",
        "print(f\"\\n📊 Total documentos a indexar: {len(all_documents)}\")\n",
        "\n",
        "# 3. Inicializar bases de datos\n",
        "vector_db = VectorDatabase(config)\n",
        "bm25_search = BM25Search()\n",
        "\n",
        "# 4. Indexar documentos\n",
        "vector_db.add_documents(all_documents)\n",
        "bm25_search.index_documents(all_documents)\n",
        "\n",
        "# 5. Crear búsqueda híbrida\n",
        "hybrid_search = HybridSearch(vector_db, bm25_search, config)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ BASE DE DATOS VECTORIAL COMPLETA\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\"\"\n",
        "✅ PUNTO 1: ChromaDB configurado\n",
        "   - Colección: {config.CHROMA_CONFIG['collection_name']}\n",
        "   - Documentos: {len(all_documents)}\n",
        "   - Distancia: {config.CHROMA_CONFIG['distance_metric']}\n",
        "\n",
        "✅ PUNTO 2: Embeddings multilenguaje\n",
        "   - Modelo: {config.EMBEDDING_CONFIG['model_name']}\n",
        "   - Normalización: {config.EMBEDDING_CONFIG['normalize_embeddings']}\n",
        "\n",
        "✅ PUNTO 3: Text Splitter configurado\n",
        "   - Chunk size: {config.SPLITTER_CONFIG['chunk_size']}\n",
        "   - Chunk overlap: {config.SPLITTER_CONFIG['chunk_overlap']}\n",
        "\n",
        "✅ PUNTO 4: Búsqueda híbrida + ReRank\n",
        "   - Semántica (ChromaDB) + BM25\n",
        "   - Fusión RRF (alpha={config.HYBRID_SEARCH_CONFIG['alpha']})\n",
        "   - ReRank con Cross-Encoder\n",
        "\n",
        "🔍 Interfaz de búsqueda:\n",
        "   hybrid_search.search(query, top_k=5)\n",
        "\"\"\")\n",
        "print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9a77072696e64e8e8d12efc02f0d6a02",
            "6d4cff085a9345248ee51803b58223dc",
            "0376a249c436418ea9260a4a796f79eb",
            "c3360bd1d321482fa3f0001707c4c0c6",
            "d6a26714e41b4f23b19346467775eb9a",
            "73f4194c2ab04196885e678ac6d1946f",
            "da92741191c54fd7ad3899f1cf2b7b8a",
            "743967ae99004a7aa8b226ab0fc5986c",
            "99cf9919102c451c93c66cab3f2df170",
            "67a184c39af74864bc403ec0d6bc00a0",
            "343de6a8a7534a979b9025c818a3e01c",
            "330ee34d7ada4298aaf2271b4683a3c6",
            "a827a615f0c3438ea16dfceca5e7ffea",
            "e829d05bc5ba418aa698b0360860dda2",
            "3bad55727a5d4131bc29c8c5c7e5526e",
            "6a8b1e11ae4a466995a4e58c756495b6",
            "f1dee0275dd94b6aa74a3fc930679888",
            "a76eb6d25c8d4effb97581130b377b3f",
            "ef51da9386274f35a21360e76a5d94fe",
            "2744adfd449b4917ac4cebc199b59e87",
            "63149334640a4c7aae2e732b717b0738",
            "f0bb8e77c72841c1862c7f4275425482",
            "c1946f47c7be41cb9beb75eb887ea618",
            "0b19c5fad8624c0097cdc2455408bcc6",
            "a6b40dd1a6a14ff2ad608a6a0bd935ea",
            "91a030c55aeb42d0b084ee26e2685f96",
            "316aecd84a624974ae79dd61a81e0c06",
            "3e987a331ee342ff8d715328e3904a3d",
            "1f46ed11fcd04a59b307bfbfc8497a55",
            "d39ced911e3140238b9a09d38f95ab2f",
            "2576fe68d8dc4f218ae5481ddb8293ec",
            "fd56263b33f74e3bbb36de7faa6e7602",
            "d420220112134725915c449166c74f11",
            "6948afe6595b4b74b92e893eac8d3586",
            "dbcd65739e714167874b1223e82fc36a",
            "c3eb31df80494cc7b403881b10247e9b",
            "c4f3f022f45b4ff3ba5eb686ce0b12e0",
            "4d5bd6dcae844e899d12013f0b8115dd",
            "c7841723427c45629b80bd4ae6198586",
            "f663edc47bf3460394d0a7a9f9d4bcff",
            "c760b783f5524c9180367ec961533c67",
            "7d43ccc3e12f4d6ba7e2685b0ab1dcf7",
            "d1bddf909aa844ce8cda761a53ee9d70",
            "2503e1ab7e564a289ad2a7fb7cc7c096",
            "0a094b339d134366b7ddac98e2107bb1",
            "65e63b1fdec94885819028f47ec95caa",
            "6909d1ea5eca443896d0341980be9210",
            "a9ca4991b24042c7bc83f842517dd434",
            "d0526c08f02d4d669c2e91e2489078a3",
            "e23c5dc5404a4b5e93a1f760cbe15dbf",
            "81778570e34a4494a3ac81998373ec6c",
            "2340e4965225403ea850e99c9e7b0edb",
            "e068868cffd541a896c30d6c594c1baf",
            "3d3aa191d57241e59d6cbb3e3735cf0c",
            "1a53b60a13e146dbaca8a3a01c00aaf1",
            "e437b6e825d249c08c4f39573f10dcd1",
            "ce9964e21b604591a4e018d598f4b8d3",
            "8b1606d87e5d4bdea294f39a209aadac",
            "523ddc726e58403d855b03a84348883f",
            "3a513294ec5a4fbeacde6dae328714b1",
            "9cbdf128fc9c4fe7916d70d91f6fa9e4",
            "ba7471cc66044c0a89d8a56d3e6946f5",
            "1f92517fc83644939de7cbf5d4576c7c",
            "39796df35d284085b9c936376750c3a1",
            "e09078f30da5451f9ec4b92963414057",
            "b5889643ae3446c5a007395b0a7777de",
            "3d62aaa85a0e4aa6b5f20ca60f2b68bb",
            "608c0742d7344bfa83b27ff07301b74b",
            "8750513096754bb29a57e8e2715b1c19",
            "5f6d955ed09440b69f765cfd4f3ea127",
            "4061f04aeaa34bf9a1bc08750b295c96",
            "a97ac15b482e4be8b443c1e1f406f6c7",
            "1f161adbf72c4e0f81671860fd3d88b6",
            "652ae76a3e554b3da41048a986691ab7",
            "e37ad39bd6164200b0f0e8f628c2bd52",
            "2dfc321099fe44d3bb9f170e473bec82",
            "598214d951614dfab07ec5d27d22a584",
            "bc4e7ef74833492eb17313c15b082be8",
            "3a323074c5c64a30b26b9d8845dd3a93",
            "0d20558c1a9a4793bffa0edb3b303569",
            "96725e66e73e4c7cb7ecc614c3e7c17f",
            "96435fc1cdb3465e86b1bac10b4d3d8c",
            "6d2c8d45d29e47df8c3140f1b587ccf6",
            "38a3b59566414ae2abcc3550535ec265",
            "8a03b275305f4d1688a872edbd9fee3d",
            "b179680ce937450f9d5fea97058a9989",
            "59bbb36fee8d46f28edcfc346edaa31a",
            "aa127e522f674d4d8e715e4c996a5538",
            "0e26b7d8101646d9819855504a7b9209",
            "4e7f9b1a782c49458bbaba09692d3787",
            "a4cd5b7f61094dd89407c9e5021ba561",
            "bf5f8474d21c42f8a281404eb849a277",
            "0d9cf4eae325490aa0ec9e7720863c1a",
            "d5eef243a00b417cbd6cdda0245acf6f",
            "11b104213f4142bcb586baf12e167c09",
            "862154c055634bccab2942dc612fec3f",
            "59ccd13fd3a046679a69f434c807782e",
            "b53c3e3bcaaa477bb5ef564d97b5fb16",
            "4b526812ecb142ccaf0960d331437a0f",
            "d94e9b2e7e6c44678b27aa80d1b7e249",
            "fc02a195684b4d42a79d31e5a582539d",
            "4c102d68e2734f548c9b5d1ab00f21d4",
            "ea68b4c522e8457bb6d4a1fa580e13dc",
            "0fdc6e9d5327496b93b08ceaf129dd07",
            "3a71807fdb27491f86a0b6c3de37ea68",
            "fb474713f7284cf189a1778b0548182a",
            "1e113b2778754fe6bb6a0c5bea00de2c",
            "7604b92b30e146278f9d20aa87f65e5f",
            "b2c15fde744b404d8716ecfc8ed2ef1e",
            "6e05088801bb4049849afc6552b904ee",
            "97fa9fcea7224847b2ce85e23a747090",
            "4037165ffe0b41c087088897efafd4a6",
            "17146fbc2a3e4cbca49adb5ebe8cb0df",
            "80abd70b7c204d91b75fd9d27f1ad399",
            "9a11569393864849ac6a6ba022d74832",
            "af56e6dcd32245cf9f57550b80109436",
            "b5dc9e71b16c4ac1819a75da05fe7a1b",
            "5963d9d5a9d9433390d861cc8f31a8fb",
            "0ac7ec9959f446c7a2726e6381632efb",
            "dc6469c9b6e0476686f9b53c8243c44e",
            "509081e364474627bdfa4f82ab285e28",
            "54673bb2846b4c01853f2ab60734692b",
            "9bd98dd24c8545b5b848afb73b072478",
            "c5d032034a81493688a23a17cd5673a5",
            "3dcb9827d4304a27b6c45271ded60985",
            "2ff4537fda4b43948782e0d2a86cafa8",
            "e1a633a3e9a547a8a919ccd15924845c",
            "9300e8a5909b4f0189c5d584257c9c8f",
            "295fa1b9b1084380bae98f24d2c15ed3",
            "fe32a13348e3471c8df81ba21f496fc8",
            "b144861404d847d7a9923960cd760627",
            "80eea4fe0e4e42a7959ba5c50de6c884",
            "5ac754cf828a45b6ba205a2c1c50455f",
            "2c3669327a2f45d3b3d2eb60239ec6c3",
            "d483f8fb5da544edbd17c15d9a84b711",
            "ad6d0c8da4c04a91a39aaa213ab1704b",
            "c53dc526224f4a28b3d4d78b6b00a5b0",
            "9e5b484e1b5743bc8008456509123e82",
            "5523e4cde7114d6e904838f778cd4d9b",
            "bb469a196cc647d7a1bcf3f257718d79",
            "b96a4de56d544e45a3767b5f666ada31",
            "55c6e7dff4184f2c9eeb545f1892b338",
            "2e827e69891e419681b58a180535e87e",
            "b3056d3fe4624741877b789b48b9038a",
            "91edab52d19d4d0882b569bc6aff0916",
            "fede74ad35e54b2bb4e73e49425e44ec",
            "14e71fcc89f44a44b7871d790c03fe05",
            "3be02c0782d7423fbd3e79a2a46495c5",
            "25f78db229954ff1a5e80fa3fb00baa8",
            "5cc0d505d4e1470fa40c1ee7ab645fc1",
            "56b5d0e50a344222b18abd8503f5fdb2",
            "9d143908d82c4cea80be9f22e57cc972",
            "2c660381386f4953ad7aa8cc6fc97a18",
            "26be313acece487faa7f8997164c9be0",
            "95d799bfc8f340e69e3318e8b04a4264",
            "4c1e923f78294a308dee4c18f6a8fa0d",
            "0ff92b7445334b19bb87b804c21fdaaf",
            "88e6621f2a694fdbbbb7349a3eb18b45",
            "31b6ff07ed6a46f1b0359684c512476f",
            "0190c1495b3b42f38c9064e7917215e0",
            "a49f93c5fe7042908feeb35a7757e356",
            "b6b080ebb10f4c99a16f8f3ebf275220",
            "ce84a55c6046486a9cdb7102f9b9e283",
            "89fbeb7321b9423d89417ea7a3aa2696",
            "5906f7da2f6e4b089c7285c57b687849",
            "8e75444baf124147be779f9397d145ef",
            "2b106066014a4cce93ee8899ccc83435",
            "c1a455e80ecc49289be48ea78329abb3",
            "be9ce6a1879647c3868d591daa3dc413",
            "065134508e344c13858d581cdc37950f",
            "e7349f1abae6419aa238cbb893a18862",
            "5b99d868617648259df41d4fe5e1c6f6",
            "5a411d9cfad8411491e7ba3f48b92ff2",
            "34c4d86391be4e0dbd92a64ef1f7c80e",
            "92b3f2e2d57942d281b0e13f74ece5bb",
            "d67eea6347a840d2b23a4b1df413d02f",
            "ca63a8efae9147fab0dcd552762c6827",
            "dbe0254f5c654745a97e05b642b78aa2",
            "744b871a5b824b108ff4bc5411f16bea",
            "9794ffbd53644e20aae3fd7b352f4fdd",
            "f6431a15ffd44b9283b08530617ddf23",
            "65b3345330ec49708c516a3832c0bf83",
            "32fd11910e9e4030a350cb9c02b9281d",
            "8c240399e3534d25982ae05b2f18fbeb",
            "f305b22bf27c495fb9582aa9fbd60e43",
            "4c4c285fd9214da0bc8992b4eafb1fc2",
            "89105d78fd8d44a5b8fb3678a4fb8e3d",
            "505eaa2e48924177a85e5e59a7f76bad",
            "eb178277f87c4ca8b7d6da97a38b5c2c",
            "a63f6d37ab474402af1685b9c0caa38c",
            "dc88fd584fb84ef7b1235d217e416e6b",
            "bf458c9be5054f01afcc956a5b7d9493",
            "2f7cc1554247455c8e2ac3c2c928c024",
            "d46ec53d63d84133bebeea2b65d3be8b",
            "0850a1bc0abe41dabb6ec6638fe79183",
            "26e4858a7219469393dbe7526a64f2c1",
            "31e9581c1a954a838f13784a9d9f3ba6",
            "3a313ed2644245059695fc332745b24d"
          ]
        },
        "id": "ZuRX3H8N55S_",
        "outputId": "34f2f214-2973-4bef-ee3d-a1337d7ed0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CONSTRUYENDO BASE DE DATOS VECTORIAL\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "PROCESANDO Y VECTORIZANDO DOCUMENTOS\n",
            "============================================================\n",
            "\n",
            "📝 Text Splitter configurado:\n",
            "   - Chunk size: 400\n",
            "   - Chunk overlap: 50\n",
            "   - Separadores: ['\\n\\n', '\\n', '. ', ' ', '']\n",
            "\n",
            "📄 Preparando documentos...\n",
            "✅ FAQs preparados: 3000\n",
            "✅ Manuales preparados: 450\n",
            "✅ Reseñas preparadas: 2978\n",
            "\n",
            "📊 Total documentos a indexar: 7122\n",
            "💾 Inicializando ChromaDB...\n",
            "\n",
            "🧠 Cargando modelo de embeddings...\n",
            "   Modelo: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
            "   Dispositivo: cpu\n",
            "   Normalización: True\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a77072696e64e8e8d12efc02f0d6a02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "330ee34d7ada4298aaf2271b4683a3c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1946f47c7be41cb9beb75eb887ea618"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6948afe6595b4b74b92e893eac8d3586"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a094b339d134366b7ddac98e2107bb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e437b6e825d249c08c4f39573f10dcd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d62aaa85a0e4aa6b5f20ca60f2b68bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc4e7ef74833492eb17313c15b082be8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e26b7d8101646d9819855504a7b9209"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d94e9b2e7e6c44678b27aa80d1b7e249"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo de embeddings cargado\n",
            "\n",
            "🔄 Cargando modelo de reranking...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97fa9fcea7224847b2ce85e23a747090"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54673bb2846b4c01853f2ab60734692b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ac754cf828a45b6ba205a2c1c50455f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3056d3fe4624741877b789b48b9038a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95d799bfc8f340e69e3318e8b04a4264"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e75444baf124147be779f9397d145ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca63a8efae9147fab0dcd552762c6827"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo de reranking cargado\n",
            "\n",
            "📦 Creando colección: electrodomesticos_docs\n",
            "✅ Colección creada\n",
            "🔍 Inicializando BM25 para búsqueda híbrida...\n",
            "\n",
            "📝 Agregando 7122 documentos...\n",
            "🧠 Generando embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/223 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "505eaa2e48924177a85e5e59a7f76bad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 7122 documentos agregados a ChromaDB\n",
            "📚 Indexando 7122 documentos para BM25...\n",
            "✅ BM25 indexado\n",
            "\n",
            "🔀 Búsqueda híbrida configurada:\n",
            "   - Top-K semántico: 20\n",
            "   - Top-K BM25: 20\n",
            "   - Top-K final (rerank): 5\n",
            "   - Alpha (peso semántico): 0.7\n",
            "\n",
            "============================================================\n",
            "✅ BASE DE DATOS VECTORIAL COMPLETA\n",
            "============================================================\n",
            "\n",
            "✅ PUNTO 1: ChromaDB configurado\n",
            "   - Colección: electrodomesticos_docs\n",
            "   - Documentos: 7122\n",
            "   - Distancia: cosine\n",
            "\n",
            "✅ PUNTO 2: Embeddings multilenguaje\n",
            "   - Modelo: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
            "   - Normalización: True\n",
            "\n",
            "✅ PUNTO 3: Text Splitter configurado\n",
            "   - Chunk size: 400\n",
            "   - Chunk overlap: 50\n",
            "\n",
            "✅ PUNTO 4: Búsqueda híbrida + ReRank\n",
            "   - Semántica (ChromaDB) + BM25\n",
            "   - Fusión RRF (alpha=0.7)\n",
            "   - ReRank con Cross-Encoder\n",
            "\n",
            "🔍 Interfaz de búsqueda:\n",
            "   hybrid_search.search(query, top_k=5)\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 5: PRUEBAS DE LA BASE VECTORIAL\n",
        "============================================\n",
        "Pruebas para verificar el correcto funcionamiento\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PRUEBAS DE LA BASE DE DATOS VECTORIAL\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== PRUEBA 1: BÚSQUEDA SIMPLE ====================\n",
        "\n",
        "print(\"📝 PRUEBA 1: Búsqueda simple\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "test_query = \"¿Cómo uso mi licuadora para hacer smoothies?\"\n",
        "print(f\"Query: '{test_query}'\\n\")\n",
        "\n",
        "results = hybrid_search.search(test_query, top_k=3)\n",
        "\n",
        "print(f\"Resultados encontrados: {len(results)}\\n\")\n",
        "\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"{i}. [{result['metadata']['source'].upper()}]\")\n",
        "    print(f\"   Score: {result['rerank_score']:.4f}\")\n",
        "    print(f\"   Texto: {result['text'][:150]}...\")\n",
        "    if 'id_producto' in result['metadata']:\n",
        "        print(f\"   Producto: {result['metadata'].get('id_producto', 'N/A')}\")\n",
        "    print()\n",
        "\n",
        "# ==================== PRUEBA 2: DIFERENTES TIPOS DE CONSULTAS ====================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 2: Diferentes tipos de consultas\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "test_queries = [\n",
        "    \"¿Qué opinan los usuarios de las licuadoras?\",\n",
        "    \"Mi licuadora no enciende, ¿qué hago?\",\n",
        "    \"¿Cómo se limpia el filtro de la cafetera?\",\n",
        "]\n",
        "\n",
        "for test_query in test_queries:\n",
        "    print(f\"Query: '{test_query}'\")\n",
        "    results = hybrid_search.search(test_query, top_k=2)\n",
        "    print(f\"Resultados: {len(results)}\")\n",
        "\n",
        "    if results:\n",
        "        top_result = results[0]\n",
        "        print(f\"  → Top resultado: [{top_result['metadata']['source'].upper()}]\")\n",
        "        print(f\"    Score: {top_result['rerank_score']:.4f}\")\n",
        "        print(f\"    Preview: {top_result['text'][:100]}...\")\n",
        "    print()\n",
        "\n",
        "# ==================== PRUEBA 3: VERIFICAR FILTROS AUTOMÁTICOS ====================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 3: Filtros automáticos por tipo de pregunta\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Test filtros automáticos\n",
        "test_cases = [\n",
        "    (\"¿Cómo usar mi procesadora?\", \"manual/faq\"),\n",
        "    (\"¿Qué opinan de este producto?\", \"resena\"),\n",
        "    (\"Mi producto tiene un problema\", \"ticket/faq/manual\")\n",
        "]\n",
        "\n",
        "for query, expected_source in test_cases:\n",
        "    print(f\"Query: '{query}'\")\n",
        "    print(f\"Fuente esperada: {expected_source}\")\n",
        "\n",
        "    results = hybrid_search.search(query, top_k=3)\n",
        "    if results:\n",
        "        actual_sources = [r['metadata']['source'] for r in results]\n",
        "        print(f\"Fuentes obtenidas: {set(actual_sources)}\")\n",
        "    print()\n",
        "\n",
        "# ==================== PRUEBA 4: ESTADÍSTICAS DEL SISTEMA ====================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 ESTADÍSTICAS DEL SISTEMA\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Contar documentos por fuente\n",
        "sources_count = {}\n",
        "for doc in all_documents:\n",
        "    source = doc['metadata']['source']\n",
        "    sources_count[source] = sources_count.get(source, 0) + 1\n",
        "\n",
        "print(\"Documentos por fuente:\")\n",
        "for source, count in sorted(sources_count.items()):\n",
        "    print(f\"  {source:10s}: {count:4d} documentos\")\n",
        "\n",
        "print(f\"\\nTotal: {len(all_documents)} documentos indexados\")\n",
        "\n",
        "# Información del modelo\n",
        "print(f\"\\n🧠 Modelo de embeddings:\")\n",
        "print(f\"  Nombre: {config.EMBEDDING_CONFIG['model_name']}\")\n",
        "print(f\"  Dimensión: {vector_db.embedding_model.get_sentence_embedding_dimension()}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ TODAS LAS PRUEBAS COMPLETADAS\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== FUNCIÓN DE BÚSQUEDA INTERACTIVA ====================\n",
        "\n",
        "def buscar(query: str, top_k: int = 5, mostrar_texto: bool = True):\n",
        "    \"\"\"\n",
        "    Función helper para hacer búsquedas rápidas\n",
        "\n",
        "    Args:\n",
        "        query: Consulta en lenguaje natural\n",
        "        top_k: Número de resultados a devolver\n",
        "        mostrar_texto: Si True, muestra el texto completo\n",
        "    \"\"\"\n",
        "    print(f\"\\n🔍 Buscando: '{query}'\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    results = hybrid_search.search(query, top_k=top_k)\n",
        "\n",
        "    print(f\"\\n📊 Encontrados {len(results)} resultados:\\n\")\n",
        "\n",
        "    for i, result in enumerate(results, 1):\n",
        "        print(f\"{i}. [{result['metadata']['source'].upper()}] Score: {result['rerank_score']:.4f}\")\n",
        "\n",
        "        if 'id_producto' in result['metadata'] and result['metadata']['id_producto']:\n",
        "            print(f\"   Producto: {result['metadata']['id_producto']}\")\n",
        "\n",
        "        if mostrar_texto:\n",
        "            text = result['text']\n",
        "            if len(text) > 200:\n",
        "                text = text[:200] + \"...\"\n",
        "            print(f\"   {text}\")\n",
        "\n",
        "        print()\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"✅ Función de búsqueda lista: buscar('tu consulta', top_k=5)\")\n",
        "print(\"\\nEjemplo de uso:\")\n",
        "print(\"  results = buscar('¿Cómo hacer smoothies?', top_k=3)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9FQnj279jgo",
        "outputId": "d7775fbe-8d2f-4274-e117-3ffed68a26ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PRUEBAS DE LA BASE DE DATOS VECTORIAL\n",
            "============================================================\n",
            "\n",
            "📝 PRUEBA 1: Búsqueda simple\n",
            "------------------------------------------------------------\n",
            "Query: '¿Cómo uso mi licuadora para hacer smoothies?'\n",
            "\n",
            "Resultados encontrados: 3\n",
            "\n",
            "1. [FAQ]\n",
            "   Score: 1.6231\n",
            "   Texto: INSTRUCCIONES DE USO - Pregunta: ¿Cómo se usa correctamente este producto?\n",
            "Respuesta: El Licuadora de TechHome está diseñado para uso doméstico. Revis...\n",
            "   Producto: P0001\n",
            "\n",
            "2. [FAQ]\n",
            "   Score: 1.6231\n",
            "   Texto: INSTRUCCIONES DE USO - Pregunta: ¿Cómo se usa correctamente este producto?\n",
            "Respuesta: El Licuadora de TechHome está diseñado para uso doméstico. Revis...\n",
            "   Producto: P0001\n",
            "\n",
            "3. [FAQ]\n",
            "   Score: 1.6014\n",
            "   Texto: INSTRUCCIONES DE USO - Pregunta: ¿Cómo se usa correctamente este producto?\n",
            "Respuesta: El Compacto Licuadora de ChefMaster está diseñado para uso domés...\n",
            "   Producto: P0004\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 2: Diferentes tipos de consultas\n",
            "============================================================\n",
            "\n",
            "Query: '¿Qué opinan los usuarios de las licuadoras?'\n",
            "Resultados: 2\n",
            "  → Top resultado: [RESENA]\n",
            "    Score: 3.1803\n",
            "    Preview: OPINIÓN DE USUARIO - Reseña:\n",
            "Fecha: 2024-09-23\n",
            "Usuario: Matías_Hernández\n",
            "Teléfono: +54 9 140 3090-49...\n",
            "\n",
            "Query: 'Mi licuadora no enciende, ¿qué hago?'\n",
            "Resultados: 2\n",
            "  → Top resultado: [FAQ]\n",
            "    Score: 7.5931\n",
            "    Preview: SOLUCIÓN DE PROBLEMAS - Pregunta: ¿Qué hago si no enciende?\n",
            "Respuesta: Si su Licuadora no enciende: ...\n",
            "\n",
            "Query: '¿Cómo se limpia el filtro de la cafetera?'\n",
            "Resultados: 2\n",
            "  → Top resultado: [FAQ]\n",
            "    Score: 8.0999\n",
            "    Preview: MANTENIMIENTO - Pregunta: ¿Cómo se limpia?\n",
            "Respuesta: Para limpiar el Cafetera, desconéctelo primero...\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 3: Filtros automáticos por tipo de pregunta\n",
            "============================================================\n",
            "\n",
            "Query: '¿Cómo usar mi procesadora?'\n",
            "Fuente esperada: manual/faq\n",
            "Fuentes obtenidas: {'resena', 'faq'}\n",
            "\n",
            "Query: '¿Qué opinan de este producto?'\n",
            "Fuente esperada: resena\n",
            "Fuentes obtenidas: {'faq'}\n",
            "\n",
            "Query: 'Mi producto tiene un problema'\n",
            "Fuente esperada: ticket/faq/manual\n",
            "Fuentes obtenidas: {'resena'}\n",
            "\n",
            "\n",
            "============================================================\n",
            "📊 ESTADÍSTICAS DEL SISTEMA\n",
            "============================================================\n",
            "\n",
            "Documentos por fuente:\n",
            "  faq       : 3000 documentos\n",
            "  manual    : 1144 documentos\n",
            "  resena    : 2978 documentos\n",
            "\n",
            "Total: 7122 documentos indexados\n",
            "\n",
            "🧠 Modelo de embeddings:\n",
            "  Nombre: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
            "  Dimensión: 384\n",
            "\n",
            "============================================================\n",
            "✅ TODAS LAS PRUEBAS COMPLETADAS\n",
            "============================================================\n",
            "\n",
            "✅ Función de búsqueda lista: buscar('tu consulta', top_k=5)\n",
            "\n",
            "Ejemplo de uso:\n",
            "  results = buscar('¿Cómo hacer smoothies?', top_k=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 6: BASE DE DATOS TABULAR\n",
        "============================================\n",
        "Implementa consultas dinámicas a datos tabulares usando LLM (GROQ)\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "from typing import Dict, List, Optional, Any\n",
        "from groq import Groq\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONFIGURANDO BASE DE DATOS TABULAR\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== GENERADOR DE FILTROS CON LLM ====================\n",
        "\n",
        "class TableFilterGenerator:\n",
        "    \"\"\"\n",
        "    Genera filtros dinámicos para pandas usando GROQ\n",
        "    Convierte lenguaje natural a expresiones de filtrado\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, metadata: Dict):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "        self.metadata = metadata\n",
        "\n",
        "        print(\"🤖 Generador de filtros inicializado\")\n",
        "        print(f\"   Modelo: llama-3.3-70b-versatile\")\n",
        "\n",
        "    def generate_filter(self, query: str, table_name: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Genera filtros a partir de lenguaje natural\n",
        "\n",
        "        Args:\n",
        "            query: Consulta en lenguaje natural\n",
        "            table_name: Nombre de la tabla (productos, ventas, etc)\n",
        "\n",
        "        Returns:\n",
        "            Dict con filtros y operaciones\n",
        "        \"\"\"\n",
        "\n",
        "        # Obtener metadata de la tabla\n",
        "        table_metadata = self.metadata.get(table_name, {})\n",
        "\n",
        "        # Construir prompt con información de la tabla\n",
        "        prompt = self._build_filter_prompt(query, table_name, table_metadata)\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"llama-3.3-70b-versatile\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"\"\"Eres un experto en generar filtros para pandas DataFrames.\n",
        "\n",
        "IMPORTANTE:\n",
        "- Responde SOLO con un objeto JSON válido\n",
        "- NO uses markdown (```json)\n",
        "- NO agregues explicaciones\n",
        "- Para búsquedas de texto usa \"contains\" (no ==)\n",
        "- Para rangos de precio/números usa <, >, <=, >=\n",
        "\n",
        "Estructura del JSON:\n",
        "{\n",
        "    \"filters\": [\n",
        "        {\"column\": \"nombre_columna\", \"operator\": \"==|>|<|>=|<=|contains|in\", \"value\": valor}\n",
        "    ],\n",
        "    \"sort_by\": \"columna\",\n",
        "    \"ascending\": true,\n",
        "    \"limit\": 20\n",
        "}\n",
        "\n",
        "EJEMPLOS:\n",
        "- \"licuadoras de menos de $200\" → {\"filters\": [{\"column\": \"nombre\", \"operator\": \"contains\", \"value\": \"Licuadora\"}, {\"column\": \"precio_usd\", \"operator\": \"<\", \"value\": 200}]}\n",
        "- \"productos TechHome\" → {\"filters\": [{\"column\": \"marca\", \"operator\": \"==\", \"value\": \"TechHome\"}]}\n",
        "- \"garantía mayor a 24 meses\" → {\"filters\": [{\"column\": \"garantia_meses\", \"operator\": \">\", \"value\": 24}]}\n",
        "\n",
        "IMPORTANTE para tabla 'productos':\n",
        "- Para buscar tipo de producto (licuadora, cafetera, etc) usar columna \"nombre\" o \"subcategoria\"\n",
        "- La columna \"categoria\" solo tiene: Cocina, Climatización, Lavado, Audio y Video\"\"\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": prompt\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0.1,\n",
        "                max_tokens=500\n",
        "            )\n",
        "\n",
        "            # Extraer respuesta\n",
        "            result = response.choices[0].message.content.strip()\n",
        "\n",
        "            # Limpiar markdown si existe\n",
        "            result = result.replace('```json', '').replace('```', '').strip()\n",
        "\n",
        "            # Parsear JSON\n",
        "            filters = json.loads(result)\n",
        "\n",
        "            return filters\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error generando filtros: {e}\")\n",
        "            return {\"filters\": []}\n",
        "\n",
        "    def _build_filter_prompt(self, query: str, table_name: str, metadata: Dict) -> str:\n",
        "        \"\"\"Construye el prompt con información de la tabla\"\"\"\n",
        "\n",
        "        prompt = f\"\"\"Tabla: {table_name}\n",
        "\n",
        "Información de la tabla:\n",
        "\"\"\"\n",
        "\n",
        "        if 'columnas' in metadata:\n",
        "            prompt += f\"Columnas disponibles: {', '.join(metadata['columnas'])}\\n\"\n",
        "\n",
        "        if table_name == 'productos':\n",
        "            prompt += f\"\"\"\n",
        "Valores únicos importantes:\n",
        "- Categorías: {metadata.get('categorias_unicas', [])}\n",
        "- Marcas: {metadata.get('marcas_unicas', [])}\n",
        "- Colores: {metadata.get('colores_disponibles', [])}\n",
        "- Voltajes: {metadata.get('voltajes_disponibles', [])}\n",
        "- Rango de precios: ${metadata.get('precio_min', 0):.2f} - ${metadata.get('precio_max', 0):.2f}\n",
        "- Rango de garantía: {metadata.get('garantia_min', 0)} - {metadata.get('garantia_max', 0)} meses\n",
        "- Rango de potencia: {metadata.get('potencia_min', 0)} - {metadata.get('potencia_max', 0)} W\n",
        "\"\"\"\n",
        "\n",
        "        elif table_name == 'ventas':\n",
        "            prompt += f\"\"\"\n",
        "Valores únicos importantes:\n",
        "- Métodos de pago: {metadata.get('metodos_pago', [])}\n",
        "- Sucursales: {metadata.get('sucursales', [])}\n",
        "- Provincias: {metadata.get('provincias', [])}\n",
        "- Rango de fechas: {metadata.get('fecha_min', '')} - {metadata.get('fecha_max', '')}\n",
        "- Rango de totales: ${metadata.get('total_min', 0):.2f} - ${metadata.get('total_max', 0):.2f}\n",
        "\"\"\"\n",
        "\n",
        "        prompt += f\"\"\"\n",
        "Consulta del usuario: \"{query}\"\n",
        "\n",
        "Genera los filtros apropiados en formato JSON.\n",
        "Operadores disponibles: ==, >, <, >=, <=, contains, in\n",
        "\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "# ==================== BUSCADOR EN TABLAS ====================\n",
        "\n",
        "class TableSearcher:\n",
        "    \"\"\"\n",
        "    Realiza búsquedas en DataFrames usando filtros generados por LLM\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataframes: Dict[str, pd.DataFrame], filter_generator: TableFilterGenerator):\n",
        "        self.dataframes = dataframes\n",
        "        self.filter_generator = filter_generator\n",
        "\n",
        "        print(f\"\\n📊 Buscador de tablas inicializado\")\n",
        "        print(f\"   Tablas disponibles: {list(dataframes.keys())}\")\n",
        "\n",
        "    def search(self, query: str, table_name: str, max_results: int = 10) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Busca en una tabla usando lenguaje natural\n",
        "\n",
        "        Args:\n",
        "            query: Consulta en lenguaje natural\n",
        "            table_name: Nombre de la tabla\n",
        "            max_results: Número máximo de resultados\n",
        "\n",
        "        Returns:\n",
        "            DataFrame con resultados filtrados\n",
        "        \"\"\"\n",
        "\n",
        "        if table_name not in self.dataframes:\n",
        "            print(f\"⚠️ Tabla '{table_name}' no encontrada\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = self.dataframes[table_name].copy()\n",
        "\n",
        "        # Generar filtros con LLM\n",
        "        filter_spec = self.filter_generator.generate_filter(query, table_name)\n",
        "\n",
        "        # Debug: mostrar filtros generados\n",
        "        print(f\"🔍 Filtros generados: {json.dumps(filter_spec, indent=2, ensure_ascii=False)}\")\n",
        "\n",
        "        # Aplicar filtros\n",
        "        df_filtered = self._apply_filters(df, filter_spec)\n",
        "\n",
        "        # Aplicar ordenamiento si existe\n",
        "        if 'sort_by' in filter_spec and filter_spec['sort_by']:\n",
        "            ascending = filter_spec.get('ascending', True)\n",
        "            if filter_spec['sort_by'] in df_filtered.columns:\n",
        "                df_filtered = df_filtered.sort_values(\n",
        "                    by=filter_spec['sort_by'],\n",
        "                    ascending=ascending\n",
        "                )\n",
        "\n",
        "        # Aplicar límite\n",
        "        limit = filter_spec.get('limit', max_results)\n",
        "        df_filtered = df_filtered.head(limit)\n",
        "\n",
        "        return df_filtered\n",
        "\n",
        "    def _apply_filters(self, df: pd.DataFrame, filter_spec: Dict) -> pd.DataFrame:\n",
        "        \"\"\"Aplica los filtros al DataFrame\"\"\"\n",
        "\n",
        "        if 'filters' not in filter_spec or not filter_spec['filters']:\n",
        "            return df\n",
        "\n",
        "        mask = pd.Series([True] * len(df))\n",
        "\n",
        "        for f in filter_spec['filters']:\n",
        "            column = f.get('column')\n",
        "            operator = f.get('operator')\n",
        "            value = f.get('value')\n",
        "\n",
        "            if column not in df.columns:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                if operator == '==':\n",
        "                    mask &= (df[column] == value)\n",
        "                elif operator == '>':\n",
        "                    mask &= (df[column] > value)\n",
        "                elif operator == '<':\n",
        "                    mask &= (df[column] < value)\n",
        "                elif operator == '>=':\n",
        "                    mask &= (df[column] >= value)\n",
        "                elif operator == '<=':\n",
        "                    mask &= (df[column] <= value)\n",
        "                elif operator == 'contains':\n",
        "                    mask &= df[column].astype(str).str.contains(str(value), case=False, na=False)\n",
        "                elif operator == 'in':\n",
        "                    if isinstance(value, list):\n",
        "                        mask &= df[column].isin(value)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error aplicando filtro en {column}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return df[mask]\n",
        "\n",
        "    def get_summary(self, table_name: str) -> str:\n",
        "        \"\"\"Obtiene un resumen de la tabla\"\"\"\n",
        "\n",
        "        if table_name not in self.dataframes:\n",
        "            return f\"Tabla '{table_name}' no encontrada\"\n",
        "\n",
        "        df = self.dataframes[table_name]\n",
        "\n",
        "        summary = f\"\"\"Tabla: {table_name}\n",
        "Filas: {len(df)}\n",
        "Columnas: {len(df.columns)}\n",
        "Columnas disponibles: {', '.join(df.columns.tolist())}\n",
        "\"\"\"\n",
        "\n",
        "        return summary\n",
        "\n",
        "# ==================== INICIALIZACIÓN ====================\n",
        "\n",
        "print(\"🔧 Inicializando componentes de base de datos tabular...\\n\")\n",
        "\n",
        "# Crear generador de filtros\n",
        "filter_generator = TableFilterGenerator(\n",
        "    api_key=config.GROQ_API_KEY,\n",
        "    metadata=metadata\n",
        ")\n",
        "\n",
        "# Crear buscador de tablas\n",
        "table_searcher = TableSearcher(\n",
        "    dataframes=dataframes,\n",
        "    filter_generator=filter_generator\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ BASE DE DATOS TABULAR LISTA\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "Interfaz de búsqueda:\n",
        "    results = table_searcher.search(\n",
        "        query=\"¿Cuáles son las licuadoras de menos de $200?\",\n",
        "        table_name='productos',\n",
        "        max_results=10\n",
        "    )\n",
        "\n",
        "Tablas disponibles:\n",
        "\"\"\")\n",
        "\n",
        "for table_name in dataframes.keys():\n",
        "    df = dataframes[table_name]\n",
        "    print(f\"    - {table_name}: {len(df)} filas, {len(df.columns)} columnas\")\n",
        "\n",
        "print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2DACOkkZrhE",
        "outputId": "ea51d5c7-467d-4722-cc0b-bde38cd88b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CONFIGURANDO BASE DE DATOS TABULAR\n",
            "============================================================\n",
            "\n",
            "🔧 Inicializando componentes de base de datos tabular...\n",
            "\n",
            "🤖 Generador de filtros inicializado\n",
            "   Modelo: llama-3.3-70b-versatile\n",
            "\n",
            "📊 Buscador de tablas inicializado\n",
            "   Tablas disponibles: ['productos', 'vendedores', 'ventas', 'tickets', 'inventario', 'devoluciones']\n",
            "\n",
            "============================================================\n",
            "✅ BASE DE DATOS TABULAR LISTA\n",
            "============================================================\n",
            "\n",
            "Interfaz de búsqueda:\n",
            "    results = table_searcher.search(\n",
            "        query=\"¿Cuáles son las licuadoras de menos de $200?\",\n",
            "        table_name='productos',\n",
            "        max_results=10\n",
            "    )\n",
            "\n",
            "Tablas disponibles:\n",
            "\n",
            "    - productos: 300 filas, 14 columnas\n",
            "    - vendedores: 100 filas, 10 columnas\n",
            "    - ventas: 10000 filas, 15 columnas\n",
            "    - tickets: 2000 filas, 17 columnas\n",
            "    - inventario: 4100 filas, 14 columnas\n",
            "    - devoluciones: 800 filas, 14 columnas\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 7: PRUEBAS DE BASE TABULAR\n",
        "============================================\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PRUEBAS DE LA BASE DE DATOS TABULAR\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== PRUEBA 1: FILTRO POR PRECIO ====================\n",
        "\n",
        "print(\"📝 PRUEBA 1: Filtro por precio\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Cuáles son las licuadoras de menos de $300?\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = table_searcher.search(query, 'productos', max_results=5)\n",
        "\n",
        "print(f\"Resultados encontrados: {len(results)}\\n\")\n",
        "if len(results) > 0:\n",
        "    print(results[['id_producto', 'nombre', 'marca', 'precio_usd', 'categoria']].to_string(index=False))\n",
        "else:\n",
        "    print(\"No se encontraron resultados\")\n",
        "\n",
        "# ==================== PRUEBA 2: FILTRO POR MARCA ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 2: Filtro por marca\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"Productos de la marca TechHome\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = table_searcher.search(query, 'productos', max_results=5)\n",
        "\n",
        "print(f\"Resultados encontrados: {len(results)}\\n\")\n",
        "if len(results) > 0:\n",
        "    print(results[['id_producto', 'nombre', 'marca', 'precio_usd']].to_string(index=False))\n",
        "else:\n",
        "    print(\"No se encontraron resultados\")\n",
        "\n",
        "# ==================== PRUEBA 3: FILTRO POR GARANTÍA ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 3: Filtro por garantía\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"Productos con garantía mayor a 24 meses\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = table_searcher.search(query, 'productos', max_results=5)\n",
        "\n",
        "print(f\"Resultados encontrados: {len(results)}\\n\")\n",
        "if len(results) > 0:\n",
        "    print(results[['id_producto', 'nombre', 'garantia_meses', 'precio_usd']].to_string(index=False))\n",
        "else:\n",
        "    print(\"No se encontraron resultados\")\n",
        "\n",
        "# ==================== PRUEBA 4: CONSULTA EN VENTAS ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 4: Consulta en tabla de ventas\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"Ventas en la sucursal Centro\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = table_searcher.search(query, 'ventas', max_results=5)\n",
        "\n",
        "print(f\"Resultados encontrados: {len(results)}\\n\")\n",
        "if len(results) > 0:\n",
        "    print(results[['id_venta', 'sucursal', 'total', 'metodo_pago', 'fecha']].to_string(index=False))\n",
        "else:\n",
        "    print(\"No se encontraron resultados\")\n",
        "\n",
        "# ==================== PRUEBA 4.1: CONSULTA EN VENTAS (ADICIONAL) ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 4: Consulta en tabla de ventas\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"Cantidad de Sucursales\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = table_searcher.search(query, 'ventas', max_results=5)\n",
        "\n",
        "print(f\"Resultados encontrados: {len(results)}\\n\")\n",
        "if len(results) > 0:\n",
        "    print(results[['id_venta', 'sucursal', 'total', 'metodo_pago', 'fecha']].to_string(index=False))\n",
        "else:\n",
        "    print(\"No se encontraron resultados\")\n",
        "\n",
        "# ==================== FUNCIÓN HELPER ====================\n",
        "\n",
        "def buscar_tabla(query: str, tabla: str = 'productos', max_results: int = 10):\n",
        "    \"\"\"\n",
        "    Función helper para búsquedas rápidas en tablas\n",
        "\n",
        "    Args:\n",
        "        query: Consulta en lenguaje natural\n",
        "        tabla: Nombre de la tabla (productos, ventas, etc)\n",
        "        max_results: Número máximo de resultados\n",
        "    \"\"\"\n",
        "    print(f\"\\n🔍 Buscando en tabla '{tabla}': '{query}'\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    results = table_searcher.search(query, tabla, max_results)\n",
        "\n",
        "    print(f\"\\n📊 Encontrados {len(results)} resultados\\n\")\n",
        "\n",
        "    if len(results) > 0:\n",
        "        # Mostrar solo columnas relevantes\n",
        "        if tabla == 'productos':\n",
        "            cols = ['id_producto', 'nombre', 'marca', 'precio_usd', 'categoria']\n",
        "        elif tabla == 'ventas':\n",
        "            cols = ['id_venta', 'sucursal', 'total', 'metodo_pago', 'fecha']\n",
        "        else:\n",
        "            cols = results.columns.tolist()[:5]\n",
        "\n",
        "        display_cols = [c for c in cols if c in results.columns]\n",
        "        print(results[display_cols].to_string(index=False))\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"✅ PRUEBAS COMPLETADAS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nFunción helper disponible:\")\n",
        "print(\"  buscar_tabla('tu consulta', tabla='productos', max_results=10)\")\n",
        "print(\"\\nEjemplo:\")\n",
        "print(\"  results = buscar_tabla('licuadoras baratas', 'productos', 5)\")"
      ],
      "metadata": {
        "id": "DjMH_35-_3UZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985c8ce0-a2f3-4337-9915-2ce26553198c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PRUEBAS DE LA BASE DE DATOS TABULAR\n",
            "============================================================\n",
            "\n",
            "📝 PRUEBA 1: Filtro por precio\n",
            "------------------------------------------------------------\n",
            "Query: '¿Cuáles son las licuadoras de menos de $300?'\n",
            "\n",
            "🔍 Filtros generados: {\n",
            "  \"filters\": [\n",
            "    {\n",
            "      \"column\": \"nombre\",\n",
            "      \"operator\": \"contains\",\n",
            "      \"value\": \"Licuadora\"\n",
            "    },\n",
            "    {\n",
            "      \"column\": \"precio_usd\",\n",
            "      \"operator\": \"<\",\n",
            "      \"value\": 300\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Resultados encontrados: 2\n",
            "\n",
            "id_producto             nombre      marca  precio_usd categoria\n",
            "      P0001          Licuadora   TechHome      283.63    Cocina\n",
            "      P0004 Compacto Licuadora ChefMaster      259.42    Cocina\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 2: Filtro por marca\n",
            "------------------------------------------------------------\n",
            "Query: 'Productos de la marca TechHome'\n",
            "\n",
            "🔍 Filtros generados: {\n",
            "  \"filters\": [\n",
            "    {\n",
            "      \"column\": \"marca\",\n",
            "      \"operator\": \"==\",\n",
            "      \"value\": \"TechHome\"\n",
            "    }\n",
            "  ],\n",
            "  \"sort_by\": \"nombre\",\n",
            "  \"ascending\": true,\n",
            "  \"limit\": 20\n",
            "}\n",
            "Resultados encontrados: 20\n",
            "\n",
            "id_producto                       nombre    marca  precio_usd\n",
            "      P0012      Advanced Procesadora II TechHome     2528.96\n",
            "      P0044     Compacto Horno Eléctrico TechHome       97.66\n",
            "      P0112              Deluxe Frigobar TechHome      243.62\n",
            "      P0010           Deluxe Procesadora TechHome     1169.67\n",
            "      P0028   Digital Rallador Eléctrico TechHome      872.83\n",
            "      P0030       Eco Rallador Eléctrico TechHome      630.69\n",
            "      P0057              Elite Tostadora TechHome     2105.90\n",
            "      P0133                   Exprimidor TechHome     1942.87\n",
            "      P0055             Freidora de Aire TechHome      852.80\n",
            "      P0110                     Frigobar TechHome     2339.59\n",
            "      P0111                     Frigobar TechHome      922.34\n",
            "      P0001                    Licuadora TechHome      283.63\n",
            "      P0002                    Licuadora TechHome     1273.06\n",
            "      P0038        Max Molinillo de Café TechHome     1053.41\n",
            "      P0077                Olla Arrocera TechHome      264.30\n",
            "      P0084        Olla de Cocción Lenta TechHome     1261.07\n",
            "      P0003           Plus Licuadora Pro TechHome      329.07\n",
            "      P0080            Pro Olla Arrocera TechHome      134.16\n",
            "      P0017 Profesional Batidora de Mano TechHome      853.46\n",
            "      P0101          Profesional Freezer TechHome     1764.06\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 3: Filtro por garantía\n",
            "------------------------------------------------------------\n",
            "Query: 'Productos con garantía mayor a 24 meses'\n",
            "\n",
            "⚠️ Error generando filtros: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99884, Requested 688. Please try again in 8m14.208s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "🔍 Filtros generados: {\n",
            "  \"filters\": []\n",
            "}\n",
            "Resultados encontrados: 5\n",
            "\n",
            "id_producto             nombre  garantia_meses  precio_usd\n",
            "      P0001          Licuadora              36      283.63\n",
            "      P0002          Licuadora              36     1273.06\n",
            "      P0003 Plus Licuadora Pro              18      329.07\n",
            "      P0004 Compacto Licuadora              24      259.42\n",
            "      P0005          Licuadora              12     2602.78\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 4: Consulta en tabla de ventas\n",
            "------------------------------------------------------------\n",
            "Query: 'Ventas en la sucursal Centro'\n",
            "\n",
            "⚠️ Error generando filtros: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99884, Requested 829. Please try again in 10m16.032s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "🔍 Filtros generados: {\n",
            "  \"filters\": []\n",
            "}\n",
            "Resultados encontrados: 5\n",
            "\n",
            " id_venta            sucursal    total               metodo_pago      fecha\n",
            "VTA000056          Santa Cruz 11194.96 Tarjeta Crédito 12 cuotas 2022-11-19\n",
            "VTA000186               Jujuy  4055.65    Transferencia Bancaria 2022-11-19\n",
            "VTA001964 Santiago del Estero  2306.61    Transferencia Bancaria 2022-11-19\n",
            "VTA004701            Misiones  2290.59              Mercado Pago 2022-11-19\n",
            "VTA004760             Mendoza  2522.14    Tarjeta Crédito 1 pago 2022-11-19\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 4: Consulta en tabla de ventas\n",
            "------------------------------------------------------------\n",
            "Query: 'Cantidad de Sucursales'\n",
            "\n",
            "⚠️ Error generando filtros: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99884, Requested 827. Please try again in 10m14.304s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "🔍 Filtros generados: {\n",
            "  \"filters\": []\n",
            "}\n",
            "Resultados encontrados: 5\n",
            "\n",
            " id_venta            sucursal    total               metodo_pago      fecha\n",
            "VTA000056          Santa Cruz 11194.96 Tarjeta Crédito 12 cuotas 2022-11-19\n",
            "VTA000186               Jujuy  4055.65    Transferencia Bancaria 2022-11-19\n",
            "VTA001964 Santiago del Estero  2306.61    Transferencia Bancaria 2022-11-19\n",
            "VTA004701            Misiones  2290.59              Mercado Pago 2022-11-19\n",
            "VTA004760             Mendoza  2522.14    Tarjeta Crédito 1 pago 2022-11-19\n",
            "\n",
            "\n",
            "============================================================\n",
            "✅ PRUEBAS COMPLETADAS\n",
            "============================================================\n",
            "\n",
            "Función helper disponible:\n",
            "  buscar_tabla('tu consulta', tabla='productos', max_results=10)\n",
            "\n",
            "Ejemplo:\n",
            "  results = buscar_tabla('licuadoras baratas', 'productos', 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 8: BASE DE DATOS DE GRAFOS (NEO4J)\n",
        "============================================\n",
        "Implementa base de datos de grafos con queries Cypher dinámicas usando GROQ\n",
        "\"\"\"\n",
        "\n",
        "from neo4j import GraphDatabase\n",
        "from groq import Groq\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONFIGURANDO BASE DE DATOS DE GRAFOS\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== CONEXIÓN A NEO4J ====================\n",
        "\n",
        "class Neo4jConnection:\n",
        "    \"\"\"Gestiona la conexión a Neo4j\"\"\"\n",
        "\n",
        "    def __init__(self, uri: str, user: str, password: str):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "        print(f\"🔌 Conectando a Neo4j...\")\n",
        "\n",
        "        try:\n",
        "            self.driver.verify_connectivity()\n",
        "            print(\"✅ Conexión exitosa a Neo4j\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error conectando a Neo4j: {e}\")\n",
        "            raise\n",
        "\n",
        "    def close(self):\n",
        "        if self.driver:\n",
        "            self.driver.close()\n",
        "\n",
        "    def execute_query(self, query: str, parameters: Optional[Dict] = None) -> List[Dict]:\n",
        "        \"\"\"Ejecuta una query Cypher y retorna resultados\"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query, parameters or {})\n",
        "            return [record.data() for record in result]\n",
        "\n",
        "    def execute_write(self, query: str, parameters: Optional[Dict] = None):\n",
        "        \"\"\"Ejecuta una query de escritura\"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            session.run(query, parameters or {})\n",
        "\n",
        "    def clear_database(self):\n",
        "        \"\"\"Limpia toda la base de datos\"\"\"\n",
        "        print(\"🗑️ Limpiando base de datos...\")\n",
        "        self.execute_write(\"MATCH (n) DETACH DELETE n\")\n",
        "        print(\"✅ Base de datos limpiada\")\n",
        "\n",
        "# ==================== CONSTRUCTOR DEL GRAFO ====================\n",
        "\n",
        "class GraphBuilder:\n",
        "    \"\"\"Construye el grafo de conocimiento\"\"\"\n",
        "\n",
        "    def __init__(self, neo4j_conn: Neo4jConnection):\n",
        "        self.conn = neo4j_conn\n",
        "\n",
        "    def build_graph(self, dataframes: Dict, documents: Dict):\n",
        "        \"\"\"Construye el grafo completo\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"CONSTRUYENDO GRAFO DE CONOCIMIENTO\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        self.conn.clear_database()\n",
        "\n",
        "        if 'productos' in dataframes:\n",
        "            self._create_product_nodes(dataframes['productos'])\n",
        "            self._create_category_and_brand_nodes(dataframes['productos'])\n",
        "\n",
        "        if 'inventario' in dataframes:\n",
        "            self._create_sucursal_nodes(dataframes['inventario'])\n",
        "            self._create_inventory_relationships(dataframes['inventario'])\n",
        "\n",
        "        if 'manuales' in documents:\n",
        "            self._create_compatibility_relationships(documents['manuales'])\n",
        "\n",
        "        self._create_indexes()\n",
        "\n",
        "        print(\"\\n✅ Grafo de conocimiento construido\")\n",
        "        self._print_statistics()\n",
        "\n",
        "    def _create_product_nodes(self, df_productos: pd.DataFrame):\n",
        "        \"\"\"Crea nodos de productos\"\"\"\n",
        "        print(\"📦 Creando nodos de productos...\")\n",
        "\n",
        "        query = \"\"\"\n",
        "        UNWIND $productos AS prod\n",
        "        CREATE (p:Producto {\n",
        "            id: prod.id_producto,\n",
        "            nombre: prod.nombre,\n",
        "            marca: prod.marca,\n",
        "            precio: prod.precio_usd,\n",
        "            stock: prod.stock,\n",
        "            potencia: prod.potencia_w,\n",
        "            voltaje: prod.voltaje,\n",
        "            garantia_meses: prod.garantia_meses\n",
        "        })\n",
        "        \"\"\"\n",
        "\n",
        "        productos_data = df_productos.fillna('').to_dict('records')\n",
        "        self.conn.execute_write(query, {'productos': productos_data})\n",
        "        print(f\"✅ {len(productos_data)} productos creados\")\n",
        "\n",
        "    def _create_category_and_brand_nodes(self, df_productos: pd.DataFrame):\n",
        "        \"\"\"Crea nodos de categorías y marcas + relaciones\"\"\"\n",
        "        print(\"🏷️ Creando categorías, marcas y relaciones...\")\n",
        "\n",
        "        categorias = df_productos['categoria'].unique()\n",
        "        for categoria in categorias:\n",
        "            query = \"MERGE (c:Categoria {nombre: $nombre})\"\n",
        "            self.conn.execute_write(query, {'nombre': categoria})\n",
        "\n",
        "        marcas = df_productos['marca'].unique()\n",
        "        for marca in marcas:\n",
        "            query = \"MERGE (m:Marca {nombre: $nombre})\"\n",
        "            self.conn.execute_write(query, {'nombre': marca})\n",
        "\n",
        "        query = \"\"\"\n",
        "        MATCH (p:Producto), (c:Categoria), (m:Marca)\n",
        "        WHERE p.id = $id_producto\n",
        "          AND c.nombre = $categoria\n",
        "          AND m.nombre = $marca\n",
        "        MERGE (p)-[:PERTENECE_A]->(c)\n",
        "        MERGE (p)-[:FABRICADO_POR]->(m)\n",
        "        \"\"\"\n",
        "\n",
        "        for _, row in df_productos.iterrows():\n",
        "            self.conn.execute_write(query, {\n",
        "                'id_producto': row['id_producto'],\n",
        "                'categoria': row['categoria'],\n",
        "                'marca': row['marca']\n",
        "            })\n",
        "\n",
        "        print(f\"✅ {len(categorias)} categorías, {len(marcas)} marcas\")\n",
        "\n",
        "    def _create_sucursal_nodes(self, df_inventario: pd.DataFrame):\n",
        "        \"\"\"Crea nodos de sucursales\"\"\"\n",
        "        print(\"🏢 Creando nodos de sucursales...\")\n",
        "\n",
        "        sucursales = df_inventario['sucursal'].unique()\n",
        "        for sucursal in sucursales:\n",
        "            query = \"MERGE (s:Sucursal {nombre: $nombre})\"\n",
        "            self.conn.execute_write(query, {'nombre': sucursal})\n",
        "\n",
        "        print(f\"✅ {len(sucursales)} sucursales creadas\")\n",
        "\n",
        "    def _create_inventory_relationships(self, df_inventario: pd.DataFrame):\n",
        "        \"\"\"Crea relaciones Producto -> Sucursal con stock\"\"\"\n",
        "        print(\"📊 Creando relaciones de inventario...\")\n",
        "\n",
        "        query = \"\"\"\n",
        "        MATCH (p:Producto {id: $id_producto})\n",
        "        MATCH (s:Sucursal {nombre: $sucursal})\n",
        "        MERGE (p)-[r:DISPONIBLE_EN]->(s)\n",
        "        SET r.stock = $stock,\n",
        "            r.precio_sucursal = $precio_sucursal\n",
        "        \"\"\"\n",
        "\n",
        "        count = 0\n",
        "        for _, row in df_inventario.iterrows():\n",
        "            self.conn.execute_write(query, {\n",
        "                'id_producto': row['id_producto'],\n",
        "                'sucursal': row['sucursal'],\n",
        "                'stock': int(row['stock_sucursal']) if pd.notna(row['stock_sucursal']) else 0,\n",
        "                'precio_sucursal': float(row['precio_sucursal']) if pd.notna(row['precio_sucursal']) else 0\n",
        "            })\n",
        "            count += 1\n",
        "\n",
        "        print(f\"✅ {count} relaciones de inventario creadas\")\n",
        "\n",
        "    def _create_compatibility_relationships(self, manuales: List[Dict]):\n",
        "        \"\"\"Extrae y crea relaciones de compatibilidad desde manuales\"\"\"\n",
        "        print(\"🔗 Creando relaciones de compatibilidad...\")\n",
        "\n",
        "        count = 0\n",
        "        for manual in manuales:\n",
        "            if manual.get('tipo_seccion') != 'compatibilidad':\n",
        "                continue\n",
        "\n",
        "            id_producto_origen = manual['id_producto']\n",
        "            contenido = manual['contenido']\n",
        "\n",
        "            productos_encontrados = re.findall(r'P\\d{4}', contenido)\n",
        "            comparte_match = re.search(r'Comparte:\\s*([^\\n]+)', contenido)\n",
        "            comparte = comparte_match.group(1).strip() if comparte_match else \"Componente\"\n",
        "\n",
        "            for id_producto_destino in productos_encontrados:\n",
        "                if id_producto_destino != id_producto_origen:\n",
        "                    query = \"\"\"\n",
        "                    MATCH (p1:Producto {id: $id_origen})\n",
        "                    MATCH (p2:Producto {id: $id_destino})\n",
        "                    MERGE (p1)-[r:COMPATIBLE_CON]->(p2)\n",
        "                    SET r.comparte = $comparte\n",
        "                    \"\"\"\n",
        "\n",
        "                    try:\n",
        "                        self.conn.execute_write(query, {\n",
        "                            'id_origen': id_producto_origen,\n",
        "                            'id_destino': id_producto_destino,\n",
        "                            'comparte': comparte\n",
        "                        })\n",
        "                        count += 1\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "        print(f\"✅ {count} relaciones de compatibilidad creadas\")\n",
        "\n",
        "    def _create_indexes(self):\n",
        "        \"\"\"Crea índices para mejor performance\"\"\"\n",
        "        print(\"📇 Creando índices...\")\n",
        "\n",
        "        indexes = [\n",
        "            \"CREATE INDEX IF NOT EXISTS FOR (p:Producto) ON (p.id)\",\n",
        "            \"CREATE INDEX IF NOT EXISTS FOR (c:Categoria) ON (c.nombre)\",\n",
        "            \"CREATE INDEX IF NOT EXISTS FOR (m:Marca) ON (m.nombre)\",\n",
        "            \"CREATE INDEX IF NOT EXISTS FOR (s:Sucursal) ON (s.nombre)\"\n",
        "        ]\n",
        "\n",
        "        for index_query in indexes:\n",
        "            try:\n",
        "                self.conn.execute_write(index_query)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        print(\"✅ Índices creados\")\n",
        "\n",
        "    def _print_statistics(self):\n",
        "        \"\"\"Imprime estadísticas del grafo\"\"\"\n",
        "        print(\"\\n📊 Estadísticas del grafo:\")\n",
        "\n",
        "        stats = {\n",
        "            'Productos': \"MATCH (p:Producto) RETURN count(p) as count\",\n",
        "            'Categorías': \"MATCH (c:Categoria) RETURN count(c) as count\",\n",
        "            'Marcas': \"MATCH (m:Marca) RETURN count(m) as count\",\n",
        "            'Sucursales': \"MATCH (s:Sucursal) RETURN count(s) as count\",\n",
        "            'Relaciones totales': \"MATCH ()-[r]->() RETURN count(r) as count\",\n",
        "            'Compatibilidades': \"MATCH ()-[r:COMPATIBLE_CON]->() RETURN count(r) as count\"\n",
        "        }\n",
        "\n",
        "        for label, query in stats.items():\n",
        "            result = self.conn.execute_query(query)\n",
        "            count = result[0]['count'] if result else 0\n",
        "            print(f\"  - {label}: {count}\")\n",
        "\n",
        "# ==================== GENERADOR DE QUERIES CYPHER ====================\n",
        "\n",
        "class CypherGenerator:\n",
        "    \"\"\"Genera queries Cypher a partir de lenguaje natural usando GROQ\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "        print(\"🤖 Generador de Cypher inicializado\")\n",
        "\n",
        "    def generate_cypher(self, query: str) -> str:\n",
        "        \"\"\"Genera query Cypher desde lenguaje natural\"\"\"\n",
        "\n",
        "        prompt = f\"\"\"Eres un experto en Neo4j y Cypher.\n",
        "\n",
        "ESQUEMA DEL GRAFO:\n",
        "- (Producto {{id, nombre, marca, precio, stock, potencia, voltaje, garantia_meses}})\n",
        "- (Categoria {{nombre}})\n",
        "- (Marca {{nombre}})\n",
        "- (Sucursal {{nombre}})\n",
        "\n",
        "RELACIONES:\n",
        "- (Producto)-[:PERTENECE_A]->(Categoria)\n",
        "- (Producto)-[:FABRICADO_POR]->(Marca)\n",
        "- (Producto)-[:DISPONIBLE_EN {{stock, precio_sucursal}}]->(Sucursal)\n",
        "- (Producto)-[:COMPATIBLE_CON {{comparte}}]->(Producto)\n",
        "\n",
        "REGLAS DE SINTAXIS CYPHER:\n",
        "1. Direcciones: (A)-[:REL]->(B) o (A)<-[:REL]-(B)\n",
        "2. NUNCA uses: [:REL<-] o [:REL->] (sintaxis inválida)\n",
        "3. Usa MATCH para buscar, CREATE para crear\n",
        "4. Siempre limita resultados con LIMIT (máximo 20)\n",
        "5. Usa DISTINCT para evitar duplicados\n",
        "\n",
        "EJEMPLOS CORRECTOS:\n",
        "\n",
        "Usuario: \"¿Qué productos son compatibles con P0016?\"\n",
        "Cypher: MATCH (p1:Producto {{id: 'P0016'}})-[:COMPATIBLE_CON]->(p2:Producto) RETURN p2.nombre, p2.marca, p2.precio LIMIT 10\n",
        "\n",
        "Usuario: \"Productos de la marca TechHome\"\n",
        "Cypher: MATCH (p:Producto)-[:FABRICADO_POR]->(m:Marca {{nombre: 'TechHome'}}) RETURN p.nombre, p.precio, p.stock LIMIT 10\n",
        "\n",
        "Usuario: \"¿Dónde hay stock del producto P0001?\"\n",
        "Cypher: MATCH (p:Producto {{id: 'P0001'}})-[r:DISPONIBLE_EN]->(s:Sucursal) WHERE r.stock > 0 RETURN s.nombre, r.stock, r.precio_sucursal\n",
        "\n",
        "Usuario: \"Productos de la categoría Cocina\"\n",
        "Cypher: MATCH (p:Producto)-[:PERTENECE_A]->(c:Categoria {{nombre: 'Cocina'}}) RETURN p.nombre, p.marca, p.precio LIMIT 10\n",
        "\n",
        "Usuario: \"¿Qué marcas fabrican productos de Cocina?\"\n",
        "Cypher: MATCH (p:Producto)-[:PERTENECE_A]->(c:Categoria {{nombre: 'Cocina'}}), (p)-[:FABRICADO_POR]->(m:Marca) RETURN DISTINCT m.nombre LIMIT 10\n",
        "\n",
        "Usuario: \"Stock de TechHome por sucursal\"\n",
        "Cypher: MATCH (p:Producto)-[:FABRICADO_POR]->(m:Marca {{nombre: 'TechHome'}}), (p)-[r:DISPONIBLE_EN]->(s:Sucursal) WHERE r.stock > 0 RETURN s.nombre, p.nombre, r.stock ORDER BY s.nombre LIMIT 20\n",
        "\n",
        "CONSULTA: \"{query}\"\n",
        "\n",
        "Responde SOLO con la query Cypher válida, sin explicaciones ni markdown:\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"llama-3.3-70b-versatile\",\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.1,\n",
        "                max_tokens=300\n",
        "            )\n",
        "\n",
        "            cypher = response.choices[0].message.content.strip()\n",
        "\n",
        "            # Limpiar markdown si existe\n",
        "            cypher = re.sub(r'```cypher\\s*', '', cypher)\n",
        "            cypher = re.sub(r'```\\s*', '', cypher)\n",
        "            cypher = cypher.strip()\n",
        "\n",
        "            return cypher\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error generando Cypher: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "# ==================== MOTOR DE CONSULTAS ====================\n",
        "\n",
        "class GraphSearcher:\n",
        "    \"\"\"Motor de consultas para el grafo\"\"\"\n",
        "\n",
        "    def __init__(self, neo4j_conn: Neo4jConnection, cypher_gen: CypherGenerator):\n",
        "        self.conn = neo4j_conn\n",
        "        self.cypher_gen = cypher_gen\n",
        "        print(\"🔍 Motor de búsqueda en grafos inicializado\")\n",
        "\n",
        "    def search(self, query: str) -> List[Dict]:\n",
        "        \"\"\"Consulta el grafo con lenguaje natural\"\"\"\n",
        "\n",
        "        cypher = self.cypher_gen.generate_cypher(query)\n",
        "\n",
        "        if not cypher:\n",
        "            return []\n",
        "\n",
        "        print(f\"🔍 Cypher generado:\\n{cypher}\\n\")\n",
        "\n",
        "        try:\n",
        "            results = self.conn.execute_query(cypher)\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error ejecutando Cypher: {e}\")\n",
        "            return []\n",
        "\n",
        "    def format_results(self, results: List[Dict]) -> str:\n",
        "        \"\"\"Formatea resultados para mostrar\"\"\"\n",
        "        if not results:\n",
        "            return \"No se encontraron resultados.\"\n",
        "\n",
        "        output = f\"Se encontraron {len(results)} resultados:\\n\\n\"\n",
        "\n",
        "        for i, result in enumerate(results[:10], 1):\n",
        "            output += f\"{i}. \"\n",
        "            output += \" | \".join([f\"{k}: {v}\" for k, v in result.items()])\n",
        "            output += \"\\n\"\n",
        "\n",
        "        if len(results) > 10:\n",
        "            output += f\"\\n... y {len(results) - 10} más\"\n",
        "\n",
        "        return output\n",
        "\n",
        "# ==================== INICIALIZACIÓN ====================\n",
        "\n",
        "print(\"🔧 Inicializando base de datos de grafos...\\n\")\n",
        "\n",
        "# Conectar a Neo4j\n",
        "neo4j_conn = Neo4jConnection(\n",
        "    uri=config.NEO4J_URI,\n",
        "    user=config.NEO4J_USER,\n",
        "    password=config.NEO4J_PASSWORD\n",
        ")\n",
        "\n",
        "# Construir grafo\n",
        "graph_builder = GraphBuilder(neo4j_conn)\n",
        "graph_builder.build_graph(dataframes, documents)\n",
        "\n",
        "# Crear generador de Cypher y motor de consultas\n",
        "cypher_generator = CypherGenerator(config.GROQ_API_KEY)\n",
        "graph_searcher = GraphSearcher(neo4j_conn, cypher_generator)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ BASE DE DATOS DE GRAFOS LISTA\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "Interfaz de búsqueda:\n",
        "    results = graph_searcher.search(\"¿Qué productos son compatibles con P0016?\")\n",
        "\"\"\")\n",
        "print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pumZdj40Qe2",
        "outputId": "16544c3a-ea29-44eb-a03a-d57ac1d59799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CONFIGURANDO BASE DE DATOS DE GRAFOS\n",
            "============================================================\n",
            "\n",
            "🔧 Inicializando base de datos de grafos...\n",
            "\n",
            "🔌 Conectando a Neo4j...\n",
            "✅ Conexión exitosa a Neo4j\n",
            "\n",
            "\n",
            "============================================================\n",
            "CONSTRUYENDO GRAFO DE CONOCIMIENTO\n",
            "============================================================\n",
            "\n",
            "🗑️ Limpiando base de datos...\n",
            "✅ Base de datos limpiada\n",
            "📦 Creando nodos de productos...\n",
            "✅ 300 productos creados\n",
            "🏷️ Creando categorías, marcas y relaciones...\n",
            "✅ 4 categorías, 17 marcas\n",
            "🏢 Creando nodos de sucursales...\n",
            "✅ 24 sucursales creadas\n",
            "📊 Creando relaciones de inventario...\n",
            "✅ 4100 relaciones de inventario creadas\n",
            "🔗 Creando relaciones de compatibilidad...\n",
            "✅ 250 relaciones de compatibilidad creadas\n",
            "📇 Creando índices...\n",
            "✅ Índices creados\n",
            "\n",
            "✅ Grafo de conocimiento construido\n",
            "\n",
            "📊 Estadísticas del grafo:\n",
            "  - Productos: 300\n",
            "  - Categorías: 4\n",
            "  - Marcas: 17\n",
            "  - Sucursales: 24\n",
            "  - Relaciones totales: 4950\n",
            "  - Compatibilidades: 250\n",
            "🤖 Generador de Cypher inicializado\n",
            "🔍 Motor de búsqueda en grafos inicializado\n",
            "\n",
            "============================================================\n",
            "✅ BASE DE DATOS DE GRAFOS LISTA\n",
            "============================================================\n",
            "\n",
            "Interfaz de búsqueda:\n",
            "    results = graph_searcher.search(\"¿Qué productos son compatibles con P0016?\")\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 9: PRUEBAS DE BASE DE GRAFOS\n",
        "============================================\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PRUEBAS DE LA BASE DE DATOS DE GRAFOS\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== PRUEBA 1: COMPATIBILIDAD ====================\n",
        "\n",
        "print(\"📝 PRUEBA 1: Productos compatibles\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Qué productos son compatibles con P0016?\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = graph_searcher.search(query)\n",
        "formatted = graph_searcher.format_results(results)\n",
        "print(formatted)\n",
        "\n",
        "# ==================== PRUEBA 2: FILTRO POR MARCA EN GRAFO ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 2: Productos por marca\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"Productos de la marca TechHome\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = graph_searcher.search(query)\n",
        "formatted = graph_searcher.format_results(results)\n",
        "print(formatted)\n",
        "\n",
        "# ==================== PRUEBA 3: STOCK POR SUCURSAL ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 3: Stock por sucursal\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Dónde hay stock del producto P0001?\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = graph_searcher.search(query)\n",
        "formatted = graph_searcher.format_results(results)\n",
        "print(formatted)\n",
        "\n",
        "# ==================== PRUEBA 4: PRODUCTOS POR CATEGORÍA ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 4: Productos por categoría\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Qué productos pertenecen a la categoría Cocina?\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = graph_searcher.search(query)\n",
        "formatted = graph_searcher.format_results(results)\n",
        "print(formatted)\n",
        "\n",
        "# ==================== FUNCIÓN HELPER ====================\n",
        "\n",
        "def buscar_grafo(query: str):\n",
        "    \"\"\"\n",
        "    Función helper para búsquedas rápidas en el grafo\n",
        "\n",
        "    Args:\n",
        "        query: Consulta en lenguaje natural\n",
        "    \"\"\"\n",
        "    print(f\"\\n🔍 Buscando en grafo: '{query}'\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    results = graph_searcher.search(query)\n",
        "    formatted = graph_searcher.format_results(results)\n",
        "    print(formatted)\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"✅ PRUEBAS COMPLETADAS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nFunción helper disponible:\")\n",
        "print(\"  buscar_grafo('tu consulta')\")\n",
        "print(\"\\nEjemplo:\")\n",
        "print(\"  results = buscar_grafo('productos compatibles con P0020')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7IOAgsdsHAv",
        "outputId": "3aabef5b-9bb2-482c-b16d-2c8bdcc8fcb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PRUEBAS DE LA BASE DE DATOS DE GRAFOS\n",
            "============================================================\n",
            "\n",
            "📝 PRUEBA 1: Productos compatibles\n",
            "------------------------------------------------------------\n",
            "Query: '¿Qué productos son compatibles con P0016?'\n",
            "\n",
            "🔍 Cypher generado:\n",
            "MATCH (p1:Producto {id: 'P0016'})-[:COMPATIBLE_CON]->(p2:Producto) RETURN DISTINCT p2.nombre, p2.marca, p2.precio LIMIT 10\n",
            "\n",
            "Se encontraron 5 resultados:\n",
            "\n",
            "1. p2.nombre: Eco Mixer II | p2.marca: CookElite | p2.precio: 2906.9\n",
            "2. p2.nombre: Deluxe Abridor de Latas | p2.marca: CookElite | p2.precio: 688.19\n",
            "3. p2.nombre: Pava Eléctrica | p2.marca: CookElite | p2.precio: 1051.88\n",
            "4. p2.nombre: Sandwichera | p2.marca: CookElite | p2.precio: 565.96\n",
            "5. p2.nombre: Olla de Cocción Lenta II | p2.marca: CookElite | p2.precio: 1667.94\n",
            "\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 2: Productos por marca\n",
            "------------------------------------------------------------\n",
            "Query: 'Productos de la marca TechHome'\n",
            "\n",
            "⚠️ Error generando Cypher: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99961, Requested 685. Please try again in 9m18.144s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "No se encontraron resultados.\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 3: Stock por sucursal\n",
            "------------------------------------------------------------\n",
            "Query: '¿Dónde hay stock del producto P0001?'\n",
            "\n",
            "⚠️ Error generando Cypher: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99961, Requested 690. Please try again in 9m22.464s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "No se encontraron resultados.\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 4: Productos por categoría\n",
            "------------------------------------------------------------\n",
            "Query: '¿Qué productos pertenecen a la categoría Cocina?'\n",
            "\n",
            "⚠️ Error generando Cypher: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99961, Requested 692. Please try again in 9m24.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "No se encontraron resultados.\n",
            "\n",
            "\n",
            "============================================================\n",
            "✅ PRUEBAS COMPLETADAS\n",
            "============================================================\n",
            "\n",
            "Función helper disponible:\n",
            "  buscar_grafo('tu consulta')\n",
            "\n",
            "Ejemplo:\n",
            "  results = buscar_grafo('productos compatibles con P0020')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 8: BASE DE DATOS DE GRAFOS (NEO4J)\n",
        "============================================\n",
        "Implementa base de datos de grafos con queries Cypher dinámicas usando GROQ\n",
        "\"\"\"\n",
        "\n",
        "from neo4j import GraphDatabase\n",
        "from groq import Groq\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONFIGURANDO BASE DE DATOS DE GRAFOS\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== CONEXIÓN A NEO4J ====================\n",
        "\n",
        "class Neo4jConnection:\n",
        "    \"\"\"Gestiona la conexión a Neo4j\"\"\"\n",
        "\n",
        "    def __init__(self, uri: str, user: str, password: str):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "        print(f\"🔌 Conectando a Neo4j...\")\n",
        "\n",
        "        try:\n",
        "            self.driver.verify_connectivity()\n",
        "            print(\"✅ Conexión exitosa a Neo4j\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error conectando a Neo4j: {e}\")\n",
        "            raise\n",
        "\n",
        "    def close(self):\n",
        "        if self.driver:\n",
        "            self.driver.close()\n",
        "\n",
        "    def execute_query(self, query: str, parameters: Optional[Dict] = None) -> List[Dict]:\n",
        "        \"\"\"Ejecuta una query Cypher y retorna resultados\"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query, parameters or {})\n",
        "            return [record.data() for record in result]\n",
        "\n",
        "    def execute_write(self, query: str, parameters: Optional[Dict] = None):\n",
        "        \"\"\"Ejecuta una query de escritura\"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            session.run(query, parameters or {})\n",
        "\n",
        "    def clear_database(self):\n",
        "        \"\"\"Limpia toda la base de datos\"\"\"\n",
        "        print(\"🗑️ Limpiando base de datos...\")\n",
        "        self.execute_write(\"MATCH (n) DETACH DELETE n\")\n",
        "        print(\"✅ Base de datos limpiada\")\n",
        "\n",
        "# ==================== CONSTRUCTOR DEL GRAFO ====================\n",
        "\n",
        "class GraphBuilder:\n",
        "    \"\"\"Construye el grafo de conocimiento\"\"\"\n",
        "\n",
        "    def __init__(self, neo4j_conn: Neo4jConnection):\n",
        "        self.conn = neo4j_conn\n",
        "\n",
        "    def build_graph(self, dataframes: Dict, documents: Dict):\n",
        "        \"\"\"Construye el grafo completo\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"CONSTRUYENDO GRAFO DE CONOCIMIENTO\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        self.conn.clear_database()\n",
        "\n",
        "        if 'productos' in dataframes:\n",
        "            self._create_product_nodes(dataframes['productos'])\n",
        "            self._create_category_and_brand_nodes(dataframes['productos'])\n",
        "\n",
        "        if 'inventario' in dataframes:\n",
        "            self._create_sucursal_nodes(dataframes['inventario'])\n",
        "            self._create_inventory_relationships(dataframes['inventario'])\n",
        "\n",
        "        if 'manuales' in documents:\n",
        "            self._create_compatibility_relationships(documents['manuales'])\n",
        "\n",
        "        self._create_indexes()\n",
        "\n",
        "        print(\"\\n✅ Grafo de conocimiento construido\")\n",
        "        self._print_statistics()\n",
        "\n",
        "    def _create_product_nodes(self, df_productos: pd.DataFrame):\n",
        "        \"\"\"Crea nodos de productos\"\"\"\n",
        "        print(\"📦 Creando nodos de productos...\")\n",
        "\n",
        "        query = \"\"\"\n",
        "        UNWIND $productos AS prod\n",
        "        CREATE (p:Producto {\n",
        "            id: prod.id_producto,\n",
        "            nombre: prod.nombre,\n",
        "            marca: prod.marca,\n",
        "            precio: prod.precio_usd,\n",
        "            stock: prod.stock,\n",
        "            potencia: prod.potencia_w,\n",
        "            voltaje: prod.voltaje,\n",
        "            garantia_meses: prod.garantia_meses\n",
        "        })\n",
        "        \"\"\"\n",
        "\n",
        "        productos_data = df_productos.fillna('').to_dict('records')\n",
        "        self.conn.execute_write(query, {'productos': productos_data})\n",
        "        print(f\"✅ {len(productos_data)} productos creados\")\n",
        "\n",
        "    def _create_category_and_brand_nodes(self, df_productos: pd.DataFrame):\n",
        "        \"\"\"Crea nodos de categorías y marcas + relaciones\"\"\"\n",
        "        print(\"🏷️ Creando categorías, marcas y relaciones...\")\n",
        "\n",
        "        categorias = df_productos['categoria'].unique()\n",
        "        for categoria in categorias:\n",
        "            query = \"MERGE (c:Categoria {nombre: $nombre})\"\n",
        "            self.conn.execute_write(query, {'nombre': categoria})\n",
        "\n",
        "        marcas = df_productos['marca'].unique()\n",
        "        for marca in marcas:\n",
        "            query = \"MERGE (m:Marca {nombre: $nombre})\"\n",
        "            self.conn.execute_write(query, {'nombre': marca})\n",
        "\n",
        "        query = \"\"\"\n",
        "        MATCH (p:Producto), (c:Categoria), (m:Marca)\n",
        "        WHERE p.id = $id_producto\n",
        "          AND c.nombre = $categoria\n",
        "          AND m.nombre = $marca\n",
        "        MERGE (p)-[:PERTENECE_A]->(c)\n",
        "        MERGE (p)-[:FABRICADO_POR]->(m)\n",
        "        \"\"\"\n",
        "\n",
        "        for _, row in df_productos.iterrows():\n",
        "            self.conn.execute_write(query, {\n",
        "                'id_producto': row['id_producto'],\n",
        "                'categoria': row['categoria'],\n",
        "                'marca': row['marca']\n",
        "            })\n",
        "\n",
        "        print(f\"✅ {len(categorias)} categorías, {len(marcas)} marcas\")\n",
        "\n",
        "    def _create_sucursal_nodes(self, df_inventario: pd.DataFrame):\n",
        "        \"\"\"Crea nodos de sucursales\"\"\"\n",
        "        print(\"🏢 Creando nodos de sucursales...\")\n",
        "\n",
        "        sucursales = df_inventario['sucursal'].unique()\n",
        "        for sucursal in sucursales:\n",
        "            query = \"MERGE (s:Sucursal {nombre: $nombre})\"\n",
        "            self.conn.execute_write(query, {'nombre': sucursal})\n",
        "\n",
        "        print(f\"✅ {len(sucursales)} sucursales creadas\")\n",
        "\n",
        "    def _create_inventory_relationships(self, df_inventario: pd.DataFrame):\n",
        "        \"\"\"Crea relaciones Producto -> Sucursal con stock\"\"\"\n",
        "        print(\"📊 Creando relaciones de inventario...\")\n",
        "\n",
        "        query = \"\"\"\n",
        "        MATCH (p:Producto {id: $id_producto})\n",
        "        MATCH (s:Sucursal {nombre: $sucursal})\n",
        "        MERGE (p)-[r:DISPONIBLE_EN]->(s)\n",
        "        SET r.stock = $stock,\n",
        "            r.precio_sucursal = $precio_sucursal\n",
        "        \"\"\"\n",
        "\n",
        "        count = 0\n",
        "        for _, row in df_inventario.iterrows():\n",
        "            self.conn.execute_write(query, {\n",
        "                'id_producto': row['id_producto'],\n",
        "                'sucursal': row['sucursal'],\n",
        "                'stock': int(row['stock_sucursal']) if pd.notna(row['stock_sucursal']) else 0,\n",
        "                'precio_sucursal': float(row['precio_sucursal']) if pd.notna(row['precio_sucursal']) else 0\n",
        "            })\n",
        "            count += 1\n",
        "\n",
        "        print(f\"✅ {count} relaciones de inventario creadas\")\n",
        "\n",
        "    def _create_compatibility_relationships(self, manuales: List[Dict]):\n",
        "        \"\"\"Extrae y crea relaciones de compatibilidad desde manuales\"\"\"\n",
        "        print(\"🔗 Creando relaciones de compatibilidad...\")\n",
        "\n",
        "        count = 0\n",
        "        for manual in manuales:\n",
        "            if manual.get('tipo_seccion') != 'compatibilidad':\n",
        "                continue\n",
        "\n",
        "            id_producto_origen = manual['id_producto']\n",
        "            contenido = manual['contenido']\n",
        "\n",
        "            productos_encontrados = re.findall(r'P\\d{4}', contenido)\n",
        "            comparte_match = re.search(r'Comparte:\\s*([^\\n]+)', contenido)\n",
        "            comparte = comparte_match.group(1).strip() if comparte_match else \"Componente\"\n",
        "\n",
        "            for id_producto_destino in productos_encontrados:\n",
        "                if id_producto_destino != id_producto_origen:\n",
        "                    query = \"\"\"\n",
        "                    MATCH (p1:Producto {id: $id_origen})\n",
        "                    MATCH (p2:Producto {id: $id_destino})\n",
        "                    MERGE (p1)-[r:COMPATIBLE_CON]->(p2)\n",
        "                    SET r.comparte = $comparte\n",
        "                    \"\"\"\n",
        "\n",
        "                    try:\n",
        "                        self.conn.execute_write(query, {\n",
        "                            'id_origen': id_producto_origen,\n",
        "                            'id_destino': id_producto_destino,\n",
        "                            'comparte': comparte\n",
        "                        })\n",
        "                        count += 1\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "        print(f\"✅ {count} relaciones de compatibilidad creadas\")\n",
        "\n",
        "    def _create_indexes(self):\n",
        "        \"\"\"Crea índices para mejor performance\"\"\"\n",
        "        print(\"📇 Creando índices...\")\n",
        "\n",
        "        indexes = [\n",
        "            \"CREATE INDEX IF NOT EXISTS FOR (p:Producto) ON (p.id)\",\n",
        "            \"CREATE INDEX IF NOT EXISTS FOR (c:Categoria) ON (c.nombre)\",\n",
        "            \"CREATE INDEX IF NOT EXISTS FOR (m:Marca) ON (m.nombre)\",\n",
        "            \"CREATE INDEX IF NOT EXISTS FOR (s:Sucursal) ON (s.nombre)\"\n",
        "        ]\n",
        "\n",
        "        for index_query in indexes:\n",
        "            try:\n",
        "                self.conn.execute_write(index_query)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        print(\"✅ Índices creados\")\n",
        "\n",
        "    def _print_statistics(self):\n",
        "        \"\"\"Imprime estadísticas del grafo\"\"\"\n",
        "        print(\"\\n📊 Estadísticas del grafo:\")\n",
        "\n",
        "        stats = {\n",
        "            'Productos': \"MATCH (p:Producto) RETURN count(p) as count\",\n",
        "            'Categorías': \"MATCH (c:Categoria) RETURN count(c) as count\",\n",
        "            'Marcas': \"MATCH (m:Marca) RETURN count(m) as count\",\n",
        "            'Sucursales': \"MATCH (s:Sucursal) RETURN count(s) as count\",\n",
        "            'Relaciones totales': \"MATCH ()-[r]->() RETURN count(r) as count\",\n",
        "            'Compatibilidades': \"MATCH ()-[r:COMPATIBLE_CON]->() RETURN count(r) as count\"\n",
        "        }\n",
        "\n",
        "        for label, query in stats.items():\n",
        "            result = self.conn.execute_query(query)\n",
        "            count = result[0]['count'] if result else 0\n",
        "            print(f\"  - {label}: {count}\")\n",
        "\n",
        "# ==================== GENERADOR DE QUERIES CYPHER ====================\n",
        "\n",
        "class CypherGenerator:\n",
        "    \"\"\"Genera queries Cypher a partir de lenguaje natural usando GROQ\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "        print(\"🤖 Generador de Cypher inicializado\")\n",
        "\n",
        "    def generate_cypher(self, query: str) -> str:\n",
        "        \"\"\"Genera query Cypher desde lenguaje natural\"\"\"\n",
        "\n",
        "        prompt = f\"\"\"Eres un experto en Neo4j y Cypher.\n",
        "\n",
        "ESQUEMA DEL GRAFO:\n",
        "- (Producto {{id, nombre, marca, precio, stock, potencia, voltaje, garantia_meses}})\n",
        "- (Categoria {{nombre}})\n",
        "- (Marca {{nombre}})\n",
        "- (Sucursal {{nombre}})\n",
        "\n",
        "RELACIONES:\n",
        "- (Producto)-[:PERTENECE_A]->(Categoria)\n",
        "- (Producto)-[:FABRICADO_POR]->(Marca)\n",
        "- (Producto)-[:DISPONIBLE_EN {{stock, precio_sucursal}}]->(Sucursal)\n",
        "- (Producto)-[:COMPATIBLE_CON {{comparte}}]->(Producto)\n",
        "\n",
        "REGLAS DE SINTAXIS CYPHER:\n",
        "1. Direcciones: (A)-[:REL]->(B) o (A)<-[:REL]-(B)\n",
        "2. NUNCA uses: [:REL<-] o [:REL->] (sintaxis inválida)\n",
        "3. Usa MATCH para buscar, CREATE para crear\n",
        "4. Siempre limita resultados con LIMIT (máximo 20)\n",
        "5. Usa DISTINCT para evitar duplicados\n",
        "\n",
        "EJEMPLOS CORRECTOS:\n",
        "\n",
        "Usuario: \"¿Qué productos son compatibles con P0016?\"\n",
        "Cypher: MATCH (p1:Producto {{id: 'P0016'}})-[:COMPATIBLE_CON]->(p2:Producto) RETURN p2.nombre, p2.marca, p2.precio LIMIT 10\n",
        "\n",
        "Usuario: \"Productos de la marca TechHome\"\n",
        "Cypher: MATCH (p:Producto)-[:FABRICADO_POR]->(m:Marca {{nombre: 'TechHome'}}) RETURN p.nombre, p.precio, p.stock LIMIT 10\n",
        "\n",
        "Usuario: \"¿Dónde hay stock del producto P0001?\"\n",
        "Cypher: MATCH (p:Producto {{id: 'P0001'}})-[r:DISPONIBLE_EN]->(s:Sucursal) WHERE r.stock > 0 RETURN s.nombre, r.stock, r.precio_sucursal\n",
        "\n",
        "Usuario: \"Productos de la categoría Cocina\"\n",
        "Cypher: MATCH (p:Producto)-[:PERTENECE_A]->(c:Categoria {{nombre: 'Cocina'}}) RETURN p.nombre, p.marca, p.precio LIMIT 10\n",
        "\n",
        "Usuario: \"¿Qué marcas fabrican productos de Cocina?\"\n",
        "Cypher: MATCH (p:Producto)-[:PERTENECE_A]->(c:Categoria {{nombre: 'Cocina'}}), (p)-[:FABRICADO_POR]->(m:Marca) RETURN DISTINCT m.nombre LIMIT 10\n",
        "\n",
        "Usuario: \"Stock de TechHome por sucursal\"\n",
        "Cypher: MATCH (p:Producto)-[:FABRICADO_POR]->(m:Marca {{nombre: 'TechHome'}}), (p)-[r:DISPONIBLE_EN]->(s:Sucursal) WHERE r.stock > 0 RETURN s.nombre, p.nombre, r.stock ORDER BY s.nombre LIMIT 20\n",
        "\n",
        "CONSULTA: \"{query}\"\n",
        "\n",
        "Responde SOLO con la query Cypher válida, sin explicaciones ni markdown:\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"llama-3.3-70b-versatile\",\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.1,\n",
        "                max_tokens=300\n",
        "            )\n",
        "\n",
        "            cypher = response.choices[0].message.content.strip()\n",
        "\n",
        "            # Limpiar markdown si existe\n",
        "            cypher = re.sub(r'```cypher\\s*', '', cypher)\n",
        "            cypher = re.sub(r'```\\s*', '', cypher)\n",
        "            cypher = cypher.strip()\n",
        "\n",
        "            return cypher\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error generando Cypher: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "# ==================== MOTOR DE CONSULTAS ====================\n",
        "\n",
        "class GraphSearcher:\n",
        "    \"\"\"Motor de consultas para el grafo\"\"\"\n",
        "\n",
        "    def __init__(self, neo4j_conn: Neo4jConnection, cypher_gen: CypherGenerator):\n",
        "        self.conn = neo4j_conn\n",
        "        self.cypher_gen = cypher_gen\n",
        "        print(\"🔍 Motor de búsqueda en grafos inicializado\")\n",
        "\n",
        "    def search(self, query: str) -> List[Dict]:\n",
        "        \"\"\"Consulta el grafo con lenguaje natural\"\"\"\n",
        "\n",
        "        cypher = self.cypher_gen.generate_cypher(query)\n",
        "\n",
        "        if not cypher:\n",
        "            return []\n",
        "\n",
        "        print(f\"🔍 Cypher generado:\\n{cypher}\\n\")\n",
        "\n",
        "        try:\n",
        "            results = self.conn.execute_query(cypher)\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error ejecutando Cypher: {e}\")\n",
        "            return []\n",
        "\n",
        "    def format_results(self, results: List[Dict]) -> str:\n",
        "        \"\"\"Formatea resultados para mostrar\"\"\"\n",
        "        if not results:\n",
        "            return \"No se encontraron resultados.\"\n",
        "\n",
        "        output = f\"Se encontraron {len(results)} resultados:\\n\\n\"\n",
        "\n",
        "        for i, result in enumerate(results[:10], 1):\n",
        "            output += f\"{i}. \"\n",
        "            output += \" | \".join([f\"{k}: {v}\" for k, v in result.items()])\n",
        "            output += \"\\n\"\n",
        "\n",
        "        if len(results) > 10:\n",
        "            output += f\"\\n... y {len(results) - 10} más\"\n",
        "\n",
        "        return output\n",
        "\n",
        "# ==================== INICIALIZACIÓN ====================\n",
        "\n",
        "print(\"🔧 Inicializando base de datos de grafos...\\n\")\n",
        "\n",
        "# Conectar a Neo4j\n",
        "neo4j_conn = Neo4jConnection(\n",
        "    uri=config.NEO4J_URI,\n",
        "    user=config.NEO4J_USER,\n",
        "    password=config.NEO4J_PASSWORD\n",
        ")\n",
        "\n",
        "# Construir grafo\n",
        "graph_builder = GraphBuilder(neo4j_conn)\n",
        "graph_builder.build_graph(dataframes, documents)\n",
        "\n",
        "# Crear generador de Cypher y motor de consultas\n",
        "cypher_generator = CypherGenerator(config.GROQ_API_KEY)\n",
        "graph_searcher = GraphSearcher(neo4j_conn, cypher_generator)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ BASE DE DATOS DE GRAFOS LISTA\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "Interfaz de búsqueda:\n",
        "    results = graph_searcher.search(\"¿Qué productos son compatibles con P0016?\")\n",
        "\"\"\")\n",
        "print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9MsIKME0ZzK",
        "outputId": "94bf6767-1ca1-4f44-c89a-1ed17b1d8363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CONFIGURANDO BASE DE DATOS DE GRAFOS\n",
            "============================================================\n",
            "\n",
            "🔧 Inicializando base de datos de grafos...\n",
            "\n",
            "🔌 Conectando a Neo4j...\n",
            "✅ Conexión exitosa a Neo4j\n",
            "\n",
            "\n",
            "============================================================\n",
            "CONSTRUYENDO GRAFO DE CONOCIMIENTO\n",
            "============================================================\n",
            "\n",
            "🗑️ Limpiando base de datos...\n",
            "✅ Base de datos limpiada\n",
            "📦 Creando nodos de productos...\n",
            "✅ 300 productos creados\n",
            "🏷️ Creando categorías, marcas y relaciones...\n",
            "✅ 4 categorías, 17 marcas\n",
            "🏢 Creando nodos de sucursales...\n",
            "✅ 24 sucursales creadas\n",
            "📊 Creando relaciones de inventario...\n",
            "✅ 4100 relaciones de inventario creadas\n",
            "🔗 Creando relaciones de compatibilidad...\n",
            "✅ 250 relaciones de compatibilidad creadas\n",
            "📇 Creando índices...\n",
            "✅ Índices creados\n",
            "\n",
            "✅ Grafo de conocimiento construido\n",
            "\n",
            "📊 Estadísticas del grafo:\n",
            "  - Productos: 300\n",
            "  - Categorías: 4\n",
            "  - Marcas: 17\n",
            "  - Sucursales: 24\n",
            "  - Relaciones totales: 4950\n",
            "  - Compatibilidades: 250\n",
            "🤖 Generador de Cypher inicializado\n",
            "🔍 Motor de búsqueda en grafos inicializado\n",
            "\n",
            "============================================================\n",
            "✅ BASE DE DATOS DE GRAFOS LISTA\n",
            "============================================================\n",
            "\n",
            "Interfaz de búsqueda:\n",
            "    results = graph_searcher.search(\"¿Qué productos son compatibles con P0016?\")\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 9: PRUEBAS DE BASE DE GRAFOS\n",
        "============================================\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PRUEBAS DE LA BASE DE DATOS DE GRAFOS\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== PRUEBA 1: COMPATIBILIDAD ====================\n",
        "\n",
        "print(\"📝 PRUEBA 1: Productos compatibles\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Qué productos son compatibles con P0016?\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = graph_searcher.search(query)\n",
        "formatted = graph_searcher.format_results(results)\n",
        "print(formatted)\n",
        "\n",
        "# ==================== PRUEBA 2: FILTRO POR MARCA EN GRAFO ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 2: Productos por marca\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"Productos de la marca TechHome\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = graph_searcher.search(query)\n",
        "formatted = graph_searcher.format_results(results)\n",
        "print(formatted)\n",
        "\n",
        "# ==================== PRUEBA 3: STOCK POR SUCURSAL ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 3: Stock por sucursal\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Dónde hay stock del producto P0001?\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = graph_searcher.search(query)\n",
        "formatted = graph_searcher.format_results(results)\n",
        "print(formatted)\n",
        "\n",
        "# ==================== PRUEBA 4: PRODUCTOS POR CATEGORÍA ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 4: Productos por categoría\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Qué productos pertenecen a la categoría Cocina?\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = graph_searcher.search(query)\n",
        "formatted = graph_searcher.format_results(results)\n",
        "print(formatted)\n",
        "\n",
        "# ==================== FUNCIÓN HELPER ====================\n",
        "\n",
        "def buscar_grafo(query: str):\n",
        "    \"\"\"\n",
        "    Función helper para búsquedas rápidas en el grafo\n",
        "\n",
        "    Args:\n",
        "        query: Consulta en lenguaje natural\n",
        "    \"\"\"\n",
        "    print(f\"\\n🔍 Buscando en grafo: '{query}'\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    results = graph_searcher.search(query)\n",
        "    formatted = graph_searcher.format_results(results)\n",
        "    print(formatted)\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"✅ PRUEBAS COMPLETADAS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nFunción helper disponible:\")\n",
        "print(\"  buscar_grafo('tu consulta')\")\n",
        "print(\"\\nEjemplo:\")\n",
        "print(\"  results = buscar_grafo('productos compatibles con P0020')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3fxL0M28LvC",
        "outputId": "3b053e47-2ef3-40d4-f1dc-c6be2d9b84cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PRUEBAS DE LA BASE DE DATOS DE GRAFOS\n",
            "============================================================\n",
            "\n",
            "📝 PRUEBA 1: Productos compatibles\n",
            "------------------------------------------------------------\n",
            "Query: '¿Qué productos son compatibles con P0016?'\n",
            "\n",
            "🔍 Cypher generado:\n",
            "MATCH (p1:Producto {id: 'P0016'})-[:COMPATIBLE_CON]->(p2:Producto) RETURN DISTINCT p2.nombre, p2.marca, p2.precio LIMIT 10\n",
            "\n",
            "Se encontraron 5 resultados:\n",
            "\n",
            "1. p2.nombre: Eco Mixer II | p2.marca: CookElite | p2.precio: 2906.9\n",
            "2. p2.nombre: Deluxe Abridor de Latas | p2.marca: CookElite | p2.precio: 688.19\n",
            "3. p2.nombre: Pava Eléctrica | p2.marca: CookElite | p2.precio: 1051.88\n",
            "4. p2.nombre: Sandwichera | p2.marca: CookElite | p2.precio: 565.96\n",
            "5. p2.nombre: Olla de Cocción Lenta II | p2.marca: CookElite | p2.precio: 1667.94\n",
            "\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 2: Productos por marca\n",
            "------------------------------------------------------------\n",
            "Query: 'Productos de la marca TechHome'\n",
            "\n",
            "⚠️ Error generando Cypher: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 685. Please try again in 9m51.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "No se encontraron resultados.\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 3: Stock por sucursal\n",
            "------------------------------------------------------------\n",
            "Query: '¿Dónde hay stock del producto P0001?'\n",
            "\n",
            "⚠️ Error generando Cypher: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 690. Please try again in 9m56.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "No se encontraron resultados.\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 4: Productos por categoría\n",
            "------------------------------------------------------------\n",
            "Query: '¿Qué productos pertenecen a la categoría Cocina?'\n",
            "\n",
            "⚠️ Error generando Cypher: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 692. Please try again in 9m57.888s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "No se encontraron resultados.\n",
            "\n",
            "\n",
            "============================================================\n",
            "✅ PRUEBAS COMPLETADAS\n",
            "============================================================\n",
            "\n",
            "Función helper disponible:\n",
            "  buscar_grafo('tu consulta')\n",
            "\n",
            "Ejemplo:\n",
            "  results = buscar_grafo('productos compatibles con P0020')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 10: CLASIFICADOR DE INTENCIÓN\n",
        "============================================\n",
        "Compara dos enfoques:\n",
        "1. Clasificador basado en Keywords (baseline)\n",
        "2. Clasificador basado en LLM Few-Shot (GROQ)\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from groq import Groq\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CLASIFICADOR DE INTENCIÓN\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== DATASET SINTÉTICO ====================\n",
        "\n",
        "def create_synthetic_dataset() -> tuple:\n",
        "    \"\"\"Crea dataset sintético para entrenamiento y evaluación\"\"\"\n",
        "\n",
        "    # Ejemplos de cada clase\n",
        "    vectorial_queries = [\n",
        "        \"¿Cómo uso mi licuadora para hacer smoothies?\",\n",
        "        \"¿Qué opinan los usuarios de esta cafetera?\",\n",
        "        \"Mi licuadora no enciende, ¿qué hago?\",\n",
        "        \"¿Cómo limpio mi procesadora?\",\n",
        "        \"¿Es normal que mi batidora haga ruido?\",\n",
        "        \"Instrucciones para usar la picadora\",\n",
        "        \"¿Qué dicen las reseñas del producto P0001?\",\n",
        "        \"¿Cómo se mantiene la licuadora?\",\n",
        "        \"Problemas comunes con el exprimidor\",\n",
        "        \"Manual de uso de la batidora\",\n",
        "        \"¿Cómo preparar masa con la procesadora?\",\n",
        "        \"Opiniones sobre las licuadoras TechHome\",\n",
        "        \"¿Qué hacer si mi producto tiene fugas?\",\n",
        "        \"¿Cómo funciona el modo pulse?\",\n",
        "        \"Feedback de usuarios sobre cafeteras\",\n",
        "        \"¿Es seguro usar la picadora continuamente?\",\n",
        "        \"¿Cómo picar vegetales correctamente?\",\n",
        "        \"Reseñas de la marca ChefMaster\",\n",
        "        \"¿Por qué mi licuadora vibra mucho?\",\n",
        "        \"¿Cómo hacer smoothies cremosos?\"\n",
        "    ]\n",
        "\n",
        "    tabular_queries = [\n",
        "        \"¿Cuáles son las licuadoras de menos de $200?\",\n",
        "        \"Mostrar productos de la marca TechHome\",\n",
        "        \"¿Qué productos tienen garantía mayor a 24 meses?\",\n",
        "        \"Licuadoras con voltaje 220V\",\n",
        "        \"Productos en stock\",\n",
        "        \"¿Cuánto cuesta la procesadora P0013?\",\n",
        "        \"Productos con potencia mayor a 1000W\",\n",
        "        \"Filtrar por color rojo\",\n",
        "        \"¿Qué hay disponible en menos de $150?\",\n",
        "        \"Productos con capacidad de 2 litros\",\n",
        "        \"Mostrar batidoras baratas\",\n",
        "        \"¿Cuál es el precio de la licuadora compacta?\",\n",
        "        \"Productos de la categoría Cocina\",\n",
        "        \"Filtrar por marca HomeChef\",\n",
        "        \"¿Qué productos cuestan menos de $100?\",\n",
        "        \"Stock de productos en sucursal Centro\",\n",
        "        \"Productos con 36 meses de garantía\",\n",
        "        \"¿Cuántas ventas hubo en noviembre?\",\n",
        "        \"Distribución de ventas por método de pago\",\n",
        "        \"Top 10 productos más vendidos\"\n",
        "    ]\n",
        "\n",
        "    grafo_queries = [\n",
        "        \"¿Qué productos son compatibles con P0016?\",\n",
        "        \"Productos relacionados con licuadoras\",\n",
        "        \"¿Qué accesorios hay para la batidora?\",\n",
        "        \"Productos similares al P0001\",\n",
        "        \"¿Qué repuestos comparte con otros productos?\",\n",
        "        \"¿Dónde hay stock del producto P0005?\",\n",
        "        \"Productos de la misma categoría que P0013\",\n",
        "        \"¿Qué productos usan el mismo motor?\",\n",
        "        \"Accesorios compatibles con la picadora\",\n",
        "        \"¿En qué sucursales está disponible P0020?\",\n",
        "        \"Productos relacionados en la categoría cocina\",\n",
        "        \"¿Qué productos comparten componentes con P0008?\",\n",
        "        \"¿Qué marca fabrica productos similares?\",\n",
        "        \"Productos compatibles de TechHome\",\n",
        "        \"¿Dónde puedo conseguir repuestos?\",\n",
        "        \"Productos que comparten cuchillas\",\n",
        "        \"¿Qué otros productos de CookElite son compatibles?\",\n",
        "        \"Stock por sucursal del producto P0001\",\n",
        "        \"Productos relacionados con procesadoras\",\n",
        "        \"¿Qué accesorios son intercambiables?\"\n",
        "    ]\n",
        "\n",
        "    # Crear dataset\n",
        "    queries = vectorial_queries + tabular_queries + grafo_queries\n",
        "    labels = (\n",
        "        ['vectorial'] * len(vectorial_queries) +\n",
        "        ['tabular'] * len(tabular_queries) +\n",
        "        ['grafo'] * len(grafo_queries)\n",
        "    )\n",
        "\n",
        "    return queries, labels\n",
        "\n",
        "# ==================== CLASIFICADOR 1: KEYWORDS (BASELINE) ====================\n",
        "\n",
        "class KeywordClassifier:\n",
        "    \"\"\"Clasificador simple basado en palabras clave\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.vectorial_keywords = [\n",
        "            'cómo', 'como', 'usar', 'funciona', 'problema', 'opinión',\n",
        "            'reseña', 'manual', 'limpiar', 'mantener', 'instrucciones',\n",
        "            'normal', 'seguro', 'hacer', 'preparar', 'feedback', 'dicen',\n",
        "            'opina', 'opinan', 'comentario', 'review'\n",
        "        ]\n",
        "        self.tabular_keywords = [\n",
        "            'precio', 'menos', 'mayor', 'stock', 'cuánto', 'filtrar',\n",
        "            'ventas', 'garantía', 'cuesta', 'disponible', 'voltaje',\n",
        "            'potencia', 'capacidad', 'color', 'categoría', 'marca',\n",
        "            'baratas', 'barato', 'top', 'distribución', 'cantidad',\n",
        "            'cuántos', 'cuántas', 'hay', 'listar', 'mostrar', 'todos',\n",
        "            'por sucursal', 'por marca', 'por categoría', 'agrupado'\n",
        "        ]\n",
        "        self.grafo_keywords = [\n",
        "            'compatible', 'relacionado', 'similar', 'accesorio', 'repuesto',\n",
        "            'donde', 'dónde', 'sucursal', 'comparten', 'mismo', 'misma',\n",
        "            'intercambiable', 'componente', 'motor', 'cuchilla', 'específico',\n",
        "            'producto P', 'P0', 'con el producto'\n",
        "        ]\n",
        "\n",
        "    def predict(self, query: str) -> str:\n",
        "        \"\"\"Predice la clase de una consulta\"\"\"\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        vectorial_score = sum(1 for kw in self.vectorial_keywords if kw in query_lower)\n",
        "        tabular_score = sum(1 for kw in self.tabular_keywords if kw in query_lower)\n",
        "        grafo_score = sum(1 for kw in self.grafo_keywords if kw in query_lower)\n",
        "\n",
        "        scores = {\n",
        "            'vectorial': vectorial_score,\n",
        "            'tabular': tabular_score,\n",
        "            'grafo': grafo_score\n",
        "        }\n",
        "\n",
        "        return max(scores, key=scores.get)\n",
        "\n",
        "    def predict_batch(self, queries: List[str]) -> List[str]:\n",
        "        \"\"\"Predice múltiples consultas\"\"\"\n",
        "        return [self.predict(q) for q in queries]\n",
        "\n",
        "# ==================== CLASIFICADOR 2: LLM FEW-SHOT ====================\n",
        "\n",
        "class LLMClassifier:\n",
        "    \"\"\"Clasificador usando GROQ con Few-Shot Learning\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "\n",
        "        self.prompt_template = \"\"\"Clasifica la siguiente consulta en UNA de estas categorías:\n",
        "\n",
        "CATEGORÍAS:\n",
        "- vectorial: Preguntas sobre USO, FUNCIONAMIENTO, PROBLEMAS, MANTENIMIENTO, OPINIONES de productos\n",
        "- tabular: Consultas de PRECIOS, FILTROS por características, STOCK, ESPECIFICACIONES, VENTAS, AGRUPACIONES, LISTADOS\n",
        "- grafo: Productos RELACIONADOS, COMPATIBILIDAD, ACCESORIOS, SIMILARES con PRODUCTOS ESPECÍFICOS (IDs como P0001)\n",
        "\n",
        "REGLAS:\n",
        "- Si pregunta por \"marcas disponibles\", \"productos por sucursal\", \"cuántos/cuántas\" → tabular\n",
        "- Si menciona ID específico (P0001, P0016) con \"compatible\" o \"relacionado\" → grafo\n",
        "- Si pregunta \"cómo usar\", \"opiniones\", \"problemas\" → vectorial\n",
        "\n",
        "EJEMPLOS:\n",
        "\n",
        "Consulta: \"¿Cómo uso mi licuadora para hacer smoothies?\"\n",
        "Categoría: vectorial\n",
        "\n",
        "Consulta: \"¿Cuáles son las licuadoras de menos de $200?\"\n",
        "Categoría: tabular\n",
        "\n",
        "Consulta: \"¿Qué productos son compatibles con P0016?\"\n",
        "Categoría: grafo\n",
        "\n",
        "Consulta: \"¿Qué opinan los usuarios de esta cafetera?\"\n",
        "Categoría: vectorial\n",
        "\n",
        "Consulta: \"Productos con voltaje 220V\"\n",
        "Categoría: tabular\n",
        "\n",
        "Consulta: \"¿Dónde hay stock del producto P0001?\"\n",
        "Categoría: grafo\n",
        "\n",
        "Consulta: \"¿Qué marcas de heladeras hay disponibles por sucursal?\"\n",
        "Categoría: tabular\n",
        "\n",
        "Consulta: \"Productos relacionados con licuadoras\"\n",
        "Categoría: tabular\n",
        "\n",
        "Consulta: \"¿Qué repuestos comparte el producto P0005 con otros?\"\n",
        "Categoría: grafo\n",
        "\n",
        "CONSULTA: \"{query}\"\n",
        "\n",
        "Responde SOLO con una palabra (vectorial, tabular o grafo):\"\"\"\n",
        "\n",
        "    def predict(self, query: str) -> str:\n",
        "        \"\"\"Predice la clase de una consulta\"\"\"\n",
        "        prompt = self.prompt_template.format(query=query)\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"llama-3.3-70b-versatile\",\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.1,\n",
        "                max_tokens=10\n",
        "            )\n",
        "\n",
        "            prediction = response.choices[0].message.content.strip().lower()\n",
        "\n",
        "            # Validar que sea una clase válida\n",
        "            if prediction in ['vectorial', 'tabular', 'grafo']:\n",
        "                return prediction\n",
        "            else:\n",
        "                # Fallback a keywords\n",
        "                return self._keyword_fallback(query)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error en LLM: {e}\")\n",
        "            return self._keyword_fallback(query)\n",
        "\n",
        "    def _keyword_fallback(self, query: str) -> str:\n",
        "        \"\"\"Clasificación por palabras clave como fallback\"\"\"\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        vectorial_keywords = ['cómo', 'como', 'usar', 'funciona', 'problema', 'opinión', 'reseña']\n",
        "        tabular_keywords = ['precio', 'menos', 'mayor', 'stock', 'cuánto', 'filtrar']\n",
        "        grafo_keywords = ['compatible', 'relacionado', 'similar', 'accesorio', 'donde', 'sucursal']\n",
        "\n",
        "        vectorial_score = sum(1 for kw in vectorial_keywords if kw in query_lower)\n",
        "        tabular_score = sum(1 for kw in tabular_keywords if kw in query_lower)\n",
        "        grafo_score = sum(1 for kw in grafo_keywords if kw in query_lower)\n",
        "\n",
        "        scores = {\n",
        "            'vectorial': vectorial_score,\n",
        "            'tabular': tabular_score,\n",
        "            'grafo': grafo_score\n",
        "        }\n",
        "\n",
        "        return max(scores, key=scores.get)\n",
        "\n",
        "    def predict_batch(self, queries: List[str]) -> List[str]:\n",
        "        \"\"\"Predice múltiples consultas\"\"\"\n",
        "        return [self.predict(q) for q in queries]\n",
        "\n",
        "# ==================== EVALUACIÓN ====================\n",
        "\n",
        "def evaluate_classifier(classifier, X_test: List[str], y_test: List[str], name: str):\n",
        "    \"\"\"Evalúa un clasificador y muestra métricas\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EVALUACIÓN: {name}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Predicciones\n",
        "    y_pred = classifier.predict_batch(X_test)\n",
        "\n",
        "    # Métricas\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        y_test, y_pred,\n",
        "        average='weighted',\n",
        "        zero_division=0\n",
        "    )\n",
        "\n",
        "    print(f\"📊 Métricas globales:\")\n",
        "    print(f\"  Accuracy:  {accuracy:.3f}\")\n",
        "    print(f\"  Precision: {precision:.3f}\")\n",
        "    print(f\"  Recall:    {recall:.3f}\")\n",
        "    print(f\"  F1-Score:  {f1:.3f}\")\n",
        "\n",
        "    print(f\"\\n📋 Reporte por clase:\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "    # Ejemplos de predicciones\n",
        "    print(f\"🔍 Ejemplos de predicciones:\")\n",
        "    for i in range(min(5, len(X_test))):\n",
        "        emoji = \"✅\" if y_pred[i] == y_test[i] else \"❌\"\n",
        "        print(f\"  {emoji} '{X_test[i][:50]}...'\")\n",
        "        print(f\"     Esperado: {y_test[i]} | Predicho: {y_pred[i]}\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'predictions': y_pred\n",
        "    }\n",
        "\n",
        "# ==================== EJECUCIÓN ====================\n",
        "\n",
        "print(\"📊 Creando dataset sintético...\")\n",
        "queries, labels = create_synthetic_dataset()\n",
        "print(f\"✅ Dataset creado: {len(queries)} consultas\")\n",
        "print(f\"  - Vectorial: {labels.count('vectorial')}\")\n",
        "print(f\"  - Tabular: {labels.count('tabular')}\")\n",
        "print(f\"  - Grafo: {labels.count('grafo')}\")\n",
        "\n",
        "# Split train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    queries, labels,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "print(f\"\\n✅ Split completado:\")\n",
        "print(f\"  Train: {len(X_train)} consultas\")\n",
        "print(f\"  Test: {len(X_test)} consultas\")\n",
        "\n",
        "# Clasificador 1: Keywords\n",
        "print(\"\\n🔧 Evaluando Clasificador Baseline (Keywords)...\")\n",
        "keyword_classifier = KeywordClassifier()\n",
        "results_baseline = evaluate_classifier(keyword_classifier, X_test, y_test, \"Baseline (Keywords)\")\n",
        "\n",
        "# Clasificador 2: LLM Few-Shot\n",
        "print(\"\\n🔧 Evaluando Clasificador LLM (Few-Shot)...\")\n",
        "llm_classifier = LLMClassifier(config.GROQ_API_KEY)\n",
        "results_llm = evaluate_classifier(llm_classifier, X_test, y_test, \"LLM Few-Shot (GROQ)\")\n",
        "\n",
        "# Comparación final\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 COMPARACIÓN FINAL\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "import pandas as pd\n",
        "comparison = pd.DataFrame({\n",
        "    'Clasificador': ['Baseline (Keywords)', 'LLM Few-Shot'],\n",
        "    'Accuracy': [results_baseline['accuracy'], results_llm['accuracy']],\n",
        "    'Precision': [results_baseline['precision'], results_llm['precision']],\n",
        "    'Recall': [results_baseline['recall'], results_llm['recall']],\n",
        "    'F1-Score': [results_baseline['f1'], results_llm['f1']]\n",
        "})\n",
        "\n",
        "print(comparison.to_string(index=False))\n",
        "\n",
        "# Seleccionar mejor clasificador\n",
        "best_classifier_name = 'LLM Few-Shot' if results_llm['f1'] > results_baseline['f1'] else 'Baseline'\n",
        "best_classifier = llm_classifier if results_llm['f1'] > results_baseline['f1'] else keyword_classifier\n",
        "\n",
        "print(f\"\\n🏆 MEJOR CLASIFICADOR: {best_classifier_name}\")\n",
        "print(f\"   F1-Score: {max(results_llm['f1'], results_baseline['f1']):.3f}\")\n",
        "\n",
        "# Guardar el mejor clasificador\n",
        "intent_classifier = best_classifier\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ CLASIFICADOR DE INTENCIÓN LISTO\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nUso: intent_classifier.predict('tu consulta')\")\n",
        "print(f\"Clasificador seleccionado: {best_classifier_name}\")\n",
        "print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEyEi9_d81w1",
        "outputId": "aa7963f4-4d17-4e88-cccb-98c16daa16a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CLASIFICADOR DE INTENCIÓN\n",
            "============================================================\n",
            "\n",
            "📊 Creando dataset sintético...\n",
            "✅ Dataset creado: 60 consultas\n",
            "  - Vectorial: 20\n",
            "  - Tabular: 20\n",
            "  - Grafo: 20\n",
            "\n",
            "✅ Split completado:\n",
            "  Train: 42 consultas\n",
            "  Test: 18 consultas\n",
            "\n",
            "🔧 Evaluando Clasificador Baseline (Keywords)...\n",
            "\n",
            "============================================================\n",
            "EVALUACIÓN: Baseline (Keywords)\n",
            "============================================================\n",
            "\n",
            "📊 Métricas globales:\n",
            "  Accuracy:  0.833\n",
            "  Precision: 0.889\n",
            "  Recall:    0.833\n",
            "  F1-Score:  0.822\n",
            "\n",
            "📋 Reporte por clase:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       grafo       1.00      0.50      0.67         6\n",
            "     tabular       0.67      1.00      0.80         6\n",
            "   vectorial       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.83        18\n",
            "   macro avg       0.89      0.83      0.82        18\n",
            "weighted avg       0.89      0.83      0.82        18\n",
            "\n",
            "🔍 Ejemplos de predicciones:\n",
            "  ✅ '¿Cómo limpio mi procesadora?...'\n",
            "     Esperado: vectorial | Predicho: vectorial\n",
            "  ✅ 'Mostrar productos de la marca TechHome...'\n",
            "     Esperado: tabular | Predicho: tabular\n",
            "  ❌ 'Productos de la misma categoría que P0013...'\n",
            "     Esperado: grafo | Predicho: tabular\n",
            "  ❌ '¿Qué marca fabrica productos similares?...'\n",
            "     Esperado: grafo | Predicho: tabular\n",
            "  ✅ 'Problemas comunes con el exprimidor...'\n",
            "     Esperado: vectorial | Predicho: vectorial\n",
            "\n",
            "🔧 Evaluando Clasificador LLM (Few-Shot)...\n",
            "\n",
            "============================================================\n",
            "EVALUACIÓN: LLM Few-Shot (GROQ)\n",
            "============================================================\n",
            "\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 485. Please try again in 6m59.04s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 486. Please try again in 6m59.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 488. Please try again in 7m1.632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 486. Please try again in 6m59.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100000, Requested 488. Please try again in 7m1.632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 485. Please try again in 6m58.176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 488. Please try again in 7m0.768s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 486. Please try again in 6m59.04s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 488. Please try again in 7m0.768s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 487. Please try again in 6m59.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 491. Please try again in 7m3.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 486. Please try again in 6m59.04s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 492. Please try again in 7m4.224s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 487. Please try again in 6m59.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 486. Please try again in 6m59.04s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 486. Please try again in 6m59.04s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 487. Please try again in 6m59.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "⚠️ Error en LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99999, Requested 491. Please try again in 7m3.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "📊 Métricas globales:\n",
            "  Accuracy:  0.611\n",
            "  Precision: 0.821\n",
            "  Recall:    0.611\n",
            "  F1-Score:  0.599\n",
            "\n",
            "📋 Reporte por clase:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       grafo       1.00      0.33      0.50         6\n",
            "     tabular       1.00      0.50      0.67         6\n",
            "   vectorial       0.46      1.00      0.63         6\n",
            "\n",
            "    accuracy                           0.61        18\n",
            "   macro avg       0.82      0.61      0.60        18\n",
            "weighted avg       0.82      0.61      0.60        18\n",
            "\n",
            "🔍 Ejemplos de predicciones:\n",
            "  ✅ '¿Cómo limpio mi procesadora?...'\n",
            "     Esperado: vectorial | Predicho: vectorial\n",
            "  ❌ 'Mostrar productos de la marca TechHome...'\n",
            "     Esperado: tabular | Predicho: vectorial\n",
            "  ❌ 'Productos de la misma categoría que P0013...'\n",
            "     Esperado: grafo | Predicho: vectorial\n",
            "  ✅ '¿Qué marca fabrica productos similares?...'\n",
            "     Esperado: grafo | Predicho: grafo\n",
            "  ✅ 'Problemas comunes con el exprimidor...'\n",
            "     Esperado: vectorial | Predicho: vectorial\n",
            "\n",
            "============================================================\n",
            "📊 COMPARACIÓN FINAL\n",
            "============================================================\n",
            "\n",
            "       Clasificador  Accuracy  Precision   Recall  F1-Score\n",
            "Baseline (Keywords)  0.833333   0.888889 0.833333  0.822222\n",
            "       LLM Few-Shot  0.611111   0.820513 0.611111  0.599415\n",
            "\n",
            "🏆 MEJOR CLASIFICADOR: Baseline\n",
            "   F1-Score: 0.822\n",
            "\n",
            "============================================================\n",
            "✅ CLASIFICADOR DE INTENCIÓN LISTO\n",
            "============================================================\n",
            "\n",
            "Uso: intent_classifier.predict('tu consulta')\n",
            "Clasificador seleccionado: Baseline\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 11: PIPELINE DE RECUPERACIÓN\n",
        "============================================\n",
        "Integra las 3 fuentes de datos:\n",
        "- Vectorial (ChromaDB + búsqueda híbrida)\n",
        "- Tabular (Pandas con filtros dinámicos)\n",
        "- Grafo (Neo4j con Cypher dinámico)\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, List, Optional\n",
        "import json\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PIPELINE DE RECUPERACIÓN INTEGRADO\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== PIPELINE DE RECUPERACIÓN ====================\n",
        "\n",
        "class RetrievalPipeline:\n",
        "    \"\"\"\n",
        "    Pipeline que integra las 3 fuentes de datos y el clasificador de intención\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vector_search,\n",
        "        table_search,\n",
        "        graph_search,\n",
        "        classifier\n",
        "    ):\n",
        "        self.vector_search = vector_search\n",
        "        self.table_search = table_search\n",
        "        self.graph_search = graph_search\n",
        "        self.classifier = classifier\n",
        "\n",
        "        print(\"🔧 Pipeline de recuperación inicializado\")\n",
        "        print(\"   ✅ Búsqueda vectorial (ChromaDB)\")\n",
        "        print(\"   ✅ Búsqueda tabular (Pandas)\")\n",
        "        print(\"   ✅ Búsqueda en grafos (Neo4j)\")\n",
        "        print(\"   ✅ Clasificador de intención\")\n",
        "\n",
        "    def retrieve(self, query: str, top_k: int = 5) -> Dict:\n",
        "        \"\"\"\n",
        "        Recupera información relevante según la consulta\n",
        "\n",
        "        Args:\n",
        "            query: Consulta del usuario\n",
        "            top_k: Número de resultados a retornar\n",
        "\n",
        "        Returns:\n",
        "            Dict con: intent, source, results, context\n",
        "        \"\"\"\n",
        "\n",
        "        # 1. Clasificar intención\n",
        "        intent = self.classifier.predict(query)\n",
        "        print(f\"\\n🎯 Intención detectada: {intent}\")\n",
        "\n",
        "        # 2. Recuperar según intención\n",
        "        if intent == 'vectorial':\n",
        "            results = self._retrieve_vectorial(query, top_k)\n",
        "            source = 'vectorial'\n",
        "        elif intent == 'tabular':\n",
        "            results = self._retrieve_tabular(query, top_k)\n",
        "            source = 'tabular'\n",
        "        elif intent == 'grafo':\n",
        "            results = self._retrieve_grafo(query, top_k)\n",
        "            source = 'grafo'\n",
        "        else:\n",
        "            results = []\n",
        "            source = 'unknown'\n",
        "\n",
        "        # 3. Formatear contexto\n",
        "        context = self._format_context(results, source)\n",
        "\n",
        "        # 4. Calcular número de resultados\n",
        "        import pandas as pd\n",
        "        if isinstance(results, pd.DataFrame):\n",
        "            num_results = len(results)\n",
        "        elif isinstance(results, list):\n",
        "            num_results = len(results)\n",
        "        else:\n",
        "            num_results = 0\n",
        "\n",
        "        return {\n",
        "            'intent': intent,\n",
        "            'source': source,\n",
        "            'results': results,\n",
        "            'context': context,\n",
        "            'num_results': num_results\n",
        "        }\n",
        "\n",
        "    def _retrieve_vectorial(self, query: str, top_k: int) -> List[Dict]:\n",
        "        \"\"\"Recupera de la base vectorial\"\"\"\n",
        "        print(f\"📚 Buscando en base vectorial (híbrida + rerank)...\")\n",
        "\n",
        "        results = self.vector_search.search(query, top_k=top_k)\n",
        "\n",
        "        print(f\"   ✅ {len(results)} documentos recuperados\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _retrieve_tabular(self, query: str, top_k: int):\n",
        "        \"\"\"Recupera de las tablas\"\"\"\n",
        "        print(f\"📊 Buscando en base tabular (Pandas)...\")\n",
        "\n",
        "        # Intentar búsqueda en productos primero\n",
        "        results = self.table_search.search(query, 'productos', max_results=top_k)\n",
        "\n",
        "        # Si no hay resultados, intentar en ventas\n",
        "        if len(results) == 0:\n",
        "            results = self.table_search.search(query, 'ventas', max_results=top_k)\n",
        "\n",
        "        print(f\"   ✅ {len(results)} filas recuperadas\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _retrieve_grafo(self, query: str, top_k: int = 10) -> List[Dict]:\n",
        "        \"\"\"Recupera del grafo\"\"\"\n",
        "        print(f\"🕸️ Buscando en base de grafos (Neo4j)...\")\n",
        "\n",
        "        results = self.graph_search.search(query)\n",
        "\n",
        "        # Limitar resultados\n",
        "        if len(results) > top_k:\n",
        "            results = results[:top_k]\n",
        "\n",
        "        print(f\"   ✅ {len(results)} nodos/relaciones recuperados\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _format_context(self, results, source: str) -> str:\n",
        "        \"\"\"Formatea los resultados como contexto para el LLM\"\"\"\n",
        "\n",
        "        import pandas as pd\n",
        "\n",
        "        # Verificar si hay resultados según el tipo\n",
        "        is_empty = False\n",
        "        if isinstance(results, pd.DataFrame):\n",
        "            is_empty = results.empty\n",
        "        elif isinstance(results, list):\n",
        "            is_empty = len(results) == 0\n",
        "        else:\n",
        "            is_empty = not results\n",
        "\n",
        "        if is_empty:\n",
        "            return \"No se encontró información relevante para responder esta consulta.\"\n",
        "\n",
        "        context = f\"INFORMACIÓN RECUPERADA (Fuente: {source}):\\n\\n\"\n",
        "\n",
        "        if source == 'vectorial':\n",
        "            # Resultados de ChromaDB\n",
        "            for i, result in enumerate(results, 1):\n",
        "                context += f\"{i}. {result['text'][:300]}...\\n\"\n",
        "                context += f\"   [Fuente: {result['metadata'].get('source', 'N/A')}]\\n\\n\"\n",
        "\n",
        "        elif source == 'tabular':\n",
        "            # Resultados de Pandas DataFrame\n",
        "            if isinstance(results, pd.DataFrame):\n",
        "                # Convertir a diccionarios\n",
        "                records = results.head(10).to_dict('records')\n",
        "                for i, record in enumerate(records, 1):\n",
        "                    context += f\"{i}. \"\n",
        "                    context += \" | \".join([f\"{k}: {v}\" for k, v in record.items() if pd.notna(v)])\n",
        "                    context += \"\\n\"\n",
        "            else:\n",
        "                context += str(results)\n",
        "\n",
        "        elif source == 'grafo':\n",
        "            # Resultados de Neo4j\n",
        "            for i, result in enumerate(results, 1):\n",
        "                context += f\"{i}. \"\n",
        "                context += \" | \".join([f\"{k}: {v}\" for k, v in result.items()])\n",
        "                context += \"\\n\"\n",
        "\n",
        "        return context.strip()\n",
        "\n",
        "    def get_stats(self) -> Dict:\n",
        "        \"\"\"Retorna estadísticas del pipeline\"\"\"\n",
        "        return {\n",
        "            'classifier': type(self.classifier).__name__,\n",
        "            'vector_db': 'ChromaDB + Hybrid Search',\n",
        "            'table_db': 'Pandas DataFrames',\n",
        "            'graph_db': 'Neo4j'\n",
        "        }\n",
        "\n",
        "# ==================== INICIALIZACIÓN ====================\n",
        "\n",
        "print(\"🔧 Inicializando pipeline de recuperación...\\n\")\n",
        "\n",
        "# Crear pipeline con todos los componentes\n",
        "retrieval_pipeline = RetrievalPipeline(\n",
        "    vector_search=hybrid_search,      # De celda 4\n",
        "    table_search=table_searcher,      # De celda 6\n",
        "    graph_search=graph_searcher,      # De celda 8\n",
        "    classifier=intent_classifier      # De celda 10\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ PIPELINE DE RECUPERACIÓN LISTO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Mostrar estadísticas\n",
        "stats = retrieval_pipeline.get_stats()\n",
        "print(f\"\"\"\n",
        "Componentes integrados:\n",
        "  - Clasificador: {stats['classifier']}\n",
        "  - Base vectorial: {stats['vector_db']}\n",
        "  - Base tabular: {stats['table_db']}\n",
        "  - Base de grafos: {stats['graph_db']}\n",
        "\n",
        "Uso:\n",
        "  result = retrieval_pipeline.retrieve(\"¿Cómo usar mi licuadora?\", top_k=5)\n",
        "\n",
        "  print(result['intent'])    # Intención detectada\n",
        "  print(result['source'])    # Fuente de datos usada\n",
        "  print(result['context'])   # Contexto formateado para LLM\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfG8HH3Ww9Rs",
        "outputId": "b666b804-2f2a-455c-f68d-acff5a310290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PIPELINE DE RECUPERACIÓN INTEGRADO\n",
            "============================================================\n",
            "\n",
            "🔧 Inicializando pipeline de recuperación...\n",
            "\n",
            "🔧 Pipeline de recuperación inicializado\n",
            "   ✅ Búsqueda vectorial (ChromaDB)\n",
            "   ✅ Búsqueda tabular (Pandas)\n",
            "   ✅ Búsqueda en grafos (Neo4j)\n",
            "   ✅ Clasificador de intención\n",
            "\n",
            "============================================================\n",
            "✅ PIPELINE DE RECUPERACIÓN LISTO\n",
            "============================================================\n",
            "\n",
            "Componentes integrados:\n",
            "  - Clasificador: KeywordClassifier\n",
            "  - Base vectorial: ChromaDB + Hybrid Search\n",
            "  - Base tabular: Pandas DataFrames\n",
            "  - Base de grafos: Neo4j\n",
            "\n",
            "Uso:\n",
            "  result = retrieval_pipeline.retrieve(\"¿Cómo usar mi licuadora?\", top_k=5)\n",
            "\n",
            "  print(result['intent'])    # Intención detectada\n",
            "  print(result['source'])    # Fuente de datos usada\n",
            "  print(result['context'])   # Contexto formateado para LLM\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 12: PRUEBAS DEL PIPELINE DE RECUPERACIÓN\n",
        "============================================\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PRUEBAS DEL PIPELINE DE RECUPERACIÓN\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== PRUEBA 1: CONSULTA VECTORIAL ====================\n",
        "\n",
        "print(\"📝 PRUEBA 1: Consulta vectorial (uso de producto)\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Cómo uso mi licuadora para hacer smoothies?\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "result = retrieval_pipeline.retrieve(query, top_k=3)\n",
        "\n",
        "print(f\"\\n📋 Resultado:\")\n",
        "print(f\"  Intención: {result['intent']}\")\n",
        "print(f\"  Fuente: {result['source']}\")\n",
        "print(f\"  Documentos recuperados: {result['num_results']}\")\n",
        "print(f\"\\n📄 Contexto generado:\")\n",
        "print(result['context'][:500] + \"...\" if len(result['context']) > 500 else result['context'])\n",
        "\n",
        "# ==================== PRUEBA 2: CONSULTA TABULAR ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 2: Consulta tabular (filtro de precios)\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Cuáles son las licuadoras de menos de $300?\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "result = retrieval_pipeline.retrieve(query, top_k=5)\n",
        "\n",
        "print(f\"\\n📋 Resultado:\")\n",
        "print(f\"  Intención: {result['intent']}\")\n",
        "print(f\"  Fuente: {result['source']}\")\n",
        "print(f\"  Productos recuperados: {result['num_results']}\")\n",
        "print(f\"\\n📄 Contexto generado:\")\n",
        "print(result['context'][:500] + \"...\" if len(result['context']) > 500 else result['context'])\n",
        "\n",
        "# ==================== PRUEBA 3: CONSULTA GRAFO ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 3: Consulta grafo (compatibilidad)\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Qué productos son compatibles con P0016?\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "result = retrieval_pipeline.retrieve(query, top_k=5)\n",
        "\n",
        "print(f\"\\n📋 Resultado:\")\n",
        "print(f\"  Intención: {result['intent']}\")\n",
        "print(f\"  Fuente: {result['source']}\")\n",
        "print(f\"  Relaciones recuperadas: {result['num_results']}\")\n",
        "print(f\"\\n📄 Contexto generado:\")\n",
        "print(result['context'][:500] + \"...\" if len(result['context']) > 500 else result['context'])\n",
        "\n",
        "# ==================== PRUEBA 4: OPINIONES ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 4: Consulta vectorial (opiniones)\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Qué opinan los usuarios de las licuadoras TechHome?\"\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "result = retrieval_pipeline.retrieve(query, top_k=3)\n",
        "\n",
        "print(f\"\\n📋 Resultado:\")\n",
        "print(f\"  Intención: {result['intent']}\")\n",
        "print(f\"  Fuente: {result['source']}\")\n",
        "print(f\"  Documentos recuperados: {result['num_results']}\")\n",
        "print(f\"\\n📄 Contexto generado:\")\n",
        "print(result['context'][:500] + \"...\" if len(result['context']) > 500 else result['context'])\n",
        "\n",
        "# ==================== FUNCIÓN HELPER ====================\n",
        "\n",
        "def buscar(query: str, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Función helper para búsquedas rápidas\n",
        "\n",
        "    Args:\n",
        "        query: Consulta del usuario\n",
        "        top_k: Número de resultados\n",
        "    \"\"\"\n",
        "    print(f\"\\n🔍 Buscando: '{query}'\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    result = retrieval_pipeline.retrieve(query, top_k)\n",
        "\n",
        "    print(f\"\\n📊 Resumen:\")\n",
        "    print(f\"  Intención: {result['intent']}\")\n",
        "    print(f\"  Fuente: {result['source']}\")\n",
        "    print(f\"  Resultados: {result['num_results']}\")\n",
        "    print(f\"\\n💬 Contexto:\")\n",
        "    print(result['context'][:300] + \"...\" if len(result['context']) > 300 else result['context'])\n",
        "\n",
        "    return result\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"✅ PRUEBAS COMPLETADAS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nFunción helper disponible:\")\n",
        "print(\"  buscar('tu consulta', top_k=5)\")\n",
        "print(\"\\nEjemplo:\")\n",
        "print(\"  result = buscar('productos con garantía mayor a 24 meses')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9eBc7YMwGhM",
        "outputId": "68e0e43d-c503-4d37-d651-3c13639f95a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PRUEBAS DEL PIPELINE DE RECUPERACIÓN\n",
            "============================================================\n",
            "\n",
            "📝 PRUEBA 1: Consulta vectorial (uso de producto)\n",
            "------------------------------------------------------------\n",
            "Query: '¿Cómo uso mi licuadora para hacer smoothies?'\n",
            "\n",
            "\n",
            "🎯 Intención detectada: vectorial\n",
            "📚 Buscando en base vectorial (híbrida + rerank)...\n",
            "   ✅ 3 documentos recuperados\n",
            "\n",
            "📋 Resultado:\n",
            "  Intención: vectorial\n",
            "  Fuente: vectorial\n",
            "  Documentos recuperados: 3\n",
            "\n",
            "📄 Contexto generado:\n",
            "INFORMACIÓN RECUPERADA (Fuente: vectorial):\n",
            "\n",
            "1. INSTRUCCIONES DE USO - Pregunta: ¿Cómo se usa correctamente este producto?\n",
            "Respuesta: El Licuadora de TechHome está diseñado para uso doméstico. Revise el manual del producto (código P0001) para más detalles. Ante cualquier duda, contacte a nuestro servicio de atención al cliente....\n",
            "   [Fuente: faq]\n",
            "\n",
            "2. INSTRUCCIONES DE USO - Pregunta: ¿Cómo se usa correctamente este producto?\n",
            "Respuesta: El Licuadora de TechHome está diseñado para uso doméstico. R...\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 2: Consulta tabular (filtro de precios)\n",
            "------------------------------------------------------------\n",
            "Query: '¿Cuáles son las licuadoras de menos de $300?'\n",
            "\n",
            "\n",
            "🎯 Intención detectada: tabular\n",
            "📊 Buscando en base tabular (Pandas)...\n",
            "⚠️ Error generando filtros: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99996, Requested 693. Please try again in 9m55.296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "🔍 Filtros generados: {\n",
            "  \"filters\": []\n",
            "}\n",
            "   ✅ 5 filas recuperadas\n",
            "\n",
            "📋 Resultado:\n",
            "  Intención: tabular\n",
            "  Fuente: tabular\n",
            "  Productos recuperados: 5\n",
            "\n",
            "📄 Contexto generado:\n",
            "INFORMACIÓN RECUPERADA (Fuente: tabular):\n",
            "\n",
            "1. id_producto: P0001 | nombre: Licuadora | categoria: Cocina | subcategoria: Preparación | marca: TechHome | precio_usd: 283.63 | stock: 108 | color: Blanco | potencia_w: 650.0 | capacidad: 1.2L | voltaje: 12V | peso_kg: 5.6 | garantia_meses: 36 | descripcion: Descubrí el poder de la Licuadora de TechHome, diseñada para transformar tu experiencia en la cocina. Con su motor de 650W, esta licuadora procesa ingredientes con una eficiencia incomparable. Su...\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 3: Consulta grafo (compatibilidad)\n",
            "------------------------------------------------------------\n",
            "Query: '¿Qué productos son compatibles con P0016?'\n",
            "\n",
            "\n",
            "🎯 Intención detectada: grafo\n",
            "🕸️ Buscando en base de grafos (Neo4j)...\n",
            "⚠️ Error generando Cypher: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99996, Requested 689. Please try again in 9m51.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "   ✅ 0 nodos/relaciones recuperados\n",
            "\n",
            "📋 Resultado:\n",
            "  Intención: grafo\n",
            "  Fuente: grafo\n",
            "  Relaciones recuperadas: 0\n",
            "\n",
            "📄 Contexto generado:\n",
            "No se encontró información relevante para responder esta consulta.\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 4: Consulta vectorial (opiniones)\n",
            "------------------------------------------------------------\n",
            "Query: '¿Qué opinan los usuarios de las licuadoras TechHome?'\n",
            "\n",
            "\n",
            "🎯 Intención detectada: vectorial\n",
            "📚 Buscando en base vectorial (híbrida + rerank)...\n",
            "   ✅ 3 documentos recuperados\n",
            "\n",
            "📋 Resultado:\n",
            "  Intención: vectorial\n",
            "  Fuente: vectorial\n",
            "  Documentos recuperados: 3\n",
            "\n",
            "📄 Contexto generado:\n",
            "INFORMACIÓN RECUPERADA (Fuente: vectorial):\n",
            "\n",
            "1. INSTRUCCIONES DE USO - Pregunta: ¿Puedo usarlo todos los días?\n",
            "Respuesta: El Licuadora de TechHome está diseñado para uso doméstico. Revise el manual del producto (código P0002) para más detalles. Ante cualquier duda, contacte a nuestro servicio de atención al cliente....\n",
            "   [Fuente: faq]\n",
            "\n",
            "2. INSTRUCCIONES DE USO - Pregunta: ¿Es seguro para uso continuo?\n",
            "Respuesta: El Licuadora de TechHome está diseñado para uso doméstico. Revise el manual del prod...\n",
            "\n",
            "\n",
            "============================================================\n",
            "✅ PRUEBAS COMPLETADAS\n",
            "============================================================\n",
            "\n",
            "Función helper disponible:\n",
            "  buscar('tu consulta', top_k=5)\n",
            "\n",
            "Ejemplo:\n",
            "  result = buscar('productos con garantía mayor a 24 meses')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 13: LLM GENERATOR\n",
        "============================================\n",
        "Wrapper unificado para generación de respuestas con GROQ\n",
        "Soporta múltiples modelos y manejo de errores\n",
        "\"\"\"\n",
        "\n",
        "from groq import Groq\n",
        "from typing import List, Dict, Optional\n",
        "import time\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LLM GENERATOR\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== LLM GENERATOR ====================\n",
        "\n",
        "class LLMGenerator:\n",
        "    \"\"\"\n",
        "    Generador de respuestas usando GROQ (LLama 3.3 70B)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        api_key: str,\n",
        "        model: str = \"llama-3.3-70b-versatile\",\n",
        "        temperature: float = 0.7,\n",
        "        max_tokens: int = 1024\n",
        "    ):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "        self.max_tokens = max_tokens\n",
        "\n",
        "        print(f\"🤖 LLM Generator inicializado\")\n",
        "        print(f\"   Proveedor: GROQ\")\n",
        "        print(f\"   Modelo: {model}\")\n",
        "        print(f\"   Temperature: {temperature}\")\n",
        "        print(f\"   Max tokens: {max_tokens}\")\n",
        "\n",
        "    def generate(\n",
        "        self,\n",
        "        query: str,\n",
        "        context: str,\n",
        "        system_prompt: Optional[str] = None,\n",
        "        conversational_history: Optional[List[Dict]] = None\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Genera una respuesta basada en el contexto\n",
        "\n",
        "        Args:\n",
        "            query: Pregunta del usuario\n",
        "            context: Contexto recuperado\n",
        "            system_prompt: Prompt del sistema (opcional)\n",
        "            conversational_history: Historial de conversación (opcional)\n",
        "\n",
        "        Returns:\n",
        "            Dict con: response, model, tokens, time\n",
        "        \"\"\"\n",
        "\n",
        "        # System prompt por defecto\n",
        "        if system_prompt is None:\n",
        "            system_prompt = \"\"\"Eres un asistente virtual experto en electrodomésticos.\n",
        "\n",
        "Instrucciones:\n",
        "1. Responde SIEMPRE en español\n",
        "2. Usa SOLO la información del contexto proporcionado\n",
        "3. Si no hay información suficiente, dilo claramente y sugiere reformular la pregunta\n",
        "4. Sé claro, conciso y útil\n",
        "5. Cita información específica cuando sea relevante (ej: \"El producto P0001...\")\n",
        "6. Mantén un tono profesional pero amigable\n",
        "\n",
        "IMPORTANTE: NO inventes información. Si el contexto no contiene la respuesta, indícalo.\"\"\"\n",
        "\n",
        "        # Construir mensajes\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt}\n",
        "        ]\n",
        "\n",
        "        # Agregar historial conversacional si existe\n",
        "        if conversational_history:\n",
        "            messages.extend(conversational_history)\n",
        "\n",
        "        # Agregar query actual con contexto\n",
        "        user_message = f\"\"\"CONTEXTO:\n",
        "{context}\n",
        "\n",
        "PREGUNTA DEL USUARIO:\n",
        "{query}\n",
        "\n",
        "Responde basándote SOLO en el contexto proporcionado:\"\"\"\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "        # Generar respuesta\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=messages,\n",
        "                temperature=self.temperature,\n",
        "                max_tokens=self.max_tokens,\n",
        "                top_p=0.9\n",
        "            )\n",
        "\n",
        "            elapsed_time = time.time() - start_time\n",
        "\n",
        "            return {\n",
        "                'response': response.choices[0].message.content,\n",
        "                'model': self.model,\n",
        "                'tokens': {\n",
        "                    'prompt': response.usage.prompt_tokens,\n",
        "                    'completion': response.usage.completion_tokens,\n",
        "                    'total': response.usage.total_tokens\n",
        "                },\n",
        "                'time': elapsed_time,\n",
        "                'success': True,\n",
        "                'error': None\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            elapsed_time = time.time() - start_time\n",
        "\n",
        "            return {\n",
        "                'response': f\"Lo siento, hubo un error al generar la respuesta: {str(e)}\",\n",
        "                'model': self.model,\n",
        "                'tokens': None,\n",
        "                'time': elapsed_time,\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "    def generate_simple(self, query: str, context: str) -> str:\n",
        "        \"\"\"\n",
        "        Versión simplificada que solo retorna el texto de respuesta\n",
        "\n",
        "        Args:\n",
        "            query: Pregunta del usuario\n",
        "            context: Contexto recuperado\n",
        "\n",
        "        Returns:\n",
        "            Texto de la respuesta\n",
        "        \"\"\"\n",
        "        result = self.generate(query, context)\n",
        "        return result['response']\n",
        "\n",
        "    def get_model_info(self) -> Dict:\n",
        "        \"\"\"Retorna información del modelo\"\"\"\n",
        "        return {\n",
        "            'provider': 'GROQ',\n",
        "            'model': self.model,\n",
        "            'temperature': self.temperature,\n",
        "            'max_tokens': self.max_tokens,\n",
        "            'location': 'Cloud (GROQ API)'\n",
        "        }\n",
        "\n",
        "# ==================== INICIALIZACIÓN ====================\n",
        "\n",
        "print(\"\\n🔧 Inicializando LLM Generator...\\n\")\n",
        "\n",
        "# Crear generador LLM\n",
        "llm_generator = LLMGenerator(\n",
        "    api_key=config.GROQ_API_KEY,\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ LLM GENERATOR LISTO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Mostrar información del modelo\n",
        "model_info = llm_generator.get_model_info()\n",
        "print(f\"\"\"\n",
        "Información del modelo:\n",
        "  - Proveedor: {model_info['provider']}\n",
        "  - Modelo: {model_info['model']}\n",
        "  - Ubicación: {model_info['location']}\n",
        "  - Temperature: {model_info['temperature']}\n",
        "  - Max tokens: {model_info['max_tokens']}\n",
        "\n",
        "Justificación de elección:\n",
        "  ✅ GROQ ofrece inferencia ultra-rápida (>300 tokens/seg)\n",
        "  ✅ LLama 3.3 70B es un modelo de alta calidad\n",
        "  ✅ API gratuita con límites generosos\n",
        "  ✅ Sin filtros restrictivos (a diferencia de Gemini)\n",
        "  ✅ Ideal para producción y desarrollo\n",
        "\n",
        "Uso:\n",
        "  result = llm_generator.generate(query, context)\n",
        "  print(result['response'])\n",
        "\n",
        "  # O simplificado:\n",
        "  response = llm_generator.generate_simple(query, context)\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjashVQxyM0N",
        "outputId": "86b96535-4219-4668-d8a3-dcf7add87cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "LLM GENERATOR\n",
            "============================================================\n",
            "\n",
            "\n",
            "🔧 Inicializando LLM Generator...\n",
            "\n",
            "🤖 LLM Generator inicializado\n",
            "   Proveedor: GROQ\n",
            "   Modelo: llama-3.3-70b-versatile\n",
            "   Temperature: 0.7\n",
            "   Max tokens: 1024\n",
            "\n",
            "============================================================\n",
            "✅ LLM GENERATOR LISTO\n",
            "============================================================\n",
            "\n",
            "Información del modelo:\n",
            "  - Proveedor: GROQ\n",
            "  - Modelo: llama-3.3-70b-versatile\n",
            "  - Ubicación: Cloud (GROQ API)\n",
            "  - Temperature: 0.7\n",
            "  - Max tokens: 1024\n",
            "\n",
            "Justificación de elección:\n",
            "  ✅ GROQ ofrece inferencia ultra-rápida (>300 tokens/seg)\n",
            "  ✅ LLama 3.3 70B es un modelo de alta calidad\n",
            "  ✅ API gratuita con límites generosos\n",
            "  ✅ Sin filtros restrictivos (a diferencia de Gemini)\n",
            "  ✅ Ideal para producción y desarrollo\n",
            "\n",
            "Uso:\n",
            "  result = llm_generator.generate(query, context)\n",
            "  print(result['response'])\n",
            "\n",
            "  # O simplificado:\n",
            "  response = llm_generator.generate_simple(query, context)\n",
            "\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 14: PRUEBAS DEL LLM GENERATOR\n",
        "============================================\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PRUEBAS DEL LLM GENERATOR\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== PRUEBA 1: GENERACIÓN SIMPLE ====================\n",
        "\n",
        "print(\"📝 PRUEBA 1: Generación simple con contexto\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Cómo uso mi licuadora?\"\n",
        "context = \"\"\"INFORMACIÓN RECUPERADA (Fuente: vectorial):\n",
        "\n",
        "1. INSTRUCCIONES DE USO PASO A PASO - Procedimientos de Uso\n",
        "Para preparar smoothies: 1) Cortar frutas en trozos pequeños, 2) Agregar líquido primero,\n",
        "3) Agregar frutas congeladas al final, 4) Usar modo pulse para romper hielo...\n",
        "   [Fuente: manual]\n",
        "\n",
        "2. INSTRUCCIONES DE USO - Pregunta: ¿Cómo preparar smoothies con la licuadora?\n",
        "Respuesta: Para mejores resultados, agregue primero los líquidos, luego frutas suaves\n",
        "y finalmente hielo o frutas congeladas...\n",
        "   [Fuente: faq]\n",
        "\"\"\"\n",
        "\n",
        "print(f\"Query: '{query}'\")\n",
        "print(f\"\\nContexto proporcionado: {len(context)} caracteres\")\n",
        "print(\"\\n🤖 Generando respuesta...\\n\")\n",
        "\n",
        "result = llm_generator.generate(query, context)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"RESPUESTA GENERADA:\")\n",
        "print(\"=\"*60)\n",
        "print(result['response'])\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n📊 Estadísticas:\")\n",
        "print(f\"  ✅ Éxito: {result['success']}\")\n",
        "print(f\"  ⏱️  Tiempo: {result['time']:.2f}s\")\n",
        "\n",
        "if result.get('tokens'):\n",
        "    print(f\"  🔢 Tokens prompt: {result['tokens'].get('prompt', 'N/A')}\")\n",
        "    print(f\"  🔢 Tokens completados: {result['tokens'].get('completion', 'N/A')}\")\n",
        "    print(f\"  🔢 Tokens totales: {result['tokens'].get('total', 'N/A')}\")\n",
        "else:\n",
        "    print(f\"  🔢 Tokens: N/A (error en la solicitud)\")\n",
        "\n",
        "\n",
        "# ==================== PRUEBA 2: CON INFORMACIÓN INSUFICIENTE ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 2: Respuesta cuando NO hay información suficiente\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Cuál es el color del producto P9999?\"\n",
        "context = \"No se encontró información relevante para responder esta consulta.\"\n",
        "\n",
        "print(f\"Query: '{query}'\")\n",
        "print(f\"Contexto: '{context}'\")\n",
        "print(\"\\n🤖 Generando respuesta...\\n\")\n",
        "\n",
        "result = llm_generator.generate(query, context)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"RESPUESTA GENERADA:\")\n",
        "print(\"=\"*60)\n",
        "print(result['response'])\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ==================== PRUEBA 3: VERSIÓN SIMPLIFICADA ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 3: Uso simplificado (solo respuesta)\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Qué productos son compatibles con P0016?\"\n",
        "context = \"\"\"INFORMACIÓN RECUPERADA (Fuente: grafo):\n",
        "\n",
        "1. nombre: Procesadora | marca: TechHome | precio: 329.07\n",
        "2. nombre: Batidora Ultra | marca: ChefMaster | precio: 450.23\n",
        "3. nombre: Picadora Compacta | marca: TechHome | precio: 189.99\n",
        "\"\"\"\n",
        "\n",
        "print(f\"Query: '{query}'\")\n",
        "print(\"\\n🤖 Generando respuesta simplificada...\\n\")\n",
        "\n",
        "response = llm_generator.generate_simple(query, context)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"RESPUESTA:\")\n",
        "print(\"=\"*60)\n",
        "print(response)\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ==================== PRUEBA 4: INTEGRACIÓN CON PIPELINE ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 4: Integración completa (Pipeline + LLM)\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "query = \"¿Cuáles son las licuadoras de menos de $300?\"\n",
        "print(f\"Query: '{query}'\")\n",
        "\n",
        "# Recuperar contexto\n",
        "print(\"\\n1️⃣ Recuperando contexto con el pipeline...\")\n",
        "retrieval_result = retrieval_pipeline.retrieve(query, top_k=5)\n",
        "\n",
        "print(f\"   ✅ Intención: {retrieval_result['intent']}\")\n",
        "print(f\"   ✅ Fuente: {retrieval_result['source']}\")\n",
        "print(f\"   ✅ Resultados: {retrieval_result['num_results']}\")\n",
        "\n",
        "# Generar respuesta\n",
        "print(\"\\n2️⃣ Generando respuesta con LLM...\")\n",
        "llm_result = llm_generator.generate(query, retrieval_result['context'])\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESPUESTA FINAL:\")\n",
        "print(\"=\"*60)\n",
        "print(llm_result['response'])\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n📊 Estadísticas completas:\")\n",
        "print(f\"  Pipeline: {retrieval_result['source']} → {retrieval_result['num_results']} resultados\")\n",
        "print(f\"  LLM: {llm_result['tokens']['total']} tokens en {llm_result['time']:.2f}s\")\n",
        "\n",
        "# ==================== FUNCIÓN HELPER ====================\n",
        "\n",
        "def preguntar(query: str, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Función helper que integra pipeline + LLM\n",
        "\n",
        "    Args:\n",
        "        query: Pregunta del usuario\n",
        "        top_k: Número de resultados a recuperar\n",
        "    \"\"\"\n",
        "    print(f\"\\n💬 Pregunta: '{query}'\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Recuperar\n",
        "    retrieval_result = retrieval_pipeline.retrieve(query, top_k)\n",
        "    print(f\"🔍 Búsqueda: {retrieval_result['source']} ({retrieval_result['num_results']} resultados)\")\n",
        "\n",
        "    # Generar\n",
        "    print(f\"🤖 Generando respuesta...\")\n",
        "    llm_result = llm_generator.generate(query, retrieval_result['context'])\n",
        "\n",
        "    # Mostrar\n",
        "    print(f\"\\n💡 Respuesta:\")\n",
        "    print(\"=\"*60)\n",
        "    print(llm_result['response'])\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\n⏱️  {llm_result['time']:.2f}s | 🔢 {llm_result['tokens']['total']} tokens\")\n",
        "\n",
        "    return llm_result\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"✅ PRUEBAS COMPLETADAS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nFunción helper disponible:\")\n",
        "print(\"  preguntar('tu pregunta', top_k=5)\")\n",
        "print(\"\\nEjemplo:\")\n",
        "print(\"  preguntar('¿Cómo limpiar mi licuadora?')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ptg2c3QZyTOD",
        "outputId": "189a264a-af14-4f7a-934d-852557d3ce83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PRUEBAS DEL LLM GENERATOR\n",
            "============================================================\n",
            "\n",
            "📝 PRUEBA 1: Generación simple con contexto\n",
            "------------------------------------------------------------\n",
            "Query: '¿Cómo uso mi licuadora?'\n",
            "\n",
            "Contexto proporcionado: 519 caracteres\n",
            "\n",
            "🤖 Generando respuesta...\n",
            "\n",
            "============================================================\n",
            "RESPUESTA GENERADA:\n",
            "============================================================\n",
            "Para usar tu licuadora, específicamente para preparar smoothies, te recomiendo seguir los siguientes pasos:\n",
            "\n",
            "1. Corta las frutas en trozos pequeños.\n",
            "2. Agrega líquido primero.\n",
            "3. Luego, agrega frutas suaves.\n",
            "4. Finalmente, agrega frutas congeladas o hielo.\n",
            "5. Utiliza el modo pulse para romper el hielo.\n",
            "\n",
            "Estos pasos te ayudarán a obtener mejores resultados al preparar smoothies con tu licuadora.\n",
            "============================================================\n",
            "\n",
            "📊 Estadísticas:\n",
            "  ✅ Éxito: True\n",
            "  ⏱️  Tiempo: 0.35s\n",
            "  🔢 Tokens prompt: 363\n",
            "  🔢 Tokens completados: 114\n",
            "  🔢 Tokens totales: 477\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 2: Respuesta cuando NO hay información suficiente\n",
            "------------------------------------------------------------\n",
            "Query: '¿Cuál es el color del producto P9999?'\n",
            "Contexto: 'No se encontró información relevante para responder esta consulta.'\n",
            "\n",
            "🤖 Generando respuesta...\n",
            "\n",
            "============================================================\n",
            "RESPUESTA GENERADA:\n",
            "============================================================\n",
            "Lo siento, no hay información disponible en el contexto proporcionado para responder a tu pregunta sobre el color del producto P9999. No puedo proporcionar una respuesta precisa sin más datos. ¿Podrías proporcionar más contexto o reformular la pregunta? Estoy aquí para ayudarte en lo que pueda.\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 3: Uso simplificado (solo respuesta)\n",
            "------------------------------------------------------------\n",
            "Query: '¿Qué productos son compatibles con P0016?'\n",
            "\n",
            "🤖 Generando respuesta simplificada...\n",
            "\n",
            "============================================================\n",
            "RESPUESTA:\n",
            "============================================================\n",
            "Lo siento, hubo un error al generar la respuesta: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99968, Requested 276. Please try again in 3m30.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "📝 PRUEBA 4: Integración completa (Pipeline + LLM)\n",
            "------------------------------------------------------------\n",
            "Query: '¿Cuáles son las licuadoras de menos de $300?'\n",
            "\n",
            "1️⃣ Recuperando contexto con el pipeline...\n",
            "\n",
            "🎯 Intención detectada: tabular\n",
            "📊 Buscando en base tabular (Pandas)...\n",
            "⚠️ Error generando filtros: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99968, Requested 693. Please try again in 9m31.104s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "🔍 Filtros generados: {\n",
            "  \"filters\": []\n",
            "}\n",
            "   ✅ 5 filas recuperadas\n",
            "   ✅ Intención: tabular\n",
            "   ✅ Fuente: tabular\n",
            "   ✅ Resultados: 5\n",
            "\n",
            "2️⃣ Generando respuesta con LLM...\n",
            "\n",
            "============================================================\n",
            "RESPUESTA FINAL:\n",
            "============================================================\n",
            "Lo siento, hubo un error al generar la respuesta: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kcac3rggfy5v1fkvyk7szfqb` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99968, Requested 2204. Please try again in 31m16.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
            "============================================================\n",
            "\n",
            "📊 Estadísticas completas:\n",
            "  Pipeline: tabular → 5 resultados\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4173178763.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n📊 Estadísticas completas:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Pipeline: {retrieval_result['source']} → {retrieval_result['num_results']} resultados\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  LLM: {llm_result['tokens']['total']} tokens en {llm_result['time']:.2f}s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;31m# ==================== FUNCIÓN HELPER ====================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preguntar(\"¿Qué marcas de heladeras hay disponibles por sucursal?\", top_k=10)"
      ],
      "metadata": {
        "id": "Ti7bUEMIyyJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 15: SISTEMA CONVERSACIONAL CON MEMORIA\n",
        "============================================\n",
        "Sistema RAG completo con:\n",
        "- Memoria de conversación\n",
        "- Integración completa de todos los componentes\n",
        "- Chat interactivo\n",
        "\"\"\"\n",
        "\n",
        "from typing import List, Dict, Optional\n",
        "import time\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SISTEMA CONVERSACIONAL RAG\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== MEMORIA CONVERSACIONAL ====================\n",
        "\n",
        "class ConversationalMemory:\n",
        "    \"\"\"Gestiona el historial de conversación\"\"\"\n",
        "\n",
        "    def __init__(self, max_turns: int = 5):\n",
        "        self.max_turns = max_turns\n",
        "        self.history = []\n",
        "\n",
        "        print(f\"💭 Memoria conversacional inicializada\")\n",
        "        print(f\"   Máximo de turnos: {max_turns}\")\n",
        "\n",
        "    def add_turn(self, user_message: str, assistant_message: str):\n",
        "        \"\"\"Agrega un turno de conversación\"\"\"\n",
        "        self.history.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_message\n",
        "        })\n",
        "        self.history.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": assistant_message\n",
        "        })\n",
        "\n",
        "        # Mantener solo los últimos N turnos\n",
        "        if len(self.history) > self.max_turns * 2:\n",
        "            self.history = self.history[-(self.max_turns * 2):]\n",
        "\n",
        "    def get_history(self) -> List[Dict]:\n",
        "        \"\"\"Retorna el historial\"\"\"\n",
        "        return self.history\n",
        "\n",
        "    def clear(self):\n",
        "        \"\"\"Limpia la memoria\"\"\"\n",
        "        self.history = []\n",
        "        print(\"🗑️ Memoria limpiada\")\n",
        "\n",
        "    def get_summary(self) -> str:\n",
        "        \"\"\"Retorna un resumen del historial\"\"\"\n",
        "        if not self.history:\n",
        "            return \"Memoria vacía\"\n",
        "\n",
        "        turns = len(self.history) // 2\n",
        "        return f\"{turns} turnos en memoria\"\n",
        "\n",
        "# ==================== SISTEMA RAG CONVERSACIONAL ====================\n",
        "\n",
        "class ConversationalRAG:\n",
        "    \"\"\"\n",
        "    Sistema RAG completo con capacidades conversacionales\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        retrieval_pipeline,\n",
        "        llm_generator,\n",
        "        memory: Optional[ConversationalMemory] = None,\n",
        "        language: str = 'es'\n",
        "    ):\n",
        "        self.retrieval_pipeline = retrieval_pipeline\n",
        "        self.llm_generator = llm_generator\n",
        "        self.memory = memory or ConversationalMemory(max_turns=5)\n",
        "        self.language = language\n",
        "\n",
        "        print(\"🤖 Sistema RAG Conversacional inicializado\")\n",
        "        print(f\"   Idioma: {language}\")\n",
        "        print(f\"   Memoria: {self.memory.max_turns} turnos\")\n",
        "\n",
        "    def chat(self, user_message: str, top_k: int = 5, verbose: bool = True) -> Dict:\n",
        "        \"\"\"\n",
        "        Procesa un mensaje del usuario y genera respuesta\n",
        "\n",
        "        Args:\n",
        "            user_message: Mensaje del usuario\n",
        "            top_k: Número de resultados a recuperar\n",
        "            verbose: Mostrar información de debug\n",
        "\n",
        "        Returns:\n",
        "            Dict con: response, intent, source, time, etc.\n",
        "        \"\"\"\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\n💬 Usuario: {user_message}\")\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "        # 1. Recuperar información relevante\n",
        "        if verbose:\n",
        "            print(\"🔍 Recuperando información...\")\n",
        "\n",
        "        retrieval_result = self.retrieval_pipeline.retrieve(user_message, top_k)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"   Intención: {retrieval_result['intent']}\")\n",
        "            print(f\"   Fuente: {retrieval_result['source']}\")\n",
        "            print(f\"   Resultados: {retrieval_result['num_results']}\")\n",
        "\n",
        "        # 2. Generar respuesta con historial conversacional\n",
        "        if verbose:\n",
        "            print(\"🤖 Generando respuesta...\")\n",
        "\n",
        "        llm_result = self.llm_generator.generate(\n",
        "            query=user_message,\n",
        "            context=retrieval_result['context'],\n",
        "            conversational_history=self.memory.get_history()\n",
        "        )\n",
        "\n",
        "        # 3. Actualizar memoria\n",
        "        self.memory.add_turn(user_message, llm_result['response'])\n",
        "\n",
        "        # 4. Calcular tiempo total\n",
        "        total_time = time.time() - start_time\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\n⏱️  Tiempo total: {total_time:.2f}s\")\n",
        "            print(f\"🔢 Tokens: {llm_result['tokens']['total']}\")\n",
        "\n",
        "        return {\n",
        "            'response': llm_result['response'],\n",
        "            'intent': retrieval_result['intent'],\n",
        "            'source': retrieval_result['source'],\n",
        "            'num_results': retrieval_result['num_results'],\n",
        "            'tokens': llm_result['tokens'],\n",
        "            'time': total_time,\n",
        "            'success': llm_result['success']\n",
        "        }\n",
        "\n",
        "    def chat_simple(self, user_message: str, top_k: int = 5) -> str:\n",
        "        \"\"\"Versión simplificada que solo retorna la respuesta\"\"\"\n",
        "        result = self.chat(user_message, top_k, verbose=False)\n",
        "        return result['response']\n",
        "\n",
        "    def reset_memory(self):\n",
        "        \"\"\"Reinicia la memoria conversacional\"\"\"\n",
        "        self.memory.clear()\n",
        "\n",
        "    def get_memory_summary(self) -> str:\n",
        "        \"\"\"Obtiene resumen de la memoria\"\"\"\n",
        "        return self.memory.get_summary()\n",
        "\n",
        "    def print_response(self, result: Dict):\n",
        "        \"\"\"Imprime una respuesta de forma bonita\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🤖 ASISTENTE:\")\n",
        "        print(\"=\"*60)\n",
        "        print(result['response'])\n",
        "        print(\"=\"*60)\n",
        "        print(f\"\\n📊 Fuente: {result['source']} | ⏱️ {result['time']:.2f}s | 🔢 {result['tokens']['total']} tokens\")\n",
        "\n",
        "# ==================== INICIALIZACIÓN ====================\n",
        "\n",
        "print(\"🔧 Inicializando sistema conversacional...\\n\")\n",
        "\n",
        "# Crear sistema RAG conversacional\n",
        "rag_system = ConversationalRAG(\n",
        "    retrieval_pipeline=retrieval_pipeline,\n",
        "    llm_generator=llm_generator,\n",
        "    memory=ConversationalMemory(max_turns=5),\n",
        "    language='es'\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ SISTEMA CONVERSACIONAL RAG LISTO\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "Componentes integrados:\n",
        "  ✅ Pipeline de recuperación (3 fuentes)\n",
        "  ✅ Clasificador de intención\n",
        "  ✅ LLM Generator (GROQ)\n",
        "  ✅ Memoria conversacional (5 turnos)\n",
        "\n",
        "Uso básico:\n",
        "  # Chat interactivo\n",
        "  result = rag_system.chat(\"¿Cómo usar mi licuadora?\")\n",
        "\n",
        "  # Solo respuesta\n",
        "  response = rag_system.chat_simple(\"¿Qué productos hay de menos de $200?\")\n",
        "\n",
        "  # Resetear memoria\n",
        "  rag_system.reset_memory()\n",
        "\n",
        "Características:\n",
        "  - Mantiene contexto de conversación\n",
        "  - Soporta preguntas de seguimiento\n",
        "  - Responde en español\n",
        "  - Si no hay información, sugiere reformular\n",
        "\"\"\")\n",
        "print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "id": "duI7Ym-m_EmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 16: PRUEBAS DEL SISTEMA CONVERSACIONAL\n",
        "============================================\n",
        "Pruebas de conversaciones multi-turno con memoria\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PRUEBAS DEL SISTEMA CONVERSACIONAL\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== PRUEBA 1: CONVERSACIÓN SIMPLE ====================\n",
        "\n",
        "print(\"📝 PRUEBA 1: Conversación simple (sin memoria)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "result = rag_system.chat(\"¿Cómo usar mi licuadora para hacer smoothies?\")\n",
        "rag_system.print_response(result)\n",
        "\n",
        "# ==================== PRUEBA 2: CONVERSACIÓN CON MEMORIA ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 2: Conversación con memoria (seguimiento)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Resetear memoria\n",
        "rag_system.reset_memory()\n",
        "\n",
        "# Turno 1\n",
        "print(\"\\n--- Turno 1 ---\")\n",
        "result1 = rag_system.chat(\"¿Cuáles son las licuadoras de menos de $300?\")\n",
        "rag_system.print_response(result1)\n",
        "\n",
        "# Turno 2 (pregunta de seguimiento)\n",
        "print(\"\\n--- Turno 2 (seguimiento) ---\")\n",
        "result2 = rag_system.chat(\"¿Cuál de esas tiene mejor garantía?\")\n",
        "rag_system.print_response(result2)\n",
        "\n",
        "print(f\"\\n💭 Memoria: {rag_system.get_memory_summary()}\")\n",
        "\n",
        "# ==================== PRUEBA 3: CONVERSACIÓN MULTI-FUENTE ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 3: Conversación alternando fuentes\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Resetear memoria\n",
        "rag_system.reset_memory()\n",
        "\n",
        "# Turno 1 - Vectorial\n",
        "print(\"\\n--- Turno 1 (Vectorial) ---\")\n",
        "result1 = rag_system.chat(\"¿Cómo limpiar una licuadora?\")\n",
        "rag_system.print_response(result1)\n",
        "\n",
        "# Turno 2 - Tabular\n",
        "print(\"\\n--- Turno 2 (Tabular) ---\")\n",
        "result2 = rag_system.chat(\"¿Cuánto cuesta una licuadora TechHome?\")\n",
        "rag_system.print_response(result2)\n",
        "\n",
        "# Turno 3 - Grafo\n",
        "print(\"\\n--- Turno 3 (Grafo) ---\")\n",
        "result3 = rag_system.chat(\"¿Qué productos son compatibles con P0016?\")\n",
        "rag_system.print_response(result3)\n",
        "\n",
        "print(f\"\\n💭 Memoria: {rag_system.get_memory_summary()}\")\n",
        "\n",
        "# ==================== PRUEBA 4: CUANDO NO HAY INFORMACIÓN ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 4: Sin información disponible\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "result = rag_system.chat(\"¿Cuál es el color favorito del CEO de TechHome?\")\n",
        "rag_system.print_response(result)\n",
        "\n",
        "# ==================== PRUEBA 5: BATCH DE PREGUNTAS ====================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📝 PRUEBA 5: Batch de preguntas (para el informe)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Resetear memoria para cada conversación\n",
        "test_queries = [\n",
        "    \"¿Cómo usar mi licuadora para hacer smoothies?\",\n",
        "    \"¿Cuáles son las licuadoras de menos de $200?\",\n",
        "    \"¿Qué productos son compatibles con P0016?\",\n",
        "    \"¿Qué opinan los usuarios de las cafeteras?\",\n",
        "    \"Productos con garantía mayor a 24 meses\"\n",
        "]\n",
        "\n",
        "results_summary = []\n",
        "\n",
        "for i, query in enumerate(test_queries, 1):\n",
        "    print(f\"\\n--- Pregunta {i}/5 ---\")\n",
        "    rag_system.reset_memory()\n",
        "\n",
        "    result = rag_system.chat(query, verbose=True)\n",
        "\n",
        "    results_summary.append({\n",
        "        'query': query,\n",
        "        'intent': result['intent'],\n",
        "        'source': result['source'],\n",
        "        'num_results': result['num_results'],\n",
        "        'time': result['time'],\n",
        "        'tokens': result['tokens']['total'],\n",
        "        'success': result['success']\n",
        "    })\n",
        "\n",
        "    print(f\"\\n💡 Respuesta: {result['response'][:150]}...\")\n",
        "\n",
        "# Resumen\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📊 RESUMEN DE RESULTADOS (para el informe)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import pandas as pd\n",
        "df_results = pd.DataFrame(results_summary)\n",
        "\n",
        "print(\"\\n\" + df_results.to_string(index=False))\n",
        "\n",
        "print(f\"\\n📈 Estadísticas:\")\n",
        "print(f\"  Total consultas: {len(results_summary)}\")\n",
        "print(f\"  Exitosas: {sum(1 for r in results_summary if r['success'])}\")\n",
        "print(f\"  Tiempo promedio: {df_results['time'].mean():.2f}s\")\n",
        "print(f\"  Tokens promedio: {df_results['tokens'].mean():.0f}\")\n",
        "\n",
        "print(f\"\\n📊 Distribución por fuente:\")\n",
        "print(df_results['source'].value_counts().to_string())\n",
        "\n",
        "# ==================== FUNCIÓN CHAT INTERACTIVA ====================\n",
        "\n",
        "def chat_interactivo():\n",
        "    \"\"\"\n",
        "    Inicia una sesión de chat interactiva\n",
        "    Escribe 'salir' para terminar\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"💬 CHAT INTERACTIVO\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nComandos especiales:\")\n",
        "    print(\"  'salir' - Terminar chat\")\n",
        "    print(\"  'reset' - Limpiar memoria\")\n",
        "    print(\"  'memoria' - Ver estado de memoria\")\n",
        "    print(\"\\nEscribe tu pregunta:\\n\")\n",
        "\n",
        "    rag_system.reset_memory()\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"👤 Tú: \").strip()\n",
        "\n",
        "        if not user_input:\n",
        "            continue\n",
        "\n",
        "        if user_input.lower() in ['salir', 'exit', 'quit']:\n",
        "            print(\"\\n👋 ¡Hasta luego!\")\n",
        "            break\n",
        "\n",
        "        if user_input.lower() == 'reset':\n",
        "            rag_system.reset_memory()\n",
        "            continue\n",
        "\n",
        "        if user_input.lower() == 'memoria':\n",
        "            print(f\"💭 {rag_system.get_memory_summary()}\")\n",
        "            continue\n",
        "\n",
        "        result = rag_system.chat(user_input, verbose=False)\n",
        "        print(f\"\\n🤖 Asistente: {result['response']}\\n\")\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"✅ PRUEBAS COMPLETADAS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nFunción disponible:\")\n",
        "print(\"  chat_interactivo()  # Inicia chat interactivo\")\n",
        "print(\"\\nEjemplo:\")\n",
        "print(\"  chat_interactivo()\")"
      ],
      "metadata": {
        "id": "lX4O0aL8_Jht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 17: HERRAMIENTAS PARA AGENTE REACT\n",
        "============================================\n",
        "Encapsula las búsquedas en herramientas de Langchain\n",
        "- doc_search: Búsqueda en documentos (vectorial)\n",
        "- table_search: Búsqueda en tablas (Pandas)\n",
        "- graph_search: Búsqueda en grafos (Neo4j)\n",
        "- analytics_tool: Análisis y gráficos con SQL/matplotlib\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HERRAMIENTAS PARA AGENTE REACT\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Instalar Langchain si no está instalado\n",
        "print(\"📦 Verificando dependencias de Langchain...\")\n",
        "try:\n",
        "    import langchain_groq\n",
        "    print(\"   ✅ Langchain-groq ya instalado\")\n",
        "except:\n",
        "    print(\"   📦 Instalando Langchain y dependencias...\")\n",
        "    !pip install -q langchain langchain-groq langchain-community langchain-core matplotlib\n",
        "    print(\"   ✅ Langchain instalado\")\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import base64\n",
        "from typing import Optional\n",
        "\n",
        "# ==================== HERRAMIENTA 1: DOC_SEARCH ====================\n",
        "\n",
        "@tool\n",
        "def doc_search(query: str) -> str:\n",
        "    \"\"\"Busca en documentos de texto (manuales, FAQs, reseñas) usando búsqueda híbrida.\n",
        "\n",
        "    Usa esta herramienta para preguntas sobre:\n",
        "    - Cómo usar productos\n",
        "    - Instrucciones de uso\n",
        "    - Problemas y soluciones\n",
        "    - Opiniones de usuarios\n",
        "    - Mantenimiento\n",
        "\n",
        "    Ejemplo: ¿Cómo usar mi licuadora para hacer smoothies?\n",
        "\n",
        "    Args:\n",
        "        query: Consulta del usuario\n",
        "\n",
        "    Returns:\n",
        "        Texto con los documentos más relevantes\n",
        "    \"\"\"\n",
        "    try:\n",
        "        results = hybrid_search.search(query, top_k=5)\n",
        "\n",
        "        if not results:\n",
        "            return \"No se encontraron documentos relevantes para esta consulta.\"\n",
        "\n",
        "        output = f\"Encontrados {len(results)} documentos relevantes:\\n\\n\"\n",
        "\n",
        "        for i, result in enumerate(results, 1):\n",
        "            source = result['metadata'].get('source', 'N/A')\n",
        "            text = result['text'][:200]\n",
        "            output += f\"{i}. [{source.upper()}] {text}...\\n\\n\"\n",
        "\n",
        "        return output.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error en búsqueda de documentos: {str(e)}\"\n",
        "\n",
        "# ==================== HERRAMIENTA 2: TABLE_SEARCH ====================\n",
        "\n",
        "@tool\n",
        "def table_search(query: str) -> str:\n",
        "    \"\"\"Busca en tablas de datos (productos, ventas, inventario) con filtros dinámicos.\n",
        "\n",
        "    Usa esta herramienta para preguntas sobre:\n",
        "    - Precios de productos\n",
        "    - Filtros por características (voltaje, potencia, color, etc.)\n",
        "    - Stock disponible\n",
        "    - Especificaciones técnicas\n",
        "    - Información de ventas\n",
        "\n",
        "    Ejemplo: ¿Cuáles son las licuadoras de menos de $200?\n",
        "\n",
        "    Args:\n",
        "        query: Consulta del usuario\n",
        "\n",
        "    Returns:\n",
        "        Resultados de la tabla en formato texto\n",
        "    \"\"\"\n",
        "    try:\n",
        "        results = table_searcher.search(query, 'productos', max_results=10)\n",
        "\n",
        "        if len(results) == 0:\n",
        "            results = table_searcher.search(query, 'ventas', max_results=10)\n",
        "\n",
        "        if len(results) == 0 and 'inventario' in dataframes:\n",
        "            results = table_searcher.search(query, 'inventario', max_results=10)\n",
        "\n",
        "        if len(results) == 0:\n",
        "            return \"No se encontraron resultados en las tablas para esta consulta.\"\n",
        "\n",
        "        import pandas as pd\n",
        "        if isinstance(results, pd.DataFrame):\n",
        "            cols_to_show = list(results.columns)[:6]\n",
        "            output = f\"Encontrados {len(results)} registros:\\n\\n\"\n",
        "            output += results[cols_to_show].head(10).to_string(index=False)\n",
        "\n",
        "            if len(results) > 10:\n",
        "                output += f\"\\n\\n... y {len(results) - 10} registros más\"\n",
        "\n",
        "            return output\n",
        "        else:\n",
        "            return str(results)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error en búsqueda de tablas: {str(e)}\"\n",
        "\n",
        "# ==================== HERRAMIENTA 3: GRAPH_SEARCH ====================\n",
        "\n",
        "@tool\n",
        "def graph_search(query: str) -> str:\n",
        "    \"\"\"Busca relaciones en el grafo de conocimiento (Neo4j) con Cypher dinámico.\n",
        "\n",
        "    Usa esta herramienta para preguntas sobre:\n",
        "    - Productos compatibles\n",
        "    - Productos relacionados\n",
        "    - Accesorios\n",
        "    - Stock por sucursal\n",
        "    - Productos de misma marca/categoría\n",
        "\n",
        "    Ejemplo: ¿Qué productos son compatibles con P0016?\n",
        "\n",
        "    Args:\n",
        "        query: Consulta del usuario\n",
        "\n",
        "    Returns:\n",
        "        Relaciones encontradas en formato texto\n",
        "    \"\"\"\n",
        "    try:\n",
        "        results = graph_searcher.search(query)\n",
        "\n",
        "        if not results:\n",
        "            return \"No se encontraron relaciones en el grafo para esta consulta.\"\n",
        "\n",
        "        output = f\"Encontradas {len(results)} relaciones:\\n\\n\"\n",
        "\n",
        "        for i, result in enumerate(results[:10], 1):\n",
        "            items = \" | \".join([f\"{k}: {v}\" for k, v in result.items()])\n",
        "            output += f\"{i}. {items}\\n\"\n",
        "\n",
        "        if len(results) > 10:\n",
        "            output += f\"\\n... y {len(results) - 10} relaciones más\"\n",
        "\n",
        "        return output.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error en búsqueda de grafos: {str(e)}\"\n",
        "\n",
        "# ==================== HERRAMIENTA 4: ANALYTICS_TOOL ====================\n",
        "\n",
        "@tool\n",
        "def analytics_tool(query: str) -> str:\n",
        "    \"\"\"Realiza análisis de datos y genera gráficos con matplotlib.\n",
        "\n",
        "    Usa esta herramienta para:\n",
        "    - Distribuciones (métodos de pago, ventas por sucursal)\n",
        "    - Agregaciones (total ventas, promedios)\n",
        "    - Top productos\n",
        "    - Estadísticas generales\n",
        "\n",
        "    Ejemplo: Dame un gráfico sobre la distribución de métodos de pago\n",
        "\n",
        "    Args:\n",
        "        query: Descripción del análisis deseado\n",
        "\n",
        "    Returns:\n",
        "        Resultado del análisis en texto\n",
        "    \"\"\"\n",
        "    try:\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        if 'gráfico' in query_lower or 'grafico' in query_lower or 'distribución' in query_lower:\n",
        "\n",
        "            if 'método de pago' in query_lower or 'metodo de pago' in query_lower:\n",
        "                if 'ventas' in dataframes:\n",
        "                    df = dataframes['ventas']\n",
        "                    counts = df['metodo_pago'].value_counts()\n",
        "\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    counts.plot(kind='pie', autopct='%1.1f%%')\n",
        "                    plt.title('Distribución de Métodos de Pago')\n",
        "                    plt.ylabel('')\n",
        "\n",
        "                    output_path = config.OUTPUT_DIR / 'metodos_pago.png'\n",
        "                    plt.savefig(output_path, bbox_inches='tight', dpi=150)\n",
        "                    plt.close()\n",
        "\n",
        "                    output = f\"Análisis de métodos de pago:\\n\\n\"\n",
        "                    for metodo, cantidad in counts.items():\n",
        "                        pct = (cantidad / counts.sum()) * 100\n",
        "                        output += f\"  - {metodo}: {cantidad} ({pct:.1f}%)\\n\"\n",
        "\n",
        "                    output += f\"\\n✅ Gráfico guardado en: {output_path}\"\n",
        "\n",
        "                    return output\n",
        "\n",
        "            elif 'sucursal' in query_lower or 'ventas por sucursal' in query_lower:\n",
        "                if 'ventas' in dataframes:\n",
        "                    df = dataframes['ventas']\n",
        "                    ventas_sucursal = df.groupby('sucursal')['total'].sum().sort_values(ascending=False)\n",
        "\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    ventas_sucursal.plot(kind='bar')\n",
        "                    plt.title('Ventas Totales por Sucursal')\n",
        "                    plt.xlabel('Sucursal')\n",
        "                    plt.ylabel('Total Ventas (USD)')\n",
        "                    plt.xticks(rotation=45, ha='right')\n",
        "                    plt.tight_layout()\n",
        "\n",
        "                    output_path = config.OUTPUT_DIR / 'ventas_sucursal.png'\n",
        "                    plt.savefig(output_path, bbox_inches='tight', dpi=150)\n",
        "                    plt.close()\n",
        "\n",
        "                    output = f\"Análisis de ventas por sucursal:\\n\\n\"\n",
        "                    for sucursal, total in ventas_sucursal.items():\n",
        "                        output += f\"  - {sucursal}: ${total:,.2f}\\n\"\n",
        "\n",
        "                    output += f\"\\n✅ Gráfico guardado en: {output_path}\"\n",
        "\n",
        "                    return output\n",
        "\n",
        "        elif 'total' in query_lower or 'suma' in query_lower or 'cuánto' in query_lower:\n",
        "            if 'ventas' in dataframes:\n",
        "                df = dataframes['ventas']\n",
        "                total = df['total'].sum()\n",
        "                cantidad = len(df)\n",
        "                promedio = df['total'].mean()\n",
        "\n",
        "                return f\"\"\"Análisis de ventas:\n",
        "  - Total de ventas: ${total:,.2f}\n",
        "  - Cantidad de transacciones: {cantidad:,}\n",
        "  - Promedio por transacción: ${promedio:,.2f}\"\"\"\n",
        "\n",
        "        elif 'top' in query_lower or 'mejores' in query_lower:\n",
        "            if 'ventas' in dataframes:\n",
        "                df = dataframes['ventas']\n",
        "                top_productos = df.groupby('id_producto').agg({\n",
        "                    'cantidad': 'sum',\n",
        "                    'total': 'sum'\n",
        "                }).sort_values('cantidad', ascending=False).head(10)\n",
        "\n",
        "                output = \"Top 10 productos más vendidos:\\n\\n\"\n",
        "                for i, (prod_id, row) in enumerate(top_productos.iterrows(), 1):\n",
        "                    output += f\"{i}. {prod_id}: {row['cantidad']} unidades (${row['total']:,.2f})\\n\"\n",
        "\n",
        "                return output\n",
        "\n",
        "        return \"No se pudo realizar el análisis solicitado. Intenta especificar mejor qué tipo de análisis necesitas.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error en análisis de datos: {str(e)}\"\n",
        "\n",
        "# ==================== CREAR LISTA DE HERRAMIENTAS ====================\n",
        "\n",
        "print(\"🔧 Creando lista de herramientas de Langchain...\\n\")\n",
        "\n",
        "# Las herramientas ya están definidas con el decorador @tool arriba\n",
        "tools = [doc_search, table_search, graph_search, analytics_tool]\n",
        "\n",
        "print(\"✅ Herramientas creadas:\")\n",
        "for tool in tools:\n",
        "    print(f\"   - {tool.name}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ HERRAMIENTAS PARA AGENTE REACT LISTAS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "4 herramientas disponibles:\n",
        "  1. doc_search - Búsqueda en documentos (vectorial)\n",
        "  2. table_search - Búsqueda en tablas (Pandas)\n",
        "  3. graph_search - Búsqueda en grafos (Neo4j)\n",
        "  4. analytics_tool - Análisis y gráficos\n",
        "\n",
        "Las herramientas están listas para ser usadas por el agente ReAct.\n",
        "\"\"\")\n",
        "print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "id": "DvLu3shq7Fsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================\n",
        "CELDA 18: AGENTE REACT CON LANGCHAIN\n",
        "============================================\n",
        "Agente inteligente que razona (Thought), actúa (Action) y observa (Observation)\n",
        "para responder consultas complejas usando múltiples herramientas\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import re\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"AGENTE REACT CON LANGCHAIN\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ==================== CONFIGURAR LLM ====================\n",
        "\n",
        "print(\"🤖 Configurando LLM para el agente...\")\n",
        "\n",
        "# Usar GROQ con llama-3.3-70b\n",
        "llm = ChatGroq(\n",
        "    api_key=config.GROQ_API_KEY,\n",
        "    model_name=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0.1,\n",
        "    max_tokens=2048\n",
        ")\n",
        "\n",
        "print(\"   ✅ LLM configurado: llama-3.3-70b-versatile\")\n",
        "\n",
        "# ==================== AGENTE REACT MANUAL ====================\n",
        "\n",
        "class SimpleReActAgent:\n",
        "    \"\"\"\n",
        "    Agente ReAct implementado manualmente\n",
        "    Sigue el paradigma: Thought → Action → Observation → Final Answer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm, tools, max_iterations=5):\n",
        "        self.llm = llm\n",
        "        self.tools = {tool.name: tool for tool in tools}\n",
        "        self.max_iterations = max_iterations\n",
        "\n",
        "        # Crear descripción de herramientas\n",
        "        self.tools_desc = \"\\n\".join([\n",
        "            f\"- {name}: {tool.description}\"\n",
        "            for name, tool in self.tools.items()\n",
        "        ])\n",
        "\n",
        "    def _create_prompt(self, query: str, history: str = \"\") -> str:\n",
        "        \"\"\"Crea el prompt ReAct\"\"\"\n",
        "\n",
        "        prompt = f\"\"\"Eres un asistente virtual experto en electrodomésticos.\n",
        "\n",
        "Tienes acceso a estas herramientas:\n",
        "\n",
        "{self.tools_desc}\n",
        "\n",
        "FORMATO EXACTO que DEBES seguir:\n",
        "\n",
        "Thought: [tu razonamiento sobre qué hacer]\n",
        "Action: [nombre_exacto_de_herramienta]\n",
        "Action Input: [entrada para la herramienta]\n",
        "\n",
        "O si ya tienes la respuesta:\n",
        "\n",
        "Thought: Ya tengo suficiente información\n",
        "Final Answer: [tu respuesta final en español]\n",
        "\n",
        "REGLAS:\n",
        "1. Usa el formato EXACTO de arriba\n",
        "2. Nombres de herramientas: doc_search, table_search, graph_search, analytics_tool\n",
        "3. Responde SIEMPRE en español\n",
        "4. Piensa paso a paso\n",
        "\n",
        "Pregunta: {query}\n",
        "\n",
        "{history}\n",
        "\n",
        "Comienza con \"Thought:\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def run(self, query: str, verbose: bool = True) -> dict:\n",
        "        \"\"\"Ejecuta el agente\"\"\"\n",
        "\n",
        "        start_time = time.time()\n",
        "        history = \"\"\n",
        "        intermediate_steps = []\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\n💬 Usuario: {query}\")\n",
        "            print(\"=\"*60)\n",
        "            print(\"🤖 Agente ReAct procesando...\\n\")\n",
        "\n",
        "        for iteration in range(self.max_iterations):\n",
        "            if verbose:\n",
        "                print(f\"--- Iteración {iteration + 1} ---\")\n",
        "\n",
        "            # Generar respuesta del LLM\n",
        "            prompt = self._create_prompt(query, history)\n",
        "\n",
        "            try:\n",
        "                response = self.llm.invoke(prompt)\n",
        "                response_text = response.content\n",
        "\n",
        "                if verbose:\n",
        "                    print(response_text)\n",
        "                    print()\n",
        "\n",
        "                # Buscar Final Answer\n",
        "                if \"Final Answer:\" in response_text:\n",
        "                    match = re.search(r'Final Answer:\\s*(.+)', response_text, re.DOTALL)\n",
        "                    if match:\n",
        "                        final_answer = match.group(1).strip()\n",
        "                        elapsed_time = time.time() - start_time\n",
        "\n",
        "                        return {\n",
        "                            'output': final_answer,\n",
        "                            'intermediate_steps': intermediate_steps,\n",
        "                            'time': elapsed_time,\n",
        "                            'success': True,\n",
        "                            'error': None\n",
        "                        }\n",
        "\n",
        "                # Extraer Action y Action Input\n",
        "                action_match = re.search(r'Action:\\s*(\\w+)', response_text)\n",
        "                input_match = re.search(r'Action Input:\\s*(.+?)(?:\\n|$)', response_text, re.DOTALL)\n",
        "\n",
        "                if action_match and input_match:\n",
        "                    action = action_match.group(1).strip()\n",
        "                    action_input = input_match.group(1).strip()\n",
        "\n",
        "                    # Ejecutar herramienta\n",
        "                    if action in self.tools:\n",
        "                        tool = self.tools[action]\n",
        "                        observation = tool.func(action_input)\n",
        "\n",
        "                        intermediate_steps.append({\n",
        "                            'action': action,\n",
        "                            'input': action_input,\n",
        "                            'observation': observation\n",
        "                        })\n",
        "\n",
        "                        # Agregar a historial\n",
        "                        history += f\"\\n{response_text}\\nObservation: {observation}\\n\"\n",
        "\n",
        "                        if verbose:\n",
        "                            print(f\"Observation: {observation}\\n\")\n",
        "                    else:\n",
        "                        if verbose:\n",
        "                            print(f\"⚠️ Herramienta '{action}' no encontrada\\n\")\n",
        "                        history += f\"\\n{response_text}\\nObservation: Error - Herramienta no encontrada\\n\"\n",
        "                else:\n",
        "                    # No se pudo parsear, intentar de nuevo\n",
        "                    if verbose:\n",
        "                        print(\"⚠️ No se pudo parsear Action/Action Input\\n\")\n",
        "                    break\n",
        "\n",
        "            except Exception as e:\n",
        "                elapsed_time = time.time() - start_time\n",
        "                return {\n",
        "                    'output': f\"Error en iteración {iteration + 1}: {str(e)}\",\n",
        "                    'intermediate_steps': intermediate_steps,\n",
        "                    'time': elapsed_time,\n",
        "                    'success': False,\n",
        "                    'error': str(e)\n",
        "                }\n",
        "\n",
        "        # Si llegamos aquí, no se encontró respuesta final\n",
        "        elapsed_time = time.time() - start_time\n",
        "        return {\n",
        "            'output': \"No se pudo completar la consulta en el número máximo de iteraciones.\",\n",
        "            'intermediate_steps': intermediate_steps,\n",
        "            'time': elapsed_time,\n",
        "            'success': False,\n",
        "            'error': 'Max iterations reached'\n",
        "        }\n",
        "\n",
        "print(\"\\n🔧 Creando agente ReAct...\")\n",
        "\n",
        "# Crear agente\n",
        "agent_executor = SimpleReActAgent(llm, tools, max_iterations=5)\n",
        "\n",
        "print(\"   ✅ Agente ReAct creado con éxito\")\n",
        "\n",
        "# ==================== WRAPPER PARA USO FÁCIL ====================\n",
        "\n",
        "class ReactAgent:\n",
        "    \"\"\"Wrapper del agente ReAct para uso simplificado\"\"\"\n",
        "\n",
        "    def __init__(self, executor):\n",
        "        self.executor = executor\n",
        "\n",
        "    def run(self, query: str, verbose: bool = True) -> dict:\n",
        "        \"\"\"Ejecuta el agente\"\"\"\n",
        "        return self.executor.run(query, verbose)\n",
        "\n",
        "    def run_simple(self, query: str) -> str:\n",
        "        \"\"\"Versión simplificada que solo retorna la respuesta\"\"\"\n",
        "        result = self.run(query, verbose=False)\n",
        "        return result['output']\n",
        "\n",
        "    def print_response(self, result: dict):\n",
        "        \"\"\"Imprime una respuesta de forma bonita\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🎯 RESPUESTA FINAL:\")\n",
        "        print(\"=\"*60)\n",
        "        print(result['output'])\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        steps = len(result.get('intermediate_steps', []))\n",
        "        print(f\"\\n📊 Herramientas usadas: {steps} | ⏱️ Tiempo: {result['time']:.2f}s\")\n",
        "\n",
        "# Crear instancia del agente\n",
        "react_agent = ReactAgent(agent_executor)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ AGENTE REACT LISTO\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "Características:\n",
        "  ✅ Paradigma ReAct (Thought → Action → Observation)\n",
        "  ✅ 4 herramientas disponibles\n",
        "  ✅ Razonamiento paso a paso\n",
        "  ✅ Puede usar múltiples herramientas en una consulta\n",
        "  ✅ Implementación manual sin dependencias complejas\n",
        "\n",
        "Uso:\n",
        "  # Con verbose (muestra razonamiento)\n",
        "  result = react_agent.run(\"tu consulta\")\n",
        "\n",
        "  # Sin verbose (solo respuesta)\n",
        "  response = react_agent.run_simple(\"tu consulta\")\n",
        "\n",
        "  # Imprimir bonito\n",
        "  react_agent.print_response(result)\n",
        "\n",
        "Ejemplos de consultas:\n",
        "  - \"¿Cómo usar mi licuadora para hacer smoothies?\"\n",
        "  - \"¿Cuáles son las licuadoras de menos de $200?\"\n",
        "  - \"Dame un gráfico de ventas por sucursal\"\n",
        "  - \"¿Qué productos son compatibles con P0016?\"\n",
        "\"\"\")\n",
        "print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "id": "nXpDnasS9fnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Consulta vectorial (doc_search)\n",
        "react_agent.run(\"¿Cómo limpiar mi licuadora?\")\n",
        "\n",
        "# Consulta tabular (table_search)\n",
        "react_agent.run(\"Productos de menos de $300\")\n",
        "\n",
        "# Consulta grafo (graph_search)\n",
        "react_agent.run(\"¿Dónde hay stock del producto P0001?\")\n",
        "\n",
        "# Consulta analytics (analytics_tool)\n",
        "react_agent.run(\"Dame un gráfico de ventas por sucursal\")\n",
        "\n",
        "# Consulta compleja (múltiples herramientas)\n",
        "react_agent.run(\"¿Qué productos compatibles con P0016 cuestan menos de $300?\")"
      ],
      "metadata": {
        "id": "W5dp0J_g9651"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}